{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM, Dropout, Dense, InputLayer\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./datasets/datasets/Classical/57_DutchPowerDemand.npz', './datasets/datasets/Classical/55_Boschline.npz', './datasets/datasets/Classical/39_HSEFilters2.npz', './datasets/datasets/Classical/45_SWAT.npz', './datasets/datasets/Classical/62_ECoating.npz', './datasets/datasets/Classical/65_MachineryFault.npz', './datasets/datasets/Classical/43_Motorcondition2.npz', './datasets/datasets/Classical/54_CNCMachining.npz', './datasets/datasets/Classical/42_Motorcondition1.npz', './datasets/datasets/Classical/50_PLAID.npz', './datasets/datasets/Classical/48_Ladlefurnace.npz', './datasets/datasets/Classical/60_Concrete.npz', './datasets/datasets/Classical/49_Wafer2.npz', './datasets/datasets/Classical/35_IMS.npz', './datasets/datasets/Classical/66_Cuttingblade.npz', './datasets/datasets/Classical/38_HSEFilters1.npz', './datasets/datasets/Classical/51_PowerCons.npz', './datasets/datasets/Classical/63_Prensas.npz', './datasets/datasets/Classical/40_Yahoo1.npz', './datasets/datasets/Classical/36_PHM.npz', './datasets/datasets/Classical/52_Computers.npz', './datasets/datasets/Classical/44_HALsteamturbine.npz', './datasets/datasets/Classical/46_Sm4Tankbatch.npz', './datasets/datasets/Classical/34_Turbofan.npz', './datasets/datasets/Classical/61_Biopharmaceutical.npz', './datasets/datasets/Classical/59_UCISecom.npz', './datasets/datasets/Classical/58_MiningProcess.npz', './datasets/datasets/Classical/56_ShuttleMarottaValve.npz', './datasets/datasets/Classical/37_Shutlevalve.npz', './datasets/datasets/Classical/41_Yahoo2.npz', './datasets/datasets/Classical/64_PlasmaSpray.npz', './datasets/datasets/Classical/47_FordB_anreal.npz', './datasets/datasets/Classical/53_Walk2D.npz']\n"
     ]
    }
   ],
   "source": [
    "# file_path = '/path/to/Classical' 각자가 저장한 폴더로 연결해주세요\n",
    "file_path = './datasets/datasets/Classical/*.npz'\n",
    "file_list = glob.glob(file_path)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('datasets/datasets/Classical/65_MachineryFault.npz', allow_pickle=True)\n",
    "# data = np.load('datasets/datasets/Classical/54_CNCMachining.npz', allow_pickle=True)\n",
    "X, y = data['X'], data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.4359  , -1.1073  ,  0.22269 , ..., -0.037787,  0.11994 ,\n",
       "        -0.14026 ],\n",
       "       [ 4.4628  ,  0.47153 ,  0.049814, ..., -0.037627,  0.14496 ,\n",
       "         0.15596 ],\n",
       "       [ 4.4511  , -1.8167  ,  0.054311, ..., -0.037447,  0.10992 ,\n",
       "        -0.045535],\n",
       "       ...,\n",
       "       [-0.53822 ,  1.2746  ,  0.43657 , ..., -0.051854, -2.1676  ,\n",
       "        -0.13792 ],\n",
       "       [-0.52845 , -0.88213 , -0.25662 , ..., -0.052278, -2.3157  ,\n",
       "         0.20938 ],\n",
       "       [-0.53948 ,  0.76996 ,  0.38191 , ..., -0.053375, -2.2277  ,\n",
       "        -0.13198 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X shape : 99399, 3\n",
    "# (Batch size, Sequence(timestamp), Feature)\n",
    "\n",
    "X[0:5]\n",
    "X.shape\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class ConvLSTMModel(Model):\n",
    "    def __init__(self, in_channel):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "        self.conv1d_1 = Conv1D(filter=16, kernel_size=3, strides=1, padding='same', input_shape=in_channel)\n",
    "\n",
    "        self.conv1d_2 = Conv1D(filter=32, kernel_size=3, strides=1, padding='same', input_shape=16)\n",
    "\n",
    "        self.lstm = LSTM()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dropout, Dense\n",
    "from tensorflow.keras import Model\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "class Conv1d_LSTM(Model):\n",
    "    def __init__(self, in_channel=3, out_channel=1):\n",
    "        super(Conv1d_LSTM, self).__init__()\n",
    "        self.conv1d_1 = Conv1D(filters=16,\n",
    "                               kernel_size=3,\n",
    "                               strides=1,\n",
    "                               padding='same',\n",
    "                               activation=None)  # Activation will be added separately\n",
    "        self.conv1d_2 = Conv1D(filters=32,\n",
    "                               kernel_size=3,\n",
    "                               strides=1,\n",
    "                               padding='same',\n",
    "                               activation=None)  # Activation will be added separately\n",
    "        \n",
    "        self.lstm = LSTM(units=50,\n",
    "                         return_sequences=True,\n",
    "                         return_state=False,\n",
    "                         dropout=0.0,\n",
    "                         recurrent_dropout=0.0)\n",
    "        \n",
    "        self.dropout = Dropout(0.5)\n",
    "        \n",
    "        self.dense1 = Dense(32, activation='relu')\n",
    "        self.dense2 = Dense(out_channel)\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])  # Shape: (B, S, F) => (B, F, S)\n",
    "        x = self.conv1d_1(x)\n",
    "        x = tf.nn.relu(x)  # Applying ReLU activation after Conv1D\n",
    "        x = self.conv1d_2(x)\n",
    "        x = tf.nn.relu(x)  # Applying ReLU activation after Conv1D\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])  # Shape: (B, F, S) => (B, S, F)\n",
    "        \n",
    "        x, _ = self.lstm(x)  # x shape: (B, S, H) => (B, 10, 50)\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        x = self.dense1(x[:, -1, :])  # Take the last sequence element\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv1d_LSTM(in_channel=3, out_channel=1)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error',  # 회귀 문제의 경우\n",
    "              metrics=['accuracy'])  # 분류 문제의 경우 accuracy로 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seyeong/anaconda3/envs/anomaly_detection/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Conv1d_LSTM.call().\n\n\u001b[1mtoo many values to unpack (expected 2)\u001b[0m\n\nArguments received by Conv1d_LSTM.call():\n  • inputs=tf.Tensor(shape=(32, 10, 3), dtype=float32)\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 회귀 문제의 경우\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 20%의 데이터는 검증용으로 사용\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly_detection/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[34], line 40\u001b[0m, in \u001b[0;36mConv1d_LSTM.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(x)  \u001b[38;5;66;03m# Applying ReLU activation after Conv1D\u001b[39;00m\n\u001b[1;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(x, perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Shape: (B, F, S) => (B, S, F)\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)  \u001b[38;5;66;03m# x shape: (B, S, H) => (B, 10, 50)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense1(x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Take the last sequence element\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Conv1d_LSTM.call().\n\n\u001b[1mtoo many values to unpack (expected 2)\u001b[0m\n\nArguments received by Conv1d_LSTM.call():\n  • inputs=tf.Tensor(shape=(32, 10, 3), dtype=float32)\n  • training=True"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 예제\n",
    "import numpy as np\n",
    "\n",
    "# 예제 데이터 생성\n",
    "X_train = np.random.rand(100, 10, 3)  # 100개의 샘플, 각 샘플은 (10, 3) 모양\n",
    "y_train = np.random.rand(100, 1)  # 회귀 문제의 경우\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,  # 20%의 데이터는 검증용으로 사용\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Conv1d_LSTM.call().\n\n\u001b[1mtoo many values to unpack (expected 2)\u001b[0m\n\nArguments received by Conv1d_LSTM.call():\n  • inputs=tf.Tensor(shape=(32, 10, 3), dtype=float32)\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 회귀 문제의 경우\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 20%의 데이터는 검증용으로 사용\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly_detection/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[38], line 39\u001b[0m, in \u001b[0;36mConv1d_LSTM.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(x)  \u001b[38;5;66;03m# Applying ReLU activation after Conv1D\u001b[39;00m\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(x, perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Shape: (B, F, S) => (B, S, F)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)  \u001b[38;5;66;03m# x shape: (B, S, H)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense1(x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Take the last sequence element\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Conv1d_LSTM.call().\n\n\u001b[1mtoo many values to unpack (expected 2)\u001b[0m\n\nArguments received by Conv1d_LSTM.call():\n  • inputs=tf.Tensor(shape=(32, 10, 3), dtype=float32)\n  • training=True"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dropout, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class Conv1d_LSTM(Model):\n",
    "    def __init__(self, in_channel=3, out_channel=1):\n",
    "        super(Conv1d_LSTM, self).__init__()\n",
    "        self.conv1d_1 = Conv1D(filters=16,\n",
    "                               kernel_size=3,\n",
    "                               strides=1,\n",
    "                               padding='same',\n",
    "                               activation=None)  # Activation will be added separately\n",
    "        self.conv1d_2 = Conv1D(filters=32,\n",
    "                               kernel_size=3,\n",
    "                               strides=1,\n",
    "                               padding='same',\n",
    "                               activation=None)  # Activation will be added separately\n",
    "        LSTM(units=50, input_shape=(X_train.shape[1], 1), return_sequences=True)\n",
    "        self.lstm = LSTM(units=50, input_shape, return_sequences=True)\n",
    "        self.lstm = LSTM(units=50,\n",
    "                         return_sequences=True,\n",
    "                         return_state=False,\n",
    "                         dropout=0.0,\n",
    "                         recurrent_dropout=0.0)\n",
    "        \n",
    "        self.dropout = Dropout(0.5)\n",
    "        \n",
    "        self.dense1 = Dense(32, activation='relu')\n",
    "        self.dense2 = Dense(out_channel)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])  # Shape: (B, S, F) => (B, F, S)\n",
    "        x = self.conv1d_1(x)\n",
    "        x = tf.nn.relu(x)  # Applying ReLU activation after Conv1D\n",
    "        x = self.conv1d_2(x)\n",
    "        x = tf.nn.relu(x)  # Applying ReLU activation after Conv1D\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])  # Shape: (B, F, S) => (B, S, F)\n",
    "        \n",
    "        x, _ = self.lstm(x)  # x shape: (B, S, H)\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        x = self.dense1(x[:, -1, :])  # Take the last sequence element\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = Conv1d_LSTM(in_channel=3, out_channel=1)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',  # 회귀 문제에 적합한 손실 함수\n",
    "              metrics=['mae'])\n",
    "\n",
    "# 예제 데이터 생성\n",
    "import numpy as np\n",
    "X_train = np.random.rand(100, 10, 3)  # (batch_size, sequence_length, features)\n",
    "y_train = np.random.rand(100, 1)  # 회귀 문제의 경우\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,  # 20%의 데이터는 검증용으로 사용\n",
    "                    verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
