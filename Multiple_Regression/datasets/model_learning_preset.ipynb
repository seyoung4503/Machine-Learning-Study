{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "dataset_path = './datasets/Classical/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/seyeong/workspace/Machine-Learning/Multiple_Regression/datasets\n",
      "['anomaly_detection_model_automation.ipynb', 'model_learning_preset.ipynb', 'datasets']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "file_list = os.listdir(dir_path)\n",
    "\n",
    "print(dir_path)\n",
    "print(file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npz data to pd.\n",
    "def npz_to_csv(file_path):\n",
    "    file = np.load(file_path, allow_pickle=True)\n",
    "    X_df = pd.DataFrame(file['X'])\n",
    "    y_df = pd.DataFrame(file['y'])\n",
    "    return X_df, y_df\n",
    "\n",
    "# npz_to_csv(\"/Classical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series 데이터에대하여 Pandas dataframe을 입력으로 받으면 lstm모델로 학습 후, 검증 loss값들과 accuracy값들을 return해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import legacy\n",
    "def train_and_evaluate_lstm(X, y, n_splits=5, epochs=30, batch_size=32):\n",
    "    # 데이터 정규화\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    fold = 1\n",
    "    for train_idx, test_idx in tscv.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Input shape 맞추기 위함\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=50, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(units=50, return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=legacy.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
    "        \n",
    "        # 가장 좋은 검증 성능을 기록\n",
    "        best_val_loss = min(history.history['val_loss'])\n",
    "        best_val_acc = max(history.history['val_accuracy'])\n",
    "        val_losses.append(best_val_loss)\n",
    "        val_accs.append(best_val_acc)\n",
    "        \n",
    "        print(f\"Fold {fold}, Best Validation Loss: {best_val_loss}, Best Validation Accuracy: {best_val_acc}\")\n",
    "        \n",
    "        fold += 1\n",
    "\n",
    "    mean_val_loss = np.mean(val_losses)\n",
    "    mean_val_acc = np.mean(val_accs)\n",
    "    \n",
    "    print(f\"Mean Best Validation Loss: {mean_val_loss}\")\n",
    "    print(f\"Mean Best Validation Accuracy: {mean_val_acc}\")\n",
    "    val_losses.append(mean_val_loss)\n",
    "    val_accs.append(mean_val_acc)\n",
    "    \n",
    "    return val_losses, val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val losses와 val acc를 한 번에 plotting하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_metrics(val_losses, val_accs):\n",
    "    num_folds = len(val_losses)\n",
    "    \n",
    "    folds = range(1, num_folds + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "    \n",
    "    ax1.plot(folds, val_losses, marker='o', linestyle='-', color='b')\n",
    "    ax1.set_ylabel('Validation Loss')\n",
    "    ax1.set_title('Validation Loss and Accuracy')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(folds, val_accs, marker='o', linestyle='-', color='g')\n",
    "    ax2.set_xlabel('Fold')\n",
    "    ax2.set_ylabel('Validation Accuracy')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_validation_metrics(fig_name, val_losses, val_accs):\n",
    "    if not os.path.exists('figure'):\n",
    "        os.makedirs('figure')\n",
    "        \n",
    "    num_folds = len(val_losses)\n",
    "    \n",
    "    folds = range(1, num_folds + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "    \n",
    "    ax1.plot(folds, val_losses, marker='o', linestyle='-', color='b')\n",
    "    ax1.set_ylabel('Validation Loss')\n",
    "    ax1.set_title('Validation Loss and Accuracy' + fig_name)\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(folds, val_accs, marker='o', linestyle='-', color='g')\n",
    "    ax2.set_xlabel('Fold')\n",
    "    ax2.set_ylabel('Validation Accuracy')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('figure', fig_name))\n",
    "    plt.close() \n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly data 비율을 나타내는 함수.\n",
    "혹시 너무 accuracy가 정확하게 나오는 경우, 모든 데이터셋에 대하여 0이라고 판단했는데 알고보니 레이블이 0인 데이터의 개수가 엄청나게 많을 수 있음.\n",
    "따라서 항상 의심할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomaly_rate(y):\n",
    "    return y.value_counts()[1] / (y.value_counts()[0] + y.value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 val_losses와 val_accs를 데이터셋 인덱스에 따라 dictionary로 저장하기 위한 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_val_dict(index, val_loss, val_acc):\n",
    "    val_dict[index] = (val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "append_to_val_dict() missing 3 required positional arguments: 'index', 'val_loss', and 'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mappend_to_val_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: append_to_val_dict() missing 3 required positional arguments: 'index', 'val_loss', and 'val_acc'"
     ]
    }
   ],
   "source": [
    "append_to_val_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 이름 추출\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['34_Turbofan.npz',\n",
       " '35_IMS.npz',\n",
       " '36_PHM.npz',\n",
       " '37_Shutlevalve.npz',\n",
       " '38_HSEFilters1.npz',\n",
       " '39_HSEFilters2.npz',\n",
       " '40_Yahoo1.npz',\n",
       " '41_Yahoo2.npz',\n",
       " '42_Motorcondition1.npz',\n",
       " '43_Motorcondition2.npz',\n",
       " '44_HALsteamturbine.npz',\n",
       " '45_SWAT.npz',\n",
       " '46_Sm4Tankbatch.npz',\n",
       " '47_FordB_anreal.npz',\n",
       " '48_Ladlefurnace.npz',\n",
       " '49_Wafer2.npz',\n",
       " '50_PLAID.npz',\n",
       " '51_PowerCons.npz',\n",
       " '52_Computers.npz',\n",
       " '53_Walk2D.npz',\n",
       " '54_CNCMachining.npz',\n",
       " '55_Boschline.npz',\n",
       " '56_ShuttleMarottaValve.npz',\n",
       " '57_DutchPowerDemand.npz',\n",
       " '58_MiningProcess.npz',\n",
       " '59_UCISecom.npz',\n",
       " '60_Concrete.npz',\n",
       " '61_Biopharmaceutical.npz',\n",
       " '62_ECoating.npz',\n",
       " '63_Prensas.npz',\n",
       " '64_PlasmaSpray.npz',\n",
       " '65_MachineryFault.npz',\n",
       " '66_Cuttingblade.npz']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_list = os.listdir(dataset_path)\n",
    "file_list.sort()\n",
    "\n",
    "file_list = file_list[1:]\n",
    "\n",
    "print(len(file_list))\n",
    "file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size: 4044166 bytes\n",
      "3.86\n"
     ]
    }
   ],
   "source": [
    "# 파일 크기 확인\n",
    " \n",
    "# 파일 단위로 바꾸기\n",
    "def convert_size(size_bytes):\n",
    "    import math\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "# 사용 예제\n",
    "file_size = os.path.getsize(dataset_path + '34_Turbofan.npz') \n",
    "print('File Size:', file_size, 'bytes')\n",
    "a = convert_size(file_size)\n",
    "a = a.split(' ')\n",
    "print(float(a[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.86 MB'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "Epoch 1/30\n",
      "99/99 [==============================] - 2s 5ms/step - loss: 0.6701 - accuracy: 0.6302 - val_loss: 0.8709 - val_accuracy: 0.2623\n",
      "Epoch 2/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6349 - val_loss: 0.8558 - val_accuracy: 0.2623\n",
      "Epoch 3/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6349 - val_loss: 0.8544 - val_accuracy: 0.2623\n",
      "Epoch 4/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6349 - val_loss: 0.8571 - val_accuracy: 0.2623\n",
      "Epoch 5/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6349 - val_loss: 0.8691 - val_accuracy: 0.2623\n",
      "Epoch 6/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6349 - val_loss: 0.8627 - val_accuracy: 0.2623\n",
      "Epoch 7/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6349 - val_loss: 0.8622 - val_accuracy: 0.2623\n",
      "Epoch 8/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6349 - val_loss: 0.8583 - val_accuracy: 0.2623\n",
      "Epoch 9/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6349 - val_loss: 0.8551 - val_accuracy: 0.2623\n",
      "Epoch 10/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6349 - val_loss: 0.8762 - val_accuracy: 0.2623\n",
      "Epoch 11/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6349 - val_loss: 0.8599 - val_accuracy: 0.2623\n",
      "Epoch 12/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6349 - val_loss: 0.8637 - val_accuracy: 0.2623\n",
      "Epoch 13/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6349 - val_loss: 0.8543 - val_accuracy: 0.2623\n",
      "Epoch 14/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6349 - val_loss: 0.8609 - val_accuracy: 0.2623\n",
      "Epoch 15/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6349 - val_loss: 0.8733 - val_accuracy: 0.2623\n",
      "Epoch 16/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6349 - val_loss: 0.8445 - val_accuracy: 0.2623\n",
      "Epoch 17/30\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.6349 - val_loss: 0.8677 - val_accuracy: 0.2623\n",
      "Epoch 18/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6349 - val_loss: 0.8765 - val_accuracy: 0.2623\n",
      "Epoch 19/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8683 - val_accuracy: 0.2623\n",
      "Epoch 20/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6349 - val_loss: 0.8586 - val_accuracy: 0.2623\n",
      "Epoch 21/30\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.6349 - val_loss: 0.8587 - val_accuracy: 0.2623\n",
      "Epoch 22/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6349 - val_loss: 0.8635 - val_accuracy: 0.2623\n",
      "Epoch 23/30\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6349 - val_loss: 0.8710 - val_accuracy: 0.2623\n",
      "Epoch 24/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8733 - val_accuracy: 0.2623\n",
      "Epoch 25/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6349 - val_loss: 0.8700 - val_accuracy: 0.2623\n",
      "Epoch 26/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6349 - val_loss: 0.8595 - val_accuracy: 0.2623\n",
      "Epoch 27/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6349 - val_loss: 0.8546 - val_accuracy: 0.2623\n",
      "Epoch 28/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6349 - val_loss: 0.8576 - val_accuracy: 0.2623\n",
      "Epoch 29/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6349 - val_loss: 0.8528 - val_accuracy: 0.2623\n",
      "Epoch 30/30\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6349 - val_loss: 0.8433 - val_accuracy: 0.2623\n",
      "Fold 1, Best Validation Loss: 0.8433380126953125, Best Validation Accuracy: 0.2623211443424225\n",
      "Epoch 1/30\n",
      "197/197 [==============================] - 2s 3ms/step - loss: 0.6890 - accuracy: 0.5511 - val_loss: 0.6721 - val_accuracy: 0.6305\n",
      "Epoch 2/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5512 - val_loss: 0.6738 - val_accuracy: 0.6305\n",
      "Epoch 3/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5512 - val_loss: 0.6718 - val_accuracy: 0.6305\n",
      "Epoch 4/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5512 - val_loss: 0.6722 - val_accuracy: 0.6305\n",
      "Epoch 5/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6726 - val_accuracy: 0.6305\n",
      "Epoch 6/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6703 - val_accuracy: 0.6305\n",
      "Epoch 7/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5512 - val_loss: 0.6743 - val_accuracy: 0.6305\n",
      "Epoch 8/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6734 - val_accuracy: 0.6305\n",
      "Epoch 9/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6693 - val_accuracy: 0.6305\n",
      "Epoch 10/30\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5512 - val_loss: 0.6753 - val_accuracy: 0.6305\n",
      "Epoch 11/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5512 - val_loss: 0.6727 - val_accuracy: 0.6305\n",
      "Epoch 12/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6729 - val_accuracy: 0.6305\n",
      "Epoch 13/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6733 - val_accuracy: 0.6305\n",
      "Epoch 14/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6727 - val_accuracy: 0.6305\n",
      "Epoch 15/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6714 - val_accuracy: 0.6305\n",
      "Epoch 16/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5512 - val_loss: 0.6709 - val_accuracy: 0.6305\n",
      "Epoch 17/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6709 - val_accuracy: 0.6305\n",
      "Epoch 18/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6696 - val_accuracy: 0.6305\n",
      "Epoch 19/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6721 - val_accuracy: 0.6305\n",
      "Epoch 20/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5512 - val_loss: 0.6700 - val_accuracy: 0.6305\n",
      "Epoch 21/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5512 - val_loss: 0.6724 - val_accuracy: 0.6305\n",
      "Epoch 22/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6742 - val_accuracy: 0.6305\n",
      "Epoch 23/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5512 - val_loss: 0.6735 - val_accuracy: 0.6305\n",
      "Epoch 24/30\n",
      "197/197 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6705 - val_accuracy: 0.6305\n",
      "Epoch 25/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5512 - val_loss: 0.6713 - val_accuracy: 0.6305\n",
      "Epoch 26/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6691 - val_accuracy: 0.6305\n",
      "Epoch 27/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5512 - val_loss: 0.6697 - val_accuracy: 0.6305\n",
      "Epoch 28/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5512 - val_loss: 0.6704 - val_accuracy: 0.6305\n",
      "Epoch 29/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5512 - val_loss: 0.6698 - val_accuracy: 0.6305\n",
      "Epoch 30/30\n",
      "197/197 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5512 - val_loss: 0.6725 - val_accuracy: 0.6305\n",
      "Fold 2, Best Validation Loss: 0.6690797805786133, Best Validation Accuracy: 0.6305246353149414\n",
      "Epoch 1/30\n",
      "295/295 [==============================] - 2s 2ms/step - loss: 0.6832 - accuracy: 0.5761 - val_loss: 0.6185 - val_accuracy: 0.8369\n",
      "Epoch 2/30\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.6169 - val_accuracy: 0.8369\n",
      "Epoch 3/30\n",
      "295/295 [==============================] - 0s 975us/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.5933 - val_accuracy: 0.8369\n",
      "Epoch 4/30\n",
      "295/295 [==============================] - 0s 983us/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.5987 - val_accuracy: 0.8369\n",
      "Epoch 5/30\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5776 - val_loss: 0.5910 - val_accuracy: 0.8369\n",
      "Epoch 6/30\n",
      "295/295 [==============================] - 0s 988us/step - loss: 0.6812 - accuracy: 0.5776 - val_loss: 0.6040 - val_accuracy: 0.8369\n",
      "Epoch 7/30\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.6008 - val_accuracy: 0.8369\n",
      "Epoch 8/30\n",
      "295/295 [==============================] - 0s 972us/step - loss: 0.6813 - accuracy: 0.5776 - val_loss: 0.6028 - val_accuracy: 0.8369\n",
      "Epoch 9/30\n",
      "295/295 [==============================] - 0s 978us/step - loss: 0.6816 - accuracy: 0.5776 - val_loss: 0.6066 - val_accuracy: 0.8369\n",
      "Epoch 10/30\n",
      "295/295 [==============================] - 0s 983us/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5983 - val_accuracy: 0.8369\n",
      "Epoch 11/30\n",
      "295/295 [==============================] - 0s 980us/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.6112 - val_accuracy: 0.8369\n",
      "Epoch 12/30\n",
      "295/295 [==============================] - 0s 982us/step - loss: 0.6813 - accuracy: 0.5776 - val_loss: 0.6026 - val_accuracy: 0.8369\n",
      "Epoch 13/30\n",
      "295/295 [==============================] - 0s 972us/step - loss: 0.6812 - accuracy: 0.5776 - val_loss: 0.6089 - val_accuracy: 0.8369\n",
      "Epoch 14/30\n",
      "295/295 [==============================] - 0s 989us/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.5957 - val_accuracy: 0.8369\n",
      "Epoch 15/30\n",
      "295/295 [==============================] - 0s 978us/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6066 - val_accuracy: 0.8369\n",
      "Epoch 16/30\n",
      "295/295 [==============================] - 0s 982us/step - loss: 0.6812 - accuracy: 0.5776 - val_loss: 0.6026 - val_accuracy: 0.8369\n",
      "Epoch 17/30\n",
      "295/295 [==============================] - 0s 971us/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6072 - val_accuracy: 0.8369\n",
      "Epoch 18/30\n",
      "295/295 [==============================] - 0s 975us/step - loss: 0.6812 - accuracy: 0.5776 - val_loss: 0.5845 - val_accuracy: 0.8369\n",
      "Epoch 19/30\n",
      "295/295 [==============================] - 0s 981us/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5947 - val_accuracy: 0.8369\n",
      "Epoch 20/30\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.6024 - val_accuracy: 0.8369\n",
      "Epoch 21/30\n",
      "295/295 [==============================] - 0s 978us/step - loss: 0.6812 - accuracy: 0.5776 - val_loss: 0.6027 - val_accuracy: 0.8369\n",
      "Epoch 22/30\n",
      "295/295 [==============================] - 0s 979us/step - loss: 0.6813 - accuracy: 0.5776 - val_loss: 0.6009 - val_accuracy: 0.8369\n",
      "Epoch 23/30\n",
      "295/295 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5996 - val_accuracy: 0.8369\n",
      "Epoch 24/30\n",
      "295/295 [==============================] - 0s 976us/step - loss: 0.6813 - accuracy: 0.5776 - val_loss: 0.6026 - val_accuracy: 0.8369\n",
      "Epoch 25/30\n",
      "295/295 [==============================] - 0s 980us/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.5960 - val_accuracy: 0.8369\n",
      "Epoch 26/30\n",
      "295/295 [==============================] - 0s 975us/step - loss: 0.6813 - accuracy: 0.5776 - val_loss: 0.6030 - val_accuracy: 0.8369\n",
      "Epoch 27/30\n",
      "295/295 [==============================] - 0s 976us/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.5968 - val_accuracy: 0.8369\n",
      "Epoch 28/30\n",
      "295/295 [==============================] - 0s 979us/step - loss: 0.6812 - accuracy: 0.5776 - val_loss: 0.6046 - val_accuracy: 0.8369\n",
      "Epoch 29/30\n",
      "295/295 [==============================] - 0s 979us/step - loss: 0.6812 - accuracy: 0.5776 - val_loss: 0.6014 - val_accuracy: 0.8369\n",
      "Epoch 30/30\n",
      "295/295 [==============================] - 0s 971us/step - loss: 0.6812 - accuracy: 0.5776 - val_loss: 0.6027 - val_accuracy: 0.8369\n",
      "Fold 3, Best Validation Loss: 0.5844916105270386, Best Validation Accuracy: 0.8368839621543884\n",
      "Epoch 1/30\n",
      "394/394 [==============================] - 2s 2ms/step - loss: 0.6561 - accuracy: 0.6425 - val_loss: 0.5983 - val_accuracy: 0.7358\n",
      "Epoch 2/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6424 - val_loss: 0.6001 - val_accuracy: 0.7358\n",
      "Epoch 3/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6424 - val_loss: 0.6008 - val_accuracy: 0.7358\n",
      "Epoch 4/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6424 - val_loss: 0.6042 - val_accuracy: 0.7358\n",
      "Epoch 5/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6424 - val_loss: 0.5976 - val_accuracy: 0.7358\n",
      "Epoch 6/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6424 - val_loss: 0.5970 - val_accuracy: 0.7358\n",
      "Epoch 7/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6424 - val_loss: 0.5939 - val_accuracy: 0.7358\n",
      "Epoch 8/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6424 - val_loss: 0.5965 - val_accuracy: 0.7358\n",
      "Epoch 9/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6424 - val_loss: 0.5903 - val_accuracy: 0.7358\n",
      "Epoch 10/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6424 - val_loss: 0.5972 - val_accuracy: 0.7358\n",
      "Epoch 11/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6424 - val_loss: 0.5890 - val_accuracy: 0.7358\n",
      "Epoch 12/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6424 - val_loss: 0.5983 - val_accuracy: 0.7358\n",
      "Epoch 13/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6424 - val_loss: 0.5942 - val_accuracy: 0.7358\n",
      "Epoch 14/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6424 - val_loss: 0.6029 - val_accuracy: 0.7358\n",
      "Epoch 15/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6424 - val_loss: 0.5992 - val_accuracy: 0.7358\n",
      "Epoch 16/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6424 - val_loss: 0.5975 - val_accuracy: 0.7358\n",
      "Epoch 17/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6424 - val_loss: 0.5995 - val_accuracy: 0.7358\n",
      "Epoch 18/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6424 - val_loss: 0.5992 - val_accuracy: 0.7358\n",
      "Epoch 19/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6424 - val_loss: 0.5966 - val_accuracy: 0.7358\n",
      "Epoch 20/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6424 - val_loss: 0.6036 - val_accuracy: 0.7358\n",
      "Epoch 21/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6424 - val_loss: 0.6027 - val_accuracy: 0.7358\n",
      "Epoch 22/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6424 - val_loss: 0.5967 - val_accuracy: 0.7358\n",
      "Epoch 23/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6424 - val_loss: 0.5945 - val_accuracy: 0.7358\n",
      "Epoch 24/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5953 - val_accuracy: 0.7358\n",
      "Epoch 25/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6424 - val_loss: 0.5940 - val_accuracy: 0.7358\n",
      "Epoch 26/30\n",
      "394/394 [==============================] - 1s 1ms/step - loss: 0.6523 - accuracy: 0.6424 - val_loss: 0.5970 - val_accuracy: 0.7358\n",
      "Epoch 27/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6424 - val_loss: 0.5976 - val_accuracy: 0.7358\n",
      "Epoch 28/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6424 - val_loss: 0.5975 - val_accuracy: 0.7358\n",
      "Epoch 29/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6424 - val_loss: 0.5980 - val_accuracy: 0.7358\n",
      "Epoch 30/30\n",
      "394/394 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6424 - val_loss: 0.5979 - val_accuracy: 0.7358\n",
      "Fold 4, Best Validation Loss: 0.5889648199081421, Best Validation Accuracy: 0.7357710599899292\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 2s 2ms/step - loss: 0.6452 - accuracy: 0.6610 - val_loss: 0.6621 - val_accuracy: 0.6283\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6415 - accuracy: 0.6611 - val_loss: 0.6613 - val_accuracy: 0.6283\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6408 - accuracy: 0.6611 - val_loss: 0.6636 - val_accuracy: 0.6283\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6410 - accuracy: 0.6611 - val_loss: 0.6616 - val_accuracy: 0.6283\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6409 - accuracy: 0.6611 - val_loss: 0.6627 - val_accuracy: 0.6283\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6412 - accuracy: 0.6611 - val_loss: 0.6605 - val_accuracy: 0.6283\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6411 - accuracy: 0.6611 - val_loss: 0.6634 - val_accuracy: 0.6283\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6411 - accuracy: 0.6611 - val_loss: 0.6646 - val_accuracy: 0.6283\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6410 - accuracy: 0.6611 - val_loss: 0.6625 - val_accuracy: 0.6283\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6406 - accuracy: 0.6611 - val_loss: 0.6620 - val_accuracy: 0.6283\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6411 - accuracy: 0.6611 - val_loss: 0.6615 - val_accuracy: 0.6283\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6406 - accuracy: 0.6611 - val_loss: 0.6608 - val_accuracy: 0.6283\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6405 - accuracy: 0.6611 - val_loss: 0.6645 - val_accuracy: 0.6283\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6409 - accuracy: 0.6611 - val_loss: 0.6616 - val_accuracy: 0.6283\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6411 - accuracy: 0.6611 - val_loss: 0.6629 - val_accuracy: 0.6283\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6408 - accuracy: 0.6611 - val_loss: 0.6648 - val_accuracy: 0.6283\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6405 - accuracy: 0.6611 - val_loss: 0.6618 - val_accuracy: 0.6283\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6407 - accuracy: 0.6611 - val_loss: 0.6626 - val_accuracy: 0.6283\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6408 - accuracy: 0.6611 - val_loss: 0.6613 - val_accuracy: 0.6283\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6408 - accuracy: 0.6611 - val_loss: 0.6635 - val_accuracy: 0.6283\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6406 - accuracy: 0.6611 - val_loss: 0.6620 - val_accuracy: 0.6283\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6611 - val_loss: 0.6610 - val_accuracy: 0.6283\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6405 - accuracy: 0.6611 - val_loss: 0.6607 - val_accuracy: 0.6283\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6407 - accuracy: 0.6611 - val_loss: 0.6627 - val_accuracy: 0.6283\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6408 - accuracy: 0.6611 - val_loss: 0.6620 - val_accuracy: 0.6283\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6406 - accuracy: 0.6611 - val_loss: 0.6613 - val_accuracy: 0.6283\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6407 - accuracy: 0.6611 - val_loss: 0.6616 - val_accuracy: 0.6283\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6407 - accuracy: 0.6611 - val_loss: 0.6634 - val_accuracy: 0.6283\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6406 - accuracy: 0.6611 - val_loss: 0.6633 - val_accuracy: 0.6283\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6405 - accuracy: 0.6611 - val_loss: 0.6621 - val_accuracy: 0.6283\n",
      "Fold 5, Best Validation Loss: 0.6605350971221924, Best Validation Accuracy: 0.6282988786697388\n",
      "Mean Best Validation Loss: 0.6692818641662598\n",
      "Mean Best Validation Accuracy: 0.618759936094284\n",
      "48\n",
      "Epoch 1/30\n",
      "78/78 [==============================] - 6s 7ms/step - loss: 0.4837 - accuracy: 0.8992 - val_loss: 0.3663 - val_accuracy: 0.8947\n",
      "Epoch 2/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.9081 - val_loss: 0.3500 - val_accuracy: 0.8947\n",
      "Epoch 3/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.9081 - val_loss: 0.3474 - val_accuracy: 0.8947\n",
      "Epoch 4/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.9081 - val_loss: 0.3327 - val_accuracy: 0.8947\n",
      "Epoch 5/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.9081 - val_loss: 0.3182 - val_accuracy: 0.8947\n",
      "Epoch 6/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9081 - val_loss: 0.2923 - val_accuracy: 0.8955\n",
      "Epoch 7/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2412 - accuracy: 0.9150 - val_loss: 0.2845 - val_accuracy: 0.9024\n",
      "Epoch 8/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9319 - val_loss: 0.2818 - val_accuracy: 0.9113\n",
      "Epoch 9/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9383 - val_loss: 0.2725 - val_accuracy: 0.9230\n",
      "Epoch 10/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9440 - val_loss: 0.2683 - val_accuracy: 0.9230\n",
      "Epoch 11/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9488 - val_loss: 0.2577 - val_accuracy: 0.9314\n",
      "Epoch 12/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9520 - val_loss: 0.2505 - val_accuracy: 0.9302\n",
      "Epoch 13/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9512 - val_loss: 0.2315 - val_accuracy: 0.9330\n",
      "Epoch 14/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.9541 - val_loss: 0.2141 - val_accuracy: 0.9468\n",
      "Epoch 15/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.9516 - val_loss: 0.2004 - val_accuracy: 0.9439\n",
      "Epoch 16/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9581 - val_loss: 0.1874 - val_accuracy: 0.9463\n",
      "Epoch 17/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9597 - val_loss: 0.1803 - val_accuracy: 0.9480\n",
      "Epoch 18/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9593 - val_loss: 0.1770 - val_accuracy: 0.9468\n",
      "Epoch 19/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9581 - val_loss: 0.1773 - val_accuracy: 0.9476\n",
      "Epoch 20/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9605 - val_loss: 0.1911 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9581 - val_loss: 0.1736 - val_accuracy: 0.9459\n",
      "Epoch 22/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9597 - val_loss: 0.1727 - val_accuracy: 0.9435\n",
      "Epoch 23/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9601 - val_loss: 0.1733 - val_accuracy: 0.9459\n",
      "Epoch 24/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9569 - val_loss: 0.1715 - val_accuracy: 0.9468\n",
      "Epoch 25/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9601 - val_loss: 0.1729 - val_accuracy: 0.9435\n",
      "Epoch 26/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9641 - val_loss: 0.1762 - val_accuracy: 0.9411\n",
      "Epoch 27/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9585 - val_loss: 0.1696 - val_accuracy: 0.9468\n",
      "Epoch 28/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9605 - val_loss: 0.1691 - val_accuracy: 0.9463\n",
      "Epoch 29/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9593 - val_loss: 0.1640 - val_accuracy: 0.9443\n",
      "Epoch 30/30\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9613 - val_loss: 0.1694 - val_accuracy: 0.9411\n",
      "Fold 1, Best Validation Loss: 0.16399556398391724, Best Validation Accuracy: 0.9479628801345825\n",
      "Epoch 1/30\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.4185 - accuracy: 0.9000 - val_loss: 0.3156 - val_accuracy: 0.9109\n",
      "Epoch 2/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.9014 - val_loss: 0.3020 - val_accuracy: 0.9109\n",
      "Epoch 3/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.3059 - accuracy: 0.9016 - val_loss: 0.2605 - val_accuracy: 0.9109\n",
      "Epoch 4/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2610 - accuracy: 0.9141 - val_loss: 0.2277 - val_accuracy: 0.9298\n",
      "Epoch 5/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9327 - val_loss: 0.2143 - val_accuracy: 0.9371\n",
      "Epoch 6/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9401 - val_loss: 0.1980 - val_accuracy: 0.9383\n",
      "Epoch 7/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.2016 - accuracy: 0.9450 - val_loss: 0.1792 - val_accuracy: 0.9423\n",
      "Epoch 8/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9488 - val_loss: 0.1519 - val_accuracy: 0.9568\n",
      "Epoch 9/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9512 - val_loss: 0.1458 - val_accuracy: 0.9564\n",
      "Epoch 10/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1628 - accuracy: 0.9472 - val_loss: 0.1532 - val_accuracy: 0.9552\n",
      "Epoch 11/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9500 - val_loss: 0.1433 - val_accuracy: 0.9548\n",
      "Epoch 12/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9508 - val_loss: 0.1420 - val_accuracy: 0.9564\n",
      "Epoch 13/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9512 - val_loss: 0.1409 - val_accuracy: 0.9572\n",
      "Epoch 14/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9494 - val_loss: 0.1420 - val_accuracy: 0.9556\n",
      "Epoch 15/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9498 - val_loss: 0.1358 - val_accuracy: 0.9540\n",
      "Epoch 16/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9494 - val_loss: 0.1384 - val_accuracy: 0.9556\n",
      "Epoch 17/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9502 - val_loss: 0.1441 - val_accuracy: 0.9516\n",
      "Epoch 18/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9504 - val_loss: 0.1299 - val_accuracy: 0.9568\n",
      "Epoch 19/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9500 - val_loss: 0.1260 - val_accuracy: 0.9556\n",
      "Epoch 20/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9482 - val_loss: 0.1240 - val_accuracy: 0.9532\n",
      "Epoch 21/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9512 - val_loss: 0.1210 - val_accuracy: 0.9560\n",
      "Epoch 22/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9486 - val_loss: 0.1239 - val_accuracy: 0.9556\n",
      "Epoch 23/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9498 - val_loss: 0.1167 - val_accuracy: 0.9572\n",
      "Epoch 24/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9494 - val_loss: 0.1208 - val_accuracy: 0.9548\n",
      "Epoch 25/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9514 - val_loss: 0.1263 - val_accuracy: 0.9544\n",
      "Epoch 26/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9526 - val_loss: 0.1111 - val_accuracy: 0.9556\n",
      "Epoch 27/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9534 - val_loss: 0.1138 - val_accuracy: 0.9572\n",
      "Epoch 28/30\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9558 - val_loss: 0.1077 - val_accuracy: 0.9560\n",
      "Epoch 29/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9571 - val_loss: 0.1055 - val_accuracy: 0.9589\n",
      "Epoch 30/30\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9591 - val_loss: 0.1080 - val_accuracy: 0.9572\n",
      "Fold 2, Best Validation Loss: 0.10545475035905838, Best Validation Accuracy: 0.9588543772697449\n",
      "Epoch 1/30\n",
      "233/233 [==============================] - 2s 3ms/step - loss: 0.3844 - accuracy: 0.9017 - val_loss: 0.3381 - val_accuracy: 0.8975\n",
      "Epoch 2/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.9046 - val_loss: 0.2939 - val_accuracy: 0.8975\n",
      "Epoch 3/30\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.9145 - val_loss: 0.2495 - val_accuracy: 0.9238\n",
      "Epoch 4/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9370 - val_loss: 0.2273 - val_accuracy: 0.9451\n",
      "Epoch 5/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.9456 - val_loss: 0.1906 - val_accuracy: 0.9468\n",
      "Epoch 6/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9505 - val_loss: 0.1887 - val_accuracy: 0.9387\n",
      "Epoch 7/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9513 - val_loss: 0.1803 - val_accuracy: 0.9472\n",
      "Epoch 8/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9527 - val_loss: 0.1850 - val_accuracy: 0.9427\n",
      "Epoch 9/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9503 - val_loss: 0.1827 - val_accuracy: 0.9468\n",
      "Epoch 10/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9528 - val_loss: 0.1824 - val_accuracy: 0.9455\n",
      "Epoch 11/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9499 - val_loss: 0.1799 - val_accuracy: 0.9451\n",
      "Epoch 12/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9523 - val_loss: 0.1785 - val_accuracy: 0.9468\n",
      "Epoch 13/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9500 - val_loss: 0.1802 - val_accuracy: 0.9472\n",
      "Epoch 14/30\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9495 - val_loss: 0.1779 - val_accuracy: 0.9472\n",
      "Epoch 15/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1365 - accuracy: 0.9513 - val_loss: 0.1764 - val_accuracy: 0.9468\n",
      "Epoch 16/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.9511 - val_loss: 0.1752 - val_accuracy: 0.9439\n",
      "Epoch 17/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9515 - val_loss: 0.1796 - val_accuracy: 0.9459\n",
      "Epoch 18/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9505 - val_loss: 0.1772 - val_accuracy: 0.9459\n",
      "Epoch 19/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9511 - val_loss: 0.1672 - val_accuracy: 0.9463\n",
      "Epoch 20/30\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9504 - val_loss: 0.1783 - val_accuracy: 0.9451\n",
      "Epoch 21/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9500 - val_loss: 0.1727 - val_accuracy: 0.9472\n",
      "Epoch 22/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9515 - val_loss: 0.1614 - val_accuracy: 0.9455\n",
      "Epoch 23/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9530 - val_loss: 0.1619 - val_accuracy: 0.9468\n",
      "Epoch 24/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9517 - val_loss: 0.1615 - val_accuracy: 0.9496\n",
      "Epoch 25/30\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9536 - val_loss: 0.1595 - val_accuracy: 0.9512\n",
      "Epoch 26/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9579 - val_loss: 0.1555 - val_accuracy: 0.9528\n",
      "Epoch 27/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9564 - val_loss: 0.1578 - val_accuracy: 0.9508\n",
      "Epoch 28/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9607 - val_loss: 0.1565 - val_accuracy: 0.9524\n",
      "Epoch 29/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9624 - val_loss: 0.1548 - val_accuracy: 0.9580\n",
      "Epoch 30/30\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9650 - val_loss: 0.1722 - val_accuracy: 0.9621\n",
      "Fold 3, Best Validation Loss: 0.15478409826755524, Best Validation Accuracy: 0.9620814919471741\n",
      "Epoch 1/30\n",
      "310/310 [==============================] - 2s 2ms/step - loss: 0.3726 - accuracy: 0.9017 - val_loss: 0.3219 - val_accuracy: 0.9020\n",
      "Epoch 2/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.2901 - accuracy: 0.9050 - val_loss: 0.2639 - val_accuracy: 0.9238\n",
      "Epoch 3/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9317 - val_loss: 0.2388 - val_accuracy: 0.9459\n",
      "Epoch 4/30\n",
      "310/310 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9445 - val_loss: 0.1852 - val_accuracy: 0.9463\n",
      "Epoch 5/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9502 - val_loss: 0.1707 - val_accuracy: 0.9431\n",
      "Epoch 6/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9479 - val_loss: 0.1675 - val_accuracy: 0.9463\n",
      "Epoch 7/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9501 - val_loss: 0.1656 - val_accuracy: 0.9443\n",
      "Epoch 8/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9493 - val_loss: 0.1581 - val_accuracy: 0.9463\n",
      "Epoch 9/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9496 - val_loss: 0.1580 - val_accuracy: 0.9463\n",
      "Epoch 10/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9492 - val_loss: 0.1527 - val_accuracy: 0.9463\n",
      "Epoch 11/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9486 - val_loss: 0.1459 - val_accuracy: 0.9451\n",
      "Epoch 12/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9492 - val_loss: 0.1575 - val_accuracy: 0.9399\n",
      "Epoch 13/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9501 - val_loss: 0.1385 - val_accuracy: 0.9463\n",
      "Epoch 14/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9499 - val_loss: 0.1312 - val_accuracy: 0.9451\n",
      "Epoch 15/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9495 - val_loss: 0.1311 - val_accuracy: 0.9463\n",
      "Epoch 16/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9517 - val_loss: 0.1224 - val_accuracy: 0.9463\n",
      "Epoch 17/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9531 - val_loss: 0.1498 - val_accuracy: 0.9395\n",
      "Epoch 18/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9538 - val_loss: 0.1156 - val_accuracy: 0.9492\n",
      "Epoch 19/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9571 - val_loss: 0.1103 - val_accuracy: 0.9528\n",
      "Epoch 20/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9601 - val_loss: 0.1086 - val_accuracy: 0.9609\n",
      "Epoch 21/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9627 - val_loss: 0.1045 - val_accuracy: 0.9593\n",
      "Epoch 22/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9632 - val_loss: 0.1047 - val_accuracy: 0.9669\n",
      "Epoch 23/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9660 - val_loss: 0.1107 - val_accuracy: 0.9657\n",
      "Epoch 24/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9678 - val_loss: 0.0996 - val_accuracy: 0.9689\n",
      "Epoch 25/30\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 0.1058 - accuracy: 0.9678 - val_loss: 0.0977 - val_accuracy: 0.9762\n",
      "Epoch 26/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9702 - val_loss: 0.0934 - val_accuracy: 0.9754\n",
      "Epoch 27/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9699 - val_loss: 0.0932 - val_accuracy: 0.9710\n",
      "Epoch 28/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9709 - val_loss: 0.0921 - val_accuracy: 0.9689\n",
      "Epoch 29/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9711 - val_loss: 0.0891 - val_accuracy: 0.9762\n",
      "Epoch 30/30\n",
      "310/310 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9725 - val_loss: 0.1016 - val_accuracy: 0.9710\n",
      "Fold 4, Best Validation Loss: 0.089125856757164, Best Validation Accuracy: 0.9762001037597656\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 2s 2ms/step - loss: 0.3580 - accuracy: 0.9013 - val_loss: 0.3356 - val_accuracy: 0.8866\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.2632 - accuracy: 0.9173 - val_loss: 0.2884 - val_accuracy: 0.9117\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.2224 - accuracy: 0.9392 - val_loss: 0.2249 - val_accuracy: 0.9411\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1754 - accuracy: 0.9472 - val_loss: 0.1876 - val_accuracy: 0.9403\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1674 - accuracy: 0.9476 - val_loss: 0.1940 - val_accuracy: 0.9310\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1625 - accuracy: 0.9476 - val_loss: 0.1763 - val_accuracy: 0.9359\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1603 - accuracy: 0.9475 - val_loss: 0.1749 - val_accuracy: 0.9355\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1559 - accuracy: 0.9483 - val_loss: 0.1722 - val_accuracy: 0.9338\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1521 - accuracy: 0.9474 - val_loss: 0.1650 - val_accuracy: 0.9355\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1469 - accuracy: 0.9472 - val_loss: 0.1628 - val_accuracy: 0.9355\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1412 - accuracy: 0.9468 - val_loss: 0.1498 - val_accuracy: 0.9399\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1376 - accuracy: 0.9478 - val_loss: 0.1538 - val_accuracy: 0.9355\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1346 - accuracy: 0.9472 - val_loss: 0.1399 - val_accuracy: 0.9423\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1276 - accuracy: 0.9503 - val_loss: 0.1352 - val_accuracy: 0.9399\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1242 - accuracy: 0.9502 - val_loss: 0.1363 - val_accuracy: 0.9423\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1220 - accuracy: 0.9527 - val_loss: 0.1342 - val_accuracy: 0.9455\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1189 - accuracy: 0.9582 - val_loss: 0.1253 - val_accuracy: 0.9463\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1146 - accuracy: 0.9622 - val_loss: 0.1219 - val_accuracy: 0.9633\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1116 - accuracy: 0.9648 - val_loss: 0.1173 - val_accuracy: 0.9572\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1071 - accuracy: 0.9671 - val_loss: 0.1184 - val_accuracy: 0.9548\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1074 - accuracy: 0.9678 - val_loss: 0.1124 - val_accuracy: 0.9609\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1053 - accuracy: 0.9699 - val_loss: 0.1105 - val_accuracy: 0.9609\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1013 - accuracy: 0.9710 - val_loss: 0.1077 - val_accuracy: 0.9746\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.0997 - accuracy: 0.9730 - val_loss: 0.1230 - val_accuracy: 0.9645\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.1006 - accuracy: 0.9725 - val_loss: 0.1238 - val_accuracy: 0.9589\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9716 - val_loss: 0.1009 - val_accuracy: 0.9754\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9718 - val_loss: 0.1036 - val_accuracy: 0.9697\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.0979 - accuracy: 0.9728 - val_loss: 0.1111 - val_accuracy: 0.9633\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.0951 - accuracy: 0.9741 - val_loss: 0.1010 - val_accuracy: 0.9714\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 1s 1ms/step - loss: 0.0936 - accuracy: 0.9746 - val_loss: 0.1004 - val_accuracy: 0.9706\n",
      "Fold 5, Best Validation Loss: 0.100429967045784, Best Validation Accuracy: 0.9753932952880859\n",
      "Mean Best Validation Loss: 0.12275804728269576\n",
      "Mean Best Validation Accuracy: 0.9640984296798706\n",
      "49\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 2s 119ms/step - loss: 0.6535 - accuracy: 0.7824 - val_loss: 0.5482 - val_accuracy: 0.9337\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.5026 - accuracy: 0.8529 - val_loss: 0.2707 - val_accuracy: 0.9337\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.4105 - accuracy: 0.8529 - val_loss: 0.2434 - val_accuracy: 0.9337\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4115 - accuracy: 0.8529 - val_loss: 0.2757 - val_accuracy: 0.9337\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.4036 - accuracy: 0.8529 - val_loss: 0.3082 - val_accuracy: 0.9337\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4004 - accuracy: 0.8529 - val_loss: 0.2653 - val_accuracy: 0.9337\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3931 - accuracy: 0.8529 - val_loss: 0.2401 - val_accuracy: 0.9337\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3670 - accuracy: 0.8529 - val_loss: 0.2540 - val_accuracy: 0.9337\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3308 - accuracy: 0.8529 - val_loss: 0.2010 - val_accuracy: 0.9337\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3067 - accuracy: 0.8647 - val_loss: 0.1840 - val_accuracy: 0.9337\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2751 - accuracy: 0.9353 - val_loss: 0.1728 - val_accuracy: 0.9639\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.2360 - accuracy: 0.9412 - val_loss: 0.1543 - val_accuracy: 0.9639\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.2219 - accuracy: 0.9529 - val_loss: 0.1452 - val_accuracy: 0.9639\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1972 - accuracy: 0.9471 - val_loss: 0.1428 - val_accuracy: 0.9578\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1978 - accuracy: 0.9412 - val_loss: 0.1251 - val_accuracy: 0.9639\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1680 - accuracy: 0.9529 - val_loss: 0.1287 - val_accuracy: 0.9639\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1874 - accuracy: 0.9412 - val_loss: 0.1150 - val_accuracy: 0.9639\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1656 - accuracy: 0.9529 - val_loss: 0.1450 - val_accuracy: 0.9277\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1806 - accuracy: 0.9353 - val_loss: 0.0960 - val_accuracy: 0.9639\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1565 - accuracy: 0.9412 - val_loss: 0.0916 - val_accuracy: 0.9639\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1489 - accuracy: 0.9529 - val_loss: 0.0859 - val_accuracy: 0.9639\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1090 - accuracy: 0.9588 - val_loss: 0.0746 - val_accuracy: 0.9639\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0861 - accuracy: 0.9647 - val_loss: 0.0656 - val_accuracy: 0.9699\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0924 - accuracy: 0.9882 - val_loss: 0.0614 - val_accuracy: 0.9819\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0745 - accuracy: 0.9765 - val_loss: 0.0698 - val_accuracy: 0.9819\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1141 - accuracy: 0.9647 - val_loss: 0.1140 - val_accuracy: 0.9940\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1188 - accuracy: 0.9529 - val_loss: 0.1440 - val_accuracy: 0.9639\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.2318 - accuracy: 0.9353 - val_loss: 0.1171 - val_accuracy: 0.9458\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1777 - accuracy: 0.9235 - val_loss: 0.1340 - val_accuracy: 0.9880\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1226 - accuracy: 0.9647 - val_loss: 0.0928 - val_accuracy: 0.9518\n",
      "Fold 1, Best Validation Loss: 0.06142174080014229, Best Validation Accuracy: 0.9939758777618408\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 73ms/step - loss: 0.6039 - accuracy: 0.8690 - val_loss: 0.4214 - val_accuracy: 0.8916\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.3723 - accuracy: 0.8929 - val_loss: 0.3442 - val_accuracy: 0.8916\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.3533 - accuracy: 0.8929 - val_loss: 0.3307 - val_accuracy: 0.8916\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.3358 - accuracy: 0.8929 - val_loss: 0.3273 - val_accuracy: 0.8916\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.3374 - accuracy: 0.8929 - val_loss: 0.3127 - val_accuracy: 0.8916\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.3199 - accuracy: 0.8929 - val_loss: 0.2856 - val_accuracy: 0.8916\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.2766 - accuracy: 0.8929 - val_loss: 0.2404 - val_accuracy: 0.8916\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.2343 - accuracy: 0.9137 - val_loss: 0.1845 - val_accuracy: 0.9639\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.2284 - accuracy: 0.9375 - val_loss: 0.1722 - val_accuracy: 0.9639\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1969 - accuracy: 0.9435 - val_loss: 0.1724 - val_accuracy: 0.9578\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1728 - accuracy: 0.9554 - val_loss: 0.1439 - val_accuracy: 0.9699\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.1557 - accuracy: 0.9583 - val_loss: 0.1324 - val_accuracy: 0.9699\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1432 - accuracy: 0.9583 - val_loss: 0.1267 - val_accuracy: 0.9699\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1401 - accuracy: 0.9583 - val_loss: 0.1212 - val_accuracy: 0.9699\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.1348 - accuracy: 0.9524 - val_loss: 0.1146 - val_accuracy: 0.9699\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1234 - accuracy: 0.9554 - val_loss: 0.0913 - val_accuracy: 0.9699\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1099 - accuracy: 0.9583 - val_loss: 0.1406 - val_accuracy: 0.9699\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1161 - accuracy: 0.9583 - val_loss: 0.0981 - val_accuracy: 0.9639\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.2752 - accuracy: 0.8929 - val_loss: 0.1031 - val_accuracy: 0.9639\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.2694 - accuracy: 0.9137 - val_loss: 0.1904 - val_accuracy: 0.9578\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.1716 - accuracy: 0.9524 - val_loss: 0.1488 - val_accuracy: 0.9699\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1542 - accuracy: 0.9524 - val_loss: 0.1245 - val_accuracy: 0.9699\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.1297 - accuracy: 0.9583 - val_loss: 0.1105 - val_accuracy: 0.9699\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.1171 - accuracy: 0.9583 - val_loss: 0.0983 - val_accuracy: 0.9699\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.1238 - accuracy: 0.9524 - val_loss: 0.0882 - val_accuracy: 0.9699\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1270 - accuracy: 0.9435 - val_loss: 0.0880 - val_accuracy: 0.9699\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1248 - accuracy: 0.9583 - val_loss: 0.1178 - val_accuracy: 0.9699\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1375 - accuracy: 0.9554 - val_loss: 0.1141 - val_accuracy: 0.9699\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.2204 - accuracy: 0.9315 - val_loss: 0.1131 - val_accuracy: 0.9699\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.1243 - accuracy: 0.9583 - val_loss: 0.2640 - val_accuracy: 0.9157\n",
      "Fold 2, Best Validation Loss: 0.08802587538957596, Best Validation Accuracy: 0.9698795080184937\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 2s 62ms/step - loss: 0.5368 - accuracy: 0.8805 - val_loss: 0.3487 - val_accuracy: 0.8976\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3443 - accuracy: 0.8924 - val_loss: 0.3197 - val_accuracy: 0.8976\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.3393 - accuracy: 0.8924 - val_loss: 0.3130 - val_accuracy: 0.8976\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.3193 - accuracy: 0.8924 - val_loss: 0.2971 - val_accuracy: 0.8976\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.2975 - accuracy: 0.8924 - val_loss: 0.2451 - val_accuracy: 0.8976\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.2153 - accuracy: 0.9203 - val_loss: 0.1712 - val_accuracy: 0.9337\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1794 - accuracy: 0.9542 - val_loss: 0.1249 - val_accuracy: 0.9699\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1897 - accuracy: 0.9363 - val_loss: 0.1242 - val_accuracy: 0.9639\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.3494 - accuracy: 0.8386 - val_loss: 0.1381 - val_accuracy: 0.9759\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.1847 - accuracy: 0.9602 - val_loss: 0.1337 - val_accuracy: 0.9699\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1542 - accuracy: 0.9622 - val_loss: 0.1162 - val_accuracy: 0.9759\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1316 - accuracy: 0.9622 - val_loss: 0.0897 - val_accuracy: 0.9759\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1016 - accuracy: 0.9622 - val_loss: 0.0738 - val_accuracy: 0.9759\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1013 - accuracy: 0.9602 - val_loss: 0.0822 - val_accuracy: 0.9759\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.0920 - accuracy: 0.9661 - val_loss: 0.0700 - val_accuracy: 0.9819\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.0874 - accuracy: 0.9701 - val_loss: 0.0699 - val_accuracy: 0.9819\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.0986 - accuracy: 0.9701 - val_loss: 0.0682 - val_accuracy: 0.9819\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.0685 - accuracy: 0.9861 - val_loss: 0.0744 - val_accuracy: 0.9759\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.0538 - accuracy: 0.9880 - val_loss: 0.0398 - val_accuracy: 0.9880\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.0465 - accuracy: 0.9900 - val_loss: 0.0375 - val_accuracy: 0.9940\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.0530 - accuracy: 0.9841 - val_loss: 0.0768 - val_accuracy: 0.9639\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1331 - accuracy: 0.9522 - val_loss: 0.1769 - val_accuracy: 0.9157\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1173 - accuracy: 0.9622 - val_loss: 0.0585 - val_accuracy: 0.9759\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.0743 - accuracy: 0.9661 - val_loss: 0.0600 - val_accuracy: 0.9880\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.0862 - accuracy: 0.9761 - val_loss: 0.1048 - val_accuracy: 0.9819\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1470 - accuracy: 0.9502 - val_loss: 0.0892 - val_accuracy: 0.9578\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3208 - accuracy: 0.8347 - val_loss: 0.1289 - val_accuracy: 0.9337\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.2358 - accuracy: 0.8625 - val_loss: 0.1489 - val_accuracy: 0.9096\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1230 - accuracy: 0.9522 - val_loss: 0.0655 - val_accuracy: 0.9880\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.0851 - accuracy: 0.9801 - val_loss: 0.0573 - val_accuracy: 0.9819\n",
      "Fold 3, Best Validation Loss: 0.03750475496053696, Best Validation Accuracy: 0.9939758777618408\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 3s 80ms/step - loss: 0.4886 - accuracy: 0.8593 - val_loss: 0.2077 - val_accuracy: 0.9458\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3510 - accuracy: 0.8937 - val_loss: 0.2267 - val_accuracy: 0.9458\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.3362 - accuracy: 0.8937 - val_loss: 0.2235 - val_accuracy: 0.9458\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.3228 - accuracy: 0.8937 - val_loss: 0.2115 - val_accuracy: 0.9458\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2706 - accuracy: 0.8967 - val_loss: 0.1929 - val_accuracy: 0.9458\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2307 - accuracy: 0.9401 - val_loss: 0.1228 - val_accuracy: 0.9819\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.1583 - accuracy: 0.9611 - val_loss: 0.0901 - val_accuracy: 0.9699\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.1167 - accuracy: 0.9656 - val_loss: 0.0819 - val_accuracy: 0.9819\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.1817 - accuracy: 0.9431 - val_loss: 0.0803 - val_accuracy: 0.9819\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.1523 - accuracy: 0.9506 - val_loss: 0.1083 - val_accuracy: 0.9699\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.1038 - accuracy: 0.9641 - val_loss: 0.0521 - val_accuracy: 0.9699\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0874 - accuracy: 0.9626 - val_loss: 0.0406 - val_accuracy: 0.9819\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0778 - accuracy: 0.9731 - val_loss: 0.0552 - val_accuracy: 0.9759\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.0754 - accuracy: 0.9746 - val_loss: 0.0569 - val_accuracy: 0.9759\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0657 - accuracy: 0.9760 - val_loss: 0.1317 - val_accuracy: 0.9217\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0626 - accuracy: 0.9760 - val_loss: 0.0439 - val_accuracy: 0.9819\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0658 - accuracy: 0.9790 - val_loss: 0.0275 - val_accuracy: 0.9880\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.0177 - val_accuracy: 0.9940\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.0394 - accuracy: 0.9880 - val_loss: 0.0250 - val_accuracy: 0.9880\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.0464 - accuracy: 0.9865 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.0580 - accuracy: 0.9790 - val_loss: 0.0569 - val_accuracy: 0.9880\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.0473 - accuracy: 0.9865 - val_loss: 0.0260 - val_accuracy: 0.9759\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.0503 - accuracy: 0.9835 - val_loss: 0.0473 - val_accuracy: 0.9880\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0318 - accuracy: 0.9910 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0340 - accuracy: 0.9865 - val_loss: 0.0159 - val_accuracy: 0.9940\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0386 - accuracy: 0.9835 - val_loss: 0.0512 - val_accuracy: 0.9819\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0654 - accuracy: 0.9746 - val_loss: 0.0866 - val_accuracy: 0.9337\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2631 - accuracy: 0.9266 - val_loss: 1.0159 - val_accuracy: 0.6928\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.5965 - accuracy: 0.8728 - val_loss: 0.2111 - val_accuracy: 0.9458\n",
      "Fold 4, Best Validation Loss: 0.007333623245358467, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "27/27 [==============================] - 3s 54ms/step - loss: 0.4180 - accuracy: 0.9029 - val_loss: 0.3455 - val_accuracy: 0.8976\n",
      "Epoch 2/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.3308 - accuracy: 0.9041 - val_loss: 0.3307 - val_accuracy: 0.8976\n",
      "Epoch 3/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.3187 - accuracy: 0.9041 - val_loss: 0.3305 - val_accuracy: 0.8976\n",
      "Epoch 4/30\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.3240 - accuracy: 0.9041 - val_loss: 0.3312 - val_accuracy: 0.8976\n",
      "Epoch 5/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.3246 - accuracy: 0.9041 - val_loss: 0.3304 - val_accuracy: 0.8976\n",
      "Epoch 6/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.3257 - accuracy: 0.9041 - val_loss: 0.3305 - val_accuracy: 0.8976\n",
      "Epoch 7/30\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.3182 - accuracy: 0.9041 - val_loss: 0.3321 - val_accuracy: 0.8976\n",
      "Epoch 8/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.3212 - accuracy: 0.9041 - val_loss: 0.3304 - val_accuracy: 0.8976\n",
      "Epoch 9/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.3208 - accuracy: 0.9041 - val_loss: 0.3303 - val_accuracy: 0.8976\n",
      "Epoch 10/30\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.3178 - accuracy: 0.9041 - val_loss: 0.3316 - val_accuracy: 0.8976\n",
      "Epoch 11/30\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.3156 - accuracy: 0.9041 - val_loss: 0.3306 - val_accuracy: 0.8976\n",
      "Epoch 12/30\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.3217 - accuracy: 0.9041 - val_loss: 0.3311 - val_accuracy: 0.8976\n",
      "Epoch 13/30\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.3179 - accuracy: 0.9041 - val_loss: 0.3273 - val_accuracy: 0.8976\n",
      "Epoch 14/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.3198 - accuracy: 0.9041 - val_loss: 0.3307 - val_accuracy: 0.8976\n",
      "Epoch 15/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.3201 - accuracy: 0.9041 - val_loss: 0.3310 - val_accuracy: 0.8976\n",
      "Epoch 16/30\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.3199 - accuracy: 0.9041 - val_loss: 0.3291 - val_accuracy: 0.8976\n",
      "Epoch 17/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.2988 - accuracy: 0.9125 - val_loss: 0.3366 - val_accuracy: 0.8976\n",
      "Epoch 18/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.2632 - accuracy: 0.9233 - val_loss: 0.1765 - val_accuracy: 0.9458\n",
      "Epoch 19/30\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1506 - accuracy: 0.9640 - val_loss: 0.2786 - val_accuracy: 0.9096\n",
      "Epoch 20/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1661 - accuracy: 0.9544 - val_loss: 0.2425 - val_accuracy: 0.9096\n",
      "Epoch 21/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1559 - accuracy: 0.9580 - val_loss: 0.1322 - val_accuracy: 0.9699\n",
      "Epoch 22/30\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1348 - accuracy: 0.9640 - val_loss: 0.1611 - val_accuracy: 0.9458\n",
      "Epoch 23/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1449 - accuracy: 0.9580 - val_loss: 0.1214 - val_accuracy: 0.9639\n",
      "Epoch 24/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1396 - accuracy: 0.9580 - val_loss: 0.1362 - val_accuracy: 0.9578\n",
      "Epoch 25/30\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1358 - accuracy: 0.9592 - val_loss: 0.1177 - val_accuracy: 0.9699\n",
      "Epoch 26/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1167 - accuracy: 0.9688 - val_loss: 0.1107 - val_accuracy: 0.9639\n",
      "Epoch 27/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1180 - accuracy: 0.9664 - val_loss: 0.1110 - val_accuracy: 0.9699\n",
      "Epoch 28/30\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1135 - accuracy: 0.9688 - val_loss: 0.1175 - val_accuracy: 0.9639\n",
      "Epoch 29/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1151 - accuracy: 0.9676 - val_loss: 0.1013 - val_accuracy: 0.9699\n",
      "Epoch 30/30\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1092 - accuracy: 0.9688 - val_loss: 0.0969 - val_accuracy: 0.9699\n",
      "Fold 5, Best Validation Loss: 0.09693453460931778, Best Validation Accuracy: 0.9698795080184937\n",
      "Mean Best Validation Loss: 0.05824410580098629\n",
      "Mean Best Validation Accuracy: 0.9855421543121338\n",
      "50\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 2s 222ms/step - loss: 0.6868 - accuracy: 0.9348 - val_loss: 0.6692 - val_accuracy: 0.9888\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.6606 - accuracy: 0.9348 - val_loss: 0.6296 - val_accuracy: 0.9888\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.6142 - accuracy: 0.9348 - val_loss: 0.5493 - val_accuracy: 0.9888\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.5176 - accuracy: 0.9348 - val_loss: 0.3610 - val_accuracy: 0.9888\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3104 - accuracy: 0.9348 - val_loss: 0.1051 - val_accuracy: 0.9888\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.2258 - accuracy: 0.9348 - val_loss: 0.0619 - val_accuracy: 0.9888\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2358 - accuracy: 0.9348 - val_loss: 0.0608 - val_accuracy: 0.9888\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.2065 - accuracy: 0.9348 - val_loss: 0.0621 - val_accuracy: 0.9888\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1935 - accuracy: 0.9348 - val_loss: 0.0682 - val_accuracy: 0.9888\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1009 - accuracy: 0.9565 - val_loss: 0.0538 - val_accuracy: 0.9888\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0508 - accuracy: 0.9891 - val_loss: 0.0427 - val_accuracy: 0.9888\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9888\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0813 - accuracy: 0.9891 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0849 - accuracy: 0.9891 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0812 - accuracy: 0.9891 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0895 - accuracy: 0.9783 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0988 - accuracy: 0.9783 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0953 - accuracy: 0.9783 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0840 - accuracy: 0.9783 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0388 - accuracy: 0.9891 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Fold 1, Best Validation Loss: 0.003787218825891614, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 2s 124ms/step - loss: 0.6747 - accuracy: 0.9061 - val_loss: 0.6573 - val_accuracy: 0.7865\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.5746 - accuracy: 0.9613 - val_loss: 0.5418 - val_accuracy: 0.7865\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.2283 - accuracy: 0.9613 - val_loss: 0.9823 - val_accuracy: 0.7865\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1933 - accuracy: 0.9613 - val_loss: 1.0529 - val_accuracy: 0.7865\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.1936 - accuracy: 0.9613 - val_loss: 0.9190 - val_accuracy: 0.7865\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1663 - accuracy: 0.9613 - val_loss: 0.8275 - val_accuracy: 0.7865\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1735 - accuracy: 0.9613 - val_loss: 0.7341 - val_accuracy: 0.7865\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1606 - accuracy: 0.9613 - val_loss: 0.6847 - val_accuracy: 0.7865\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1604 - accuracy: 0.9613 - val_loss: 0.6574 - val_accuracy: 0.7865\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1714 - accuracy: 0.9613 - val_loss: 0.6557 - val_accuracy: 0.8090\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1650 - accuracy: 0.9613 - val_loss: 0.6490 - val_accuracy: 0.8090\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.1563 - accuracy: 0.9613 - val_loss: 0.6473 - val_accuracy: 0.8090\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1624 - accuracy: 0.9613 - val_loss: 0.6356 - val_accuracy: 0.8090\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1684 - accuracy: 0.9613 - val_loss: 0.6430 - val_accuracy: 0.8090\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1670 - accuracy: 0.9613 - val_loss: 0.6463 - val_accuracy: 0.8090\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1614 - accuracy: 0.9613 - val_loss: 0.5933 - val_accuracy: 0.8090\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1558 - accuracy: 0.9613 - val_loss: 0.5172 - val_accuracy: 0.8202\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1519 - accuracy: 0.9613 - val_loss: 0.3553 - val_accuracy: 0.8876\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1199 - accuracy: 0.9613 - val_loss: 0.2714 - val_accuracy: 0.9213\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0570 - accuracy: 0.9834 - val_loss: 0.2808 - val_accuracy: 0.9326\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9213\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.4270 - val_accuracy: 0.8764\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0855 - accuracy: 0.9613 - val_loss: 1.3591 - val_accuracy: 0.2135\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.4451 - accuracy: 0.7293 - val_loss: 0.4408 - val_accuracy: 0.8539\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0529 - accuracy: 0.9890 - val_loss: 0.3788 - val_accuracy: 0.8764\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0377 - accuracy: 0.9613 - val_loss: 0.3887 - val_accuracy: 0.8764\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0390 - accuracy: 0.9613 - val_loss: 0.3691 - val_accuracy: 0.8764\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0456 - accuracy: 0.9613 - val_loss: 0.4136 - val_accuracy: 0.8764\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0386 - accuracy: 0.9613 - val_loss: 0.3991 - val_accuracy: 0.8764\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0659 - accuracy: 0.9613 - val_loss: 0.7633 - val_accuracy: 0.8652\n",
      "Fold 2, Best Validation Loss: 0.27137690782546997, Best Validation Accuracy: 0.932584285736084\n",
      "Epoch 1/30\n",
      "9/9 [==============================] - 2s 101ms/step - loss: 0.6682 - accuracy: 0.8630 - val_loss: 0.6018 - val_accuracy: 0.9551\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.4923 - accuracy: 0.9037 - val_loss: 0.1747 - val_accuracy: 0.9551\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 0.2896 - accuracy: 0.9111 - val_loss: 0.1464 - val_accuracy: 0.9551\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 0.1800 - accuracy: 0.9370 - val_loss: 0.0707 - val_accuracy: 0.9775\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0918 - accuracy: 0.9667 - val_loss: 0.0314 - val_accuracy: 0.9888\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.0967 - accuracy: 0.9593 - val_loss: 0.0551 - val_accuracy: 0.9888\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0924 - accuracy: 0.9704 - val_loss: 0.0562 - val_accuracy: 0.9888\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 0.2187 - accuracy: 0.9556 - val_loss: 0.1518 - val_accuracy: 0.9663\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 0.1500 - accuracy: 0.9630 - val_loss: 0.0507 - val_accuracy: 0.9888\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 1s 56ms/step - loss: 0.1137 - accuracy: 0.9667 - val_loss: 0.0460 - val_accuracy: 0.9888\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.0986 - accuracy: 0.9741 - val_loss: 0.0505 - val_accuracy: 0.9888\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.1425 - accuracy: 0.9630 - val_loss: 0.1395 - val_accuracy: 0.9663\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.2451 - accuracy: 0.9370 - val_loss: 0.1377 - val_accuracy: 0.9663\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.2340 - accuracy: 0.9333 - val_loss: 0.1247 - val_accuracy: 0.9663\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.1847 - accuracy: 0.9444 - val_loss: 0.1220 - val_accuracy: 0.9663\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.1734 - accuracy: 0.9444 - val_loss: 0.1094 - val_accuracy: 0.9663\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.1271 - accuracy: 0.9630 - val_loss: 0.0547 - val_accuracy: 0.9888\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.1198 - accuracy: 0.9667 - val_loss: 0.1014 - val_accuracy: 0.9663\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.1581 - accuracy: 0.9481 - val_loss: 0.0860 - val_accuracy: 0.9663\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.1354 - accuracy: 0.9444 - val_loss: 0.0755 - val_accuracy: 0.9663\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.1153 - accuracy: 0.9481 - val_loss: 0.0606 - val_accuracy: 0.9663\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.1212 - accuracy: 0.9519 - val_loss: 0.0486 - val_accuracy: 0.9663\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.0940 - accuracy: 0.9741 - val_loss: 0.0366 - val_accuracy: 0.9775\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.0882 - accuracy: 0.9741 - val_loss: 0.1273 - val_accuracy: 0.9663\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.1040 - accuracy: 0.9741 - val_loss: 0.0531 - val_accuracy: 0.9888\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.1062 - accuracy: 0.9741 - val_loss: 0.0491 - val_accuracy: 0.9888\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.0802 - accuracy: 0.9852 - val_loss: 0.1185 - val_accuracy: 0.9663\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.1048 - accuracy: 0.9778 - val_loss: 0.0503 - val_accuracy: 0.9888\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.1218 - accuracy: 0.9704 - val_loss: 0.1290 - val_accuracy: 0.9663\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.1818 - accuracy: 0.9519 - val_loss: 0.1226 - val_accuracy: 0.9663\n",
      "Fold 3, Best Validation Loss: 0.031394798308610916, Best Validation Accuracy: 0.9887640476226807\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 2s 90ms/step - loss: 0.6395 - accuracy: 0.9164 - val_loss: 0.4373 - val_accuracy: 0.9775\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.3363 - accuracy: 0.9164 - val_loss: 0.1116 - val_accuracy: 0.9775\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.2022 - accuracy: 0.9359 - val_loss: 0.0940 - val_accuracy: 0.9775\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.1262 - accuracy: 0.9499 - val_loss: 0.0306 - val_accuracy: 0.9888\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.1165 - accuracy: 0.9749 - val_loss: 0.1199 - val_accuracy: 0.9775\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0956 - accuracy: 0.9749 - val_loss: 0.0560 - val_accuracy: 0.9775\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0877 - accuracy: 0.9749 - val_loss: 0.0386 - val_accuracy: 0.9888\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0884 - accuracy: 0.9721 - val_loss: 0.0417 - val_accuracy: 0.9888\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0887 - accuracy: 0.9749 - val_loss: 0.0338 - val_accuracy: 0.9775\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0865 - accuracy: 0.9721 - val_loss: 0.0453 - val_accuracy: 0.9775\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0825 - accuracy: 0.9721 - val_loss: 0.0311 - val_accuracy: 0.9888\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0745 - accuracy: 0.9721 - val_loss: 0.0269 - val_accuracy: 0.9888\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0736 - accuracy: 0.9666 - val_loss: 0.0249 - val_accuracy: 0.9888\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.1814 - accuracy: 0.9666 - val_loss: 0.1354 - val_accuracy: 0.9775\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.3453 - accuracy: 0.9304 - val_loss: 0.1086 - val_accuracy: 0.9775\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.2208 - accuracy: 0.9443 - val_loss: 0.1336 - val_accuracy: 0.9775\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.1484 - accuracy: 0.9694 - val_loss: 0.0903 - val_accuracy: 0.9775\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.1161 - accuracy: 0.9694 - val_loss: 0.0560 - val_accuracy: 0.9888\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0885 - accuracy: 0.9694 - val_loss: 0.0420 - val_accuracy: 0.9663\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0805 - accuracy: 0.9721 - val_loss: 0.0353 - val_accuracy: 0.9888\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0735 - accuracy: 0.9694 - val_loss: 0.0297 - val_accuracy: 0.9888\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0917 - accuracy: 0.9749 - val_loss: 0.0682 - val_accuracy: 0.9888\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.1506 - accuracy: 0.9694 - val_loss: 0.1182 - val_accuracy: 0.9775\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.3363 - accuracy: 0.9248 - val_loss: 0.1077 - val_accuracy: 0.9775\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.2984 - accuracy: 0.9192 - val_loss: 0.1403 - val_accuracy: 0.9775\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.2869 - accuracy: 0.9192 - val_loss: 0.1550 - val_accuracy: 0.9775\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.2842 - accuracy: 0.9192 - val_loss: 0.1414 - val_accuracy: 0.9775\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.2881 - accuracy: 0.9192 - val_loss: 0.1353 - val_accuracy: 0.9775\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.2807 - accuracy: 0.9192 - val_loss: 0.1342 - val_accuracy: 0.9775\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.2844 - accuracy: 0.9192 - val_loss: 0.1425 - val_accuracy: 0.9775\n",
      "Fold 4, Best Validation Loss: 0.02485794387757778, Best Validation Accuracy: 0.9887640476226807\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - 2s 72ms/step - loss: 0.5895 - accuracy: 0.9286 - val_loss: 0.3814 - val_accuracy: 0.7753\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1882 - accuracy: 0.9442 - val_loss: 0.2018 - val_accuracy: 0.9326\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0965 - accuracy: 0.9665 - val_loss: 0.1955 - val_accuracy: 0.8989\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0954 - accuracy: 0.9621 - val_loss: 0.5742 - val_accuracy: 0.8876\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1485 - accuracy: 0.9732 - val_loss: 0.1403 - val_accuracy: 0.9663\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1186 - accuracy: 0.9732 - val_loss: 0.2584 - val_accuracy: 0.9326\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1204 - accuracy: 0.9710 - val_loss: 0.1291 - val_accuracy: 0.9551\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0843 - accuracy: 0.9754 - val_loss: 0.0783 - val_accuracy: 0.9888\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0886 - accuracy: 0.9732 - val_loss: 0.0666 - val_accuracy: 0.9888\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0943 - accuracy: 0.9598 - val_loss: 0.2199 - val_accuracy: 0.8764\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0870 - accuracy: 0.9621 - val_loss: 0.1378 - val_accuracy: 0.9326\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0891 - accuracy: 0.9799 - val_loss: 0.3314 - val_accuracy: 0.9326\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.1004 - accuracy: 0.9754 - val_loss: 0.0865 - val_accuracy: 0.9663\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0772 - accuracy: 0.9754 - val_loss: 0.1116 - val_accuracy: 0.9551\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0738 - accuracy: 0.9710 - val_loss: 0.1196 - val_accuracy: 0.9551\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0705 - accuracy: 0.9710 - val_loss: 0.1070 - val_accuracy: 0.9551\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.0664 - accuracy: 0.9732 - val_loss: 0.1138 - val_accuracy: 0.9438\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.0641 - accuracy: 0.9732 - val_loss: 0.1250 - val_accuracy: 0.9326\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.0615 - accuracy: 0.9732 - val_loss: 0.1140 - val_accuracy: 0.9326\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0728 - accuracy: 0.9732 - val_loss: 0.1101 - val_accuracy: 0.9326\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0757 - accuracy: 0.9710 - val_loss: 0.1206 - val_accuracy: 0.9326\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0689 - accuracy: 0.9732 - val_loss: 0.1139 - val_accuracy: 0.9326\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0614 - accuracy: 0.9688 - val_loss: 0.1287 - val_accuracy: 0.9326\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0565 - accuracy: 0.9710 - val_loss: 0.0775 - val_accuracy: 0.9663\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1358 - accuracy: 0.9732 - val_loss: 0.4951 - val_accuracy: 0.9101\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1773 - accuracy: 0.9710 - val_loss: 0.2983 - val_accuracy: 0.9326\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.0959 - accuracy: 0.9821 - val_loss: 0.0986 - val_accuracy: 0.9663\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.1798 - accuracy: 0.9576 - val_loss: 0.2634 - val_accuracy: 0.9213\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1292 - accuracy: 0.9688 - val_loss: 0.2051 - val_accuracy: 0.9326\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.1722 - accuracy: 0.9576 - val_loss: 0.2498 - val_accuracy: 0.9213\n",
      "Fold 5, Best Validation Loss: 0.0665908232331276, Best Validation Accuracy: 0.9887640476226807\n",
      "Mean Best Validation Loss: 0.07960153841413557\n",
      "Mean Best Validation Accuracy: 0.9797752857208252\n",
      "51\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7076 - accuracy: 0.0333 - val_loss: 0.6886 - val_accuracy: 0.7667\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6887 - accuracy: 0.8667 - val_loss: 0.6719 - val_accuracy: 0.8667\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6723 - accuracy: 0.9667 - val_loss: 0.6557 - val_accuracy: 0.8667\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6549 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.8667\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6333 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.8667\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6150 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.8667\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5922 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.8667\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5647 - accuracy: 1.0000 - val_loss: 0.5589 - val_accuracy: 0.8667\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5370 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.8667\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5093 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.8667\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4584 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.8667\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4171 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.8667\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3589 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.8667\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2759 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.8667\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1889 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.8667\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1316 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.8667\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.5444 - val_accuracy: 0.8667\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.5865 - val_accuracy: 0.8667\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 0.8667\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.6577 - val_accuracy: 0.8667\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.8667\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8667\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.7457 - val_accuracy: 0.8667\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7717 - val_accuracy: 0.8667\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.8667\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.8667\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8393 - val_accuracy: 0.8667\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8586 - val_accuracy: 0.8667\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.8667\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8931 - val_accuracy: 0.8667\n",
      "Fold 1, Best Validation Loss: 0.43528175354003906, Best Validation Accuracy: 0.8666666746139526\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 2s 355ms/step - loss: 0.6894 - accuracy: 0.5500 - val_loss: 0.6667 - val_accuracy: 0.9667\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6605 - accuracy: 0.9333 - val_loss: 0.6366 - val_accuracy: 0.9667\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6296 - accuracy: 0.9333 - val_loss: 0.6000 - val_accuracy: 0.9667\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5903 - accuracy: 0.9333 - val_loss: 0.5500 - val_accuracy: 0.9667\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5373 - accuracy: 0.9333 - val_loss: 0.4757 - val_accuracy: 0.9667\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4598 - accuracy: 0.9333 - val_loss: 0.3629 - val_accuracy: 0.9667\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3880 - accuracy: 0.9333 - val_loss: 0.2280 - val_accuracy: 0.9667\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2914 - accuracy: 0.9333 - val_loss: 0.1574 - val_accuracy: 0.9667\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2603 - accuracy: 0.9333 - val_loss: 0.1467 - val_accuracy: 0.9667\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2777 - accuracy: 0.9333 - val_loss: 0.1465 - val_accuracy: 0.9667\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2627 - accuracy: 0.9333 - val_loss: 0.1472 - val_accuracy: 0.9667\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2555 - accuracy: 0.9333 - val_loss: 0.1484 - val_accuracy: 0.9667\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2433 - accuracy: 0.9333 - val_loss: 0.1515 - val_accuracy: 0.9667\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2527 - accuracy: 0.9333 - val_loss: 0.1555 - val_accuracy: 0.9667\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2308 - accuracy: 0.9333 - val_loss: 0.1582 - val_accuracy: 0.9667\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2415 - accuracy: 0.9333 - val_loss: 0.1604 - val_accuracy: 0.9667\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2437 - accuracy: 0.9333 - val_loss: 0.1612 - val_accuracy: 0.9667\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.2255 - accuracy: 0.9333 - val_loss: 0.1615 - val_accuracy: 0.9667\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2692 - accuracy: 0.9333 - val_loss: 0.1614 - val_accuracy: 0.9667\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2521 - accuracy: 0.9333 - val_loss: 0.1608 - val_accuracy: 0.9667\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2696 - accuracy: 0.9333 - val_loss: 0.1589 - val_accuracy: 0.9667\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2433 - accuracy: 0.9333 - val_loss: 0.1578 - val_accuracy: 0.9667\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2388 - accuracy: 0.9333 - val_loss: 0.1567 - val_accuracy: 0.9667\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2256 - accuracy: 0.9333 - val_loss: 0.1557 - val_accuracy: 0.9667\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2333 - accuracy: 0.9333 - val_loss: 0.1552 - val_accuracy: 0.9667\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2618 - accuracy: 0.9333 - val_loss: 0.1538 - val_accuracy: 0.9667\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2452 - accuracy: 0.9333 - val_loss: 0.1535 - val_accuracy: 0.9667\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2388 - accuracy: 0.9333 - val_loss: 0.1537 - val_accuracy: 0.9667\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2574 - accuracy: 0.9333 - val_loss: 0.1542 - val_accuracy: 0.9667\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2430 - accuracy: 0.9333 - val_loss: 0.1552 - val_accuracy: 0.9667\n",
      "Fold 2, Best Validation Loss: 0.14649908244609833, Best Validation Accuracy: 0.9666666388511658\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 2s 214ms/step - loss: 0.6673 - accuracy: 0.9000 - val_loss: 0.6328 - val_accuracy: 0.8333\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6122 - accuracy: 0.9444 - val_loss: 0.5677 - val_accuracy: 0.8333\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5222 - accuracy: 0.9444 - val_loss: 0.4894 - val_accuracy: 0.8333\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4001 - accuracy: 0.9444 - val_loss: 0.4870 - val_accuracy: 0.8333\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2757 - accuracy: 0.9444 - val_loss: 0.6097 - val_accuracy: 0.8333\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2570 - accuracy: 0.9444 - val_loss: 0.6836 - val_accuracy: 0.8333\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2497 - accuracy: 0.9444 - val_loss: 0.6692 - val_accuracy: 0.8333\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2163 - accuracy: 0.9444 - val_loss: 0.6355 - val_accuracy: 0.8333\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2386 - accuracy: 0.9444 - val_loss: 0.5957 - val_accuracy: 0.8333\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.2135 - accuracy: 0.9444 - val_loss: 0.5610 - val_accuracy: 0.8333\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2230 - accuracy: 0.9444 - val_loss: 0.5347 - val_accuracy: 0.8333\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.2144 - accuracy: 0.9444 - val_loss: 0.5172 - val_accuracy: 0.8333\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2301 - accuracy: 0.9444 - val_loss: 0.5055 - val_accuracy: 0.8333\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2251 - accuracy: 0.9444 - val_loss: 0.5063 - val_accuracy: 0.8333\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2206 - accuracy: 0.9444 - val_loss: 0.5116 - val_accuracy: 0.8333\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2134 - accuracy: 0.9444 - val_loss: 0.5178 - val_accuracy: 0.8333\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2207 - accuracy: 0.9444 - val_loss: 0.5281 - val_accuracy: 0.8333\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.2249 - accuracy: 0.9444 - val_loss: 0.5380 - val_accuracy: 0.8333\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2213 - accuracy: 0.9444 - val_loss: 0.5421 - val_accuracy: 0.8333\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2153 - accuracy: 0.9444 - val_loss: 0.5447 - val_accuracy: 0.8333\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2018 - accuracy: 0.9444 - val_loss: 0.5461 - val_accuracy: 0.8333\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2144 - accuracy: 0.9444 - val_loss: 0.5422 - val_accuracy: 0.8333\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2149 - accuracy: 0.9444 - val_loss: 0.5346 - val_accuracy: 0.8333\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2137 - accuracy: 0.9444 - val_loss: 0.5262 - val_accuracy: 0.8333\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2123 - accuracy: 0.9444 - val_loss: 0.5225 - val_accuracy: 0.8333\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2074 - accuracy: 0.9444 - val_loss: 0.5175 - val_accuracy: 0.8333\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2106 - accuracy: 0.9444 - val_loss: 0.5145 - val_accuracy: 0.8333\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2118 - accuracy: 0.9444 - val_loss: 0.5187 - val_accuracy: 0.8333\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2210 - accuracy: 0.9444 - val_loss: 0.5226 - val_accuracy: 0.8333\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2083 - accuracy: 0.9444 - val_loss: 0.5273 - val_accuracy: 0.8333\n",
      "Fold 3, Best Validation Loss: 0.48695164918899536, Best Validation Accuracy: 0.8333333134651184\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 2s 135ms/step - loss: 0.6787 - accuracy: 0.7917 - val_loss: 0.6470 - val_accuracy: 0.9667\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.6217 - accuracy: 0.9167 - val_loss: 0.5736 - val_accuracy: 0.9667\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5299 - accuracy: 0.9167 - val_loss: 0.3855 - val_accuracy: 0.9667\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3668 - accuracy: 0.9167 - val_loss: 0.1638 - val_accuracy: 0.9667\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3017 - accuracy: 0.9167 - val_loss: 0.1467 - val_accuracy: 0.9667\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3096 - accuracy: 0.9167 - val_loss: 0.1470 - val_accuracy: 0.9667\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3199 - accuracy: 0.9167 - val_loss: 0.1541 - val_accuracy: 0.9667\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2859 - accuracy: 0.9167 - val_loss: 0.1638 - val_accuracy: 0.9667\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2984 - accuracy: 0.9167 - val_loss: 0.1721 - val_accuracy: 0.9667\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3023 - accuracy: 0.9167 - val_loss: 0.1778 - val_accuracy: 0.9667\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2936 - accuracy: 0.9167 - val_loss: 0.1742 - val_accuracy: 0.9667\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2696 - accuracy: 0.9167 - val_loss: 0.1694 - val_accuracy: 0.9667\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2947 - accuracy: 0.9167 - val_loss: 0.1648 - val_accuracy: 0.9667\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2908 - accuracy: 0.9167 - val_loss: 0.1655 - val_accuracy: 0.9667\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3020 - accuracy: 0.9167 - val_loss: 0.1667 - val_accuracy: 0.9667\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2789 - accuracy: 0.9167 - val_loss: 0.1686 - val_accuracy: 0.9667\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2756 - accuracy: 0.9167 - val_loss: 0.1692 - val_accuracy: 0.9667\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2865 - accuracy: 0.9167 - val_loss: 0.1688 - val_accuracy: 0.9667\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2854 - accuracy: 0.9167 - val_loss: 0.1655 - val_accuracy: 0.9667\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2864 - accuracy: 0.9167 - val_loss: 0.1641 - val_accuracy: 0.9667\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2906 - accuracy: 0.9167 - val_loss: 0.1660 - val_accuracy: 0.9667\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2910 - accuracy: 0.9167 - val_loss: 0.1723 - val_accuracy: 0.9667\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2888 - accuracy: 0.9167 - val_loss: 0.1744 - val_accuracy: 0.9667\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2727 - accuracy: 0.9167 - val_loss: 0.1614 - val_accuracy: 0.9667\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2647 - accuracy: 0.9167 - val_loss: 0.1587 - val_accuracy: 0.9667\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2533 - accuracy: 0.9167 - val_loss: 0.1500 - val_accuracy: 0.9667\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2185 - accuracy: 0.9167 - val_loss: 0.1076 - val_accuracy: 0.9667\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2024 - accuracy: 0.9167 - val_loss: 0.0642 - val_accuracy: 0.9667\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1371 - accuracy: 0.9250 - val_loss: 0.0657 - val_accuracy: 0.9667\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1247 - accuracy: 0.9583 - val_loss: 0.0615 - val_accuracy: 0.9667\n",
      "Fold 4, Best Validation Loss: 0.06151950731873512, Best Validation Accuracy: 0.9666666388511658\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 2s 123ms/step - loss: 0.6658 - accuracy: 0.8800 - val_loss: 0.6426 - val_accuracy: 0.7667\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.5786 - accuracy: 0.9267 - val_loss: 0.5792 - val_accuracy: 0.7667\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4023 - accuracy: 0.9267 - val_loss: 0.7578 - val_accuracy: 0.7667\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2833 - accuracy: 0.9267 - val_loss: 0.9005 - val_accuracy: 0.7667\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2825 - accuracy: 0.9267 - val_loss: 0.8495 - val_accuracy: 0.7667\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2878 - accuracy: 0.9267 - val_loss: 0.7663 - val_accuracy: 0.7667\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2777 - accuracy: 0.9267 - val_loss: 0.7067 - val_accuracy: 0.7667\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2824 - accuracy: 0.9267 - val_loss: 0.6621 - val_accuracy: 0.7667\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2595 - accuracy: 0.9267 - val_loss: 0.6458 - val_accuracy: 0.7667\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2699 - accuracy: 0.9267 - val_loss: 0.6446 - val_accuracy: 0.7667\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2743 - accuracy: 0.9267 - val_loss: 0.6447 - val_accuracy: 0.7667\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2671 - accuracy: 0.9267 - val_loss: 0.6518 - val_accuracy: 0.7667\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2689 - accuracy: 0.9267 - val_loss: 0.6664 - val_accuracy: 0.7667\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2689 - accuracy: 0.9267 - val_loss: 0.6776 - val_accuracy: 0.7667\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2578 - accuracy: 0.9267 - val_loss: 0.6725 - val_accuracy: 0.7667\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2593 - accuracy: 0.9267 - val_loss: 0.6751 - val_accuracy: 0.7667\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2589 - accuracy: 0.9267 - val_loss: 0.6695 - val_accuracy: 0.7667\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2708 - accuracy: 0.9267 - val_loss: 0.6708 - val_accuracy: 0.7667\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2570 - accuracy: 0.9267 - val_loss: 0.6798 - val_accuracy: 0.7667\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2641 - accuracy: 0.9267 - val_loss: 0.6747 - val_accuracy: 0.7667\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2666 - accuracy: 0.9267 - val_loss: 0.6581 - val_accuracy: 0.7667\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2631 - accuracy: 0.9267 - val_loss: 0.6486 - val_accuracy: 0.7667\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2645 - accuracy: 0.9267 - val_loss: 0.6589 - val_accuracy: 0.7667\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.2612 - accuracy: 0.9267 - val_loss: 0.6543 - val_accuracy: 0.7667\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2776 - accuracy: 0.9267 - val_loss: 0.6500 - val_accuracy: 0.7667\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2710 - accuracy: 0.9267 - val_loss: 0.6537 - val_accuracy: 0.7667\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2729 - accuracy: 0.9267 - val_loss: 0.6519 - val_accuracy: 0.7667\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2624 - accuracy: 0.9267 - val_loss: 0.6610 - val_accuracy: 0.7667\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2671 - accuracy: 0.9267 - val_loss: 0.6719 - val_accuracy: 0.7667\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2613 - accuracy: 0.9267 - val_loss: 0.6773 - val_accuracy: 0.7667\n",
      "Fold 5, Best Validation Loss: 0.5791622996330261, Best Validation Accuracy: 0.7666666507720947\n",
      "Mean Best Validation Loss: 0.3418828584253788\n",
      "Mean Best Validation Accuracy: 0.8799999833106995\n",
      "52\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 2s 518ms/step - loss: 0.6858 - accuracy: 0.8222 - val_loss: 0.6660 - val_accuracy: 0.8049\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.6559 - accuracy: 0.9111 - val_loss: 0.6384 - val_accuracy: 0.8049\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.6194 - accuracy: 0.9111 - val_loss: 0.6033 - val_accuracy: 0.8049\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.5764 - accuracy: 0.9111 - val_loss: 0.5556 - val_accuracy: 0.8049\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 0.5070 - accuracy: 0.9111 - val_loss: 0.4940 - val_accuracy: 0.8049\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 234ms/step - loss: 0.4213 - accuracy: 0.9111 - val_loss: 0.4552 - val_accuracy: 0.8049\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.3245 - accuracy: 0.9111 - val_loss: 0.5236 - val_accuracy: 0.8049\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.2980 - accuracy: 0.9111 - val_loss: 0.6180 - val_accuracy: 0.8049\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 0.3075 - accuracy: 0.9111 - val_loss: 0.6661 - val_accuracy: 0.8049\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 0.3226 - accuracy: 0.9111 - val_loss: 0.6852 - val_accuracy: 0.8049\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 0.3418 - accuracy: 0.9111 - val_loss: 0.6757 - val_accuracy: 0.8049\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 0.3412 - accuracy: 0.9111 - val_loss: 0.6429 - val_accuracy: 0.8049\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 0.3126 - accuracy: 0.9111 - val_loss: 0.6074 - val_accuracy: 0.8049\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 235ms/step - loss: 0.3268 - accuracy: 0.9111 - val_loss: 0.5735 - val_accuracy: 0.8049\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 0.3072 - accuracy: 0.9111 - val_loss: 0.5499 - val_accuracy: 0.8049\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 0.3191 - accuracy: 0.9111 - val_loss: 0.5352 - val_accuracy: 0.8049\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 0.3016 - accuracy: 0.9111 - val_loss: 0.5254 - val_accuracy: 0.8049\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 0.3056 - accuracy: 0.9111 - val_loss: 0.5205 - val_accuracy: 0.8049\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 0.3024 - accuracy: 0.9111 - val_loss: 0.5175 - val_accuracy: 0.8049\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.3245 - accuracy: 0.9111 - val_loss: 0.5167 - val_accuracy: 0.8049\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.3209 - accuracy: 0.9111 - val_loss: 0.5162 - val_accuracy: 0.8049\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 0.3255 - accuracy: 0.9111 - val_loss: 0.5188 - val_accuracy: 0.8049\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 0.3155 - accuracy: 0.9111 - val_loss: 0.5226 - val_accuracy: 0.8049\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.3171 - accuracy: 0.9111 - val_loss: 0.5294 - val_accuracy: 0.8049\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 0.3174 - accuracy: 0.9111 - val_loss: 0.5380 - val_accuracy: 0.8049\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 0.3064 - accuracy: 0.9111 - val_loss: 0.5475 - val_accuracy: 0.8049\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 0.2972 - accuracy: 0.9111 - val_loss: 0.5566 - val_accuracy: 0.8049\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.3089 - accuracy: 0.9111 - val_loss: 0.5622 - val_accuracy: 0.8049\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 0.2990 - accuracy: 0.9111 - val_loss: 0.5683 - val_accuracy: 0.8049\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 0.3061 - accuracy: 0.9111 - val_loss: 0.5723 - val_accuracy: 0.8049\n",
      "Fold 1, Best Validation Loss: 0.45519590377807617, Best Validation Accuracy: 0.8048780560493469\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 2s 366ms/step - loss: 0.6771 - accuracy: 0.8023 - val_loss: 0.6711 - val_accuracy: 0.6829\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 0.6305 - accuracy: 0.8605 - val_loss: 0.6469 - val_accuracy: 0.6829\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.5671 - accuracy: 0.8605 - val_loss: 0.6192 - val_accuracy: 0.6829\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 0.4770 - accuracy: 0.8605 - val_loss: 0.6462 - val_accuracy: 0.6829\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 0.4033 - accuracy: 0.8605 - val_loss: 0.8179 - val_accuracy: 0.6829\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 0.4322 - accuracy: 0.8605 - val_loss: 0.8477 - val_accuracy: 0.6829\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.4096 - accuracy: 0.8605 - val_loss: 0.7889 - val_accuracy: 0.6829\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 0.3987 - accuracy: 0.8605 - val_loss: 0.7185 - val_accuracy: 0.6829\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.3970 - accuracy: 0.8605 - val_loss: 0.6926 - val_accuracy: 0.6829\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.3993 - accuracy: 0.8605 - val_loss: 0.6748 - val_accuracy: 0.6829\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.4068 - accuracy: 0.8605 - val_loss: 0.6657 - val_accuracy: 0.6829\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 0.4059 - accuracy: 0.8605 - val_loss: 0.6696 - val_accuracy: 0.6829\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.4031 - accuracy: 0.8605 - val_loss: 0.6877 - val_accuracy: 0.6829\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.3825 - accuracy: 0.8605 - val_loss: 0.7042 - val_accuracy: 0.6829\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 0.3915 - accuracy: 0.8605 - val_loss: 0.7140 - val_accuracy: 0.6829\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.3930 - accuracy: 0.8605 - val_loss: 0.7146 - val_accuracy: 0.6829\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.3938 - accuracy: 0.8605 - val_loss: 0.6964 - val_accuracy: 0.6829\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 0.3816 - accuracy: 0.8605 - val_loss: 0.6701 - val_accuracy: 0.6829\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.3949 - accuracy: 0.8605 - val_loss: 0.6579 - val_accuracy: 0.6829\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.4012 - accuracy: 0.8605 - val_loss: 0.6619 - val_accuracy: 0.6829\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.3796 - accuracy: 0.8605 - val_loss: 0.7059 - val_accuracy: 0.6829\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.3868 - accuracy: 0.8605 - val_loss: 0.7361 - val_accuracy: 0.6829\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 1s 253ms/step - loss: 0.3628 - accuracy: 0.8605 - val_loss: 0.7165 - val_accuracy: 0.6829\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.3648 - accuracy: 0.8605 - val_loss: 0.6944 - val_accuracy: 0.6829\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 0.3670 - accuracy: 0.8605 - val_loss: 0.6827 - val_accuracy: 0.6829\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.3680 - accuracy: 0.8605 - val_loss: 0.7088 - val_accuracy: 0.6829\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.3705 - accuracy: 0.8605 - val_loss: 0.7411 - val_accuracy: 0.7073\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 0.3668 - accuracy: 0.8605 - val_loss: 0.6755 - val_accuracy: 0.7317\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.3601 - accuracy: 0.8721 - val_loss: 0.6708 - val_accuracy: 0.7561\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 0.3384 - accuracy: 0.8721 - val_loss: 0.6703 - val_accuracy: 0.7317\n",
      "Fold 2, Best Validation Loss: 0.6192295551300049, Best Validation Accuracy: 0.7560975551605225\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 2s 316ms/step - loss: 0.6747 - accuracy: 0.7717 - val_loss: 0.6265 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6307 - accuracy: 0.8031 - val_loss: 0.5223 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.5513 - accuracy: 0.8031 - val_loss: 0.2953 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.4680 - accuracy: 0.8031 - val_loss: 0.0961 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5418 - accuracy: 0.8031 - val_loss: 0.1106 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.4829 - accuracy: 0.8031 - val_loss: 0.2477 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.4837 - accuracy: 0.8031 - val_loss: 0.3086 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.4910 - accuracy: 0.8031 - val_loss: 0.2815 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.4726 - accuracy: 0.8031 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.4802 - accuracy: 0.8031 - val_loss: 0.1676 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.4805 - accuracy: 0.8031 - val_loss: 0.1517 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.4854 - accuracy: 0.8031 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.4706 - accuracy: 0.8031 - val_loss: 0.2132 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.4744 - accuracy: 0.8031 - val_loss: 0.2308 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.4706 - accuracy: 0.8031 - val_loss: 0.2249 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.4750 - accuracy: 0.8031 - val_loss: 0.1766 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.4609 - accuracy: 0.8031 - val_loss: 0.1584 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.4474 - accuracy: 0.8031 - val_loss: 0.1627 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.4263 - accuracy: 0.8189 - val_loss: 0.1543 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.4286 - accuracy: 0.8268 - val_loss: 0.1621 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.4133 - accuracy: 0.8740 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.4347 - accuracy: 0.8425 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.4088 - accuracy: 0.8504 - val_loss: 0.1394 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.3671 - accuracy: 0.8740 - val_loss: 0.2212 - val_accuracy: 0.9512\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.4402 - accuracy: 0.8346 - val_loss: 0.1854 - val_accuracy: 0.9512\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.4243 - accuracy: 0.8189 - val_loss: 0.1377 - val_accuracy: 0.9512\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.4488 - accuracy: 0.7323 - val_loss: 0.1087 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.4416 - accuracy: 0.8110 - val_loss: 0.0902 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.4952 - accuracy: 0.8031 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 0.5236 - accuracy: 0.8031 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Fold 3, Best Validation Loss: 0.0902169793844223, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 3s 256ms/step - loss: 0.6573 - accuracy: 0.8452 - val_loss: 0.5622 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 0.5612 - accuracy: 0.8512 - val_loss: 0.2647 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.4123 - accuracy: 0.8512 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 0.4248 - accuracy: 0.8512 - val_loss: 0.1818 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 0.4155 - accuracy: 0.8512 - val_loss: 0.1749 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.4096 - accuracy: 0.8512 - val_loss: 0.1470 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.4035 - accuracy: 0.8512 - val_loss: 0.1461 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.4076 - accuracy: 0.8512 - val_loss: 0.1406 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 0.4069 - accuracy: 0.8512 - val_loss: 0.1143 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.3961 - accuracy: 0.8512 - val_loss: 0.1348 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.4016 - accuracy: 0.8512 - val_loss: 0.1292 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.3999 - accuracy: 0.8512 - val_loss: 0.1062 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.4051 - accuracy: 0.8512 - val_loss: 0.1440 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.4062 - accuracy: 0.8512 - val_loss: 0.1568 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.4066 - accuracy: 0.8512 - val_loss: 0.1079 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 1s 193ms/step - loss: 0.3946 - accuracy: 0.8512 - val_loss: 0.1629 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.3906 - accuracy: 0.8512 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.3927 - accuracy: 0.8512 - val_loss: 0.1360 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.3806 - accuracy: 0.8631 - val_loss: 0.1060 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.3645 - accuracy: 0.8690 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 1s 212ms/step - loss: 0.3670 - accuracy: 0.8690 - val_loss: 0.1025 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.3613 - accuracy: 0.8929 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 1s 208ms/step - loss: 0.3348 - accuracy: 0.8929 - val_loss: 0.0984 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.3213 - accuracy: 0.8988 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.3975 - accuracy: 0.8631 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.4129 - accuracy: 0.8393 - val_loss: 0.0963 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 1s 198ms/step - loss: 0.3909 - accuracy: 0.8452 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.4048 - accuracy: 0.8512 - val_loss: 0.1785 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.4304 - accuracy: 0.8512 - val_loss: 0.1550 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 1s 199ms/step - loss: 0.4224 - accuracy: 0.8512 - val_loss: 0.1445 - val_accuracy: 1.0000\n",
      "Fold 4, Best Validation Loss: 0.06940843164920807, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "7/7 [==============================] - 3s 247ms/step - loss: 0.6425 - accuracy: 0.8804 - val_loss: 0.5188 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.4745 - accuracy: 0.8804 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 0.3701 - accuracy: 0.8804 - val_loss: 0.0691 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.3654 - accuracy: 0.8804 - val_loss: 0.1447 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.3634 - accuracy: 0.8804 - val_loss: 0.1762 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 1s 201ms/step - loss: 0.3666 - accuracy: 0.8804 - val_loss: 0.1353 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.3636 - accuracy: 0.8804 - val_loss: 0.1094 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.3566 - accuracy: 0.8804 - val_loss: 0.1290 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 1s 201ms/step - loss: 0.3538 - accuracy: 0.8804 - val_loss: 0.1282 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.3493 - accuracy: 0.8804 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.3387 - accuracy: 0.8804 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 1s 207ms/step - loss: 0.3341 - accuracy: 0.8804 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.3476 - accuracy: 0.8900 - val_loss: 0.1420 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.3372 - accuracy: 0.8947 - val_loss: 0.1138 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.3067 - accuracy: 0.8947 - val_loss: 0.1124 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.3053 - accuracy: 0.9091 - val_loss: 0.1708 - val_accuracy: 0.9268\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.3071 - accuracy: 0.9091 - val_loss: 0.1066 - val_accuracy: 0.9756\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 1s 202ms/step - loss: 0.3056 - accuracy: 0.9139 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 1s 213ms/step - loss: 0.2781 - accuracy: 0.9234 - val_loss: 0.0848 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 1s 210ms/step - loss: 0.2930 - accuracy: 0.9139 - val_loss: 0.1729 - val_accuracy: 0.9268\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 1s 210ms/step - loss: 0.2965 - accuracy: 0.9091 - val_loss: 0.1789 - val_accuracy: 0.9268\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.2899 - accuracy: 0.9139 - val_loss: 0.1063 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 1s 201ms/step - loss: 0.2963 - accuracy: 0.9091 - val_loss: 0.1704 - val_accuracy: 0.9268\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 1s 202ms/step - loss: 0.3009 - accuracy: 0.9282 - val_loss: 0.1548 - val_accuracy: 0.9268\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.2793 - accuracy: 0.9282 - val_loss: 0.1514 - val_accuracy: 0.9268\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.2775 - accuracy: 0.9234 - val_loss: 0.1473 - val_accuracy: 0.9512\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.2697 - accuracy: 0.9187 - val_loss: 0.1498 - val_accuracy: 0.9512\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.2680 - accuracy: 0.9187 - val_loss: 0.1888 - val_accuracy: 0.9268\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.2609 - accuracy: 0.9187 - val_loss: 0.2337 - val_accuracy: 0.9024\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.2685 - accuracy: 0.9187 - val_loss: 0.1487 - val_accuracy: 0.9512\n",
      "Fold 5, Best Validation Loss: 0.0691051185131073, Best Validation Accuracy: 1.0\n",
      "Mean Best Validation Loss: 0.26063119769096377\n",
      "Mean Best Validation Accuracy: 0.9121951222419739\n",
      "53\n",
      "Epoch 1/30\n",
      "163/163 [==============================] - 2s 7ms/step - loss: 0.3710 - accuracy: 0.8779 - val_loss: 0.3076 - val_accuracy: 0.9099\n",
      "Epoch 2/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.3352 - accuracy: 0.8926 - val_loss: 0.3095 - val_accuracy: 0.9099\n",
      "Epoch 3/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.3272 - accuracy: 0.8926 - val_loss: 0.3022 - val_accuracy: 0.9103\n",
      "Epoch 4/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2959 - accuracy: 0.8998 - val_loss: 0.3181 - val_accuracy: 0.9108\n",
      "Epoch 5/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2885 - accuracy: 0.9034 - val_loss: 0.3200 - val_accuracy: 0.9112\n",
      "Epoch 6/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2817 - accuracy: 0.9059 - val_loss: 0.3104 - val_accuracy: 0.9112\n",
      "Epoch 7/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2843 - accuracy: 0.9038 - val_loss: 0.2780 - val_accuracy: 0.9149\n",
      "Epoch 8/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2775 - accuracy: 0.9076 - val_loss: 0.3228 - val_accuracy: 0.9112\n",
      "Epoch 9/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2758 - accuracy: 0.9080 - val_loss: 0.3111 - val_accuracy: 0.9153\n",
      "Epoch 10/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2743 - accuracy: 0.9076 - val_loss: 0.2902 - val_accuracy: 0.9153\n",
      "Epoch 11/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2709 - accuracy: 0.9088 - val_loss: 0.2924 - val_accuracy: 0.9139\n",
      "Epoch 12/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2660 - accuracy: 0.9097 - val_loss: 0.2962 - val_accuracy: 0.9160\n",
      "Epoch 13/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2650 - accuracy: 0.9105 - val_loss: 0.2719 - val_accuracy: 0.9135\n",
      "Epoch 14/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2639 - accuracy: 0.9105 - val_loss: 0.2833 - val_accuracy: 0.9160\n",
      "Epoch 15/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2642 - accuracy: 0.9101 - val_loss: 0.2815 - val_accuracy: 0.9160\n",
      "Epoch 16/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2611 - accuracy: 0.9111 - val_loss: 0.2882 - val_accuracy: 0.9162\n",
      "Epoch 17/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2535 - accuracy: 0.9132 - val_loss: 0.3054 - val_accuracy: 0.9153\n",
      "Epoch 18/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2589 - accuracy: 0.9097 - val_loss: 0.2703 - val_accuracy: 0.9160\n",
      "Epoch 19/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2523 - accuracy: 0.9092 - val_loss: 0.2854 - val_accuracy: 0.9162\n",
      "Epoch 20/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2529 - accuracy: 0.9111 - val_loss: 0.3163 - val_accuracy: 0.9149\n",
      "Epoch 21/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2465 - accuracy: 0.9118 - val_loss: 0.3279 - val_accuracy: 0.9128\n",
      "Epoch 22/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2388 - accuracy: 0.9132 - val_loss: 0.3633 - val_accuracy: 0.9128\n",
      "Epoch 23/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2351 - accuracy: 0.9136 - val_loss: 0.3534 - val_accuracy: 0.9151\n",
      "Epoch 24/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2338 - accuracy: 0.9120 - val_loss: 0.3141 - val_accuracy: 0.9179\n",
      "Epoch 25/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2239 - accuracy: 0.9147 - val_loss: 0.2846 - val_accuracy: 0.9160\n",
      "Epoch 26/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2228 - accuracy: 0.9134 - val_loss: 0.3426 - val_accuracy: 0.9124\n",
      "Epoch 27/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2256 - accuracy: 0.9132 - val_loss: 0.3175 - val_accuracy: 0.9174\n",
      "Epoch 28/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2226 - accuracy: 0.9103 - val_loss: 0.2976 - val_accuracy: 0.9174\n",
      "Epoch 29/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9161 - val_loss: 0.2806 - val_accuracy: 0.9174\n",
      "Epoch 30/30\n",
      "163/163 [==============================] - 1s 5ms/step - loss: 0.2154 - accuracy: 0.9126 - val_loss: 0.3070 - val_accuracy: 0.9176\n",
      "Fold 1, Best Validation Loss: 0.2702780067920685, Best Validation Accuracy: 0.9179477095603943\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 3s 6ms/step - loss: 0.3328 - accuracy: 0.9013 - val_loss: 0.2715 - val_accuracy: 0.9247\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 2s 5ms/step - loss: 0.3154 - accuracy: 0.9014 - val_loss: 0.2766 - val_accuracy: 0.9247\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.3024 - accuracy: 0.9054 - val_loss: 0.2681 - val_accuracy: 0.9247\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2954 - accuracy: 0.9063 - val_loss: 0.2637 - val_accuracy: 0.9247\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2879 - accuracy: 0.9071 - val_loss: 0.2735 - val_accuracy: 0.9247\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2765 - accuracy: 0.9109 - val_loss: 0.2627 - val_accuracy: 0.9247\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2753 - accuracy: 0.9089 - val_loss: 0.3066 - val_accuracy: 0.9249\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2672 - accuracy: 0.9133 - val_loss: 0.2833 - val_accuracy: 0.9262\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.9117 - val_loss: 0.2836 - val_accuracy: 0.9247\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2558 - accuracy: 0.9134 - val_loss: 0.3111 - val_accuracy: 0.9247\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2529 - accuracy: 0.9119 - val_loss: 0.2657 - val_accuracy: 0.9247\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2431 - accuracy: 0.9161 - val_loss: 0.2388 - val_accuracy: 0.9251\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2375 - accuracy: 0.9153 - val_loss: 0.2363 - val_accuracy: 0.9252\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2325 - accuracy: 0.9166 - val_loss: 0.2449 - val_accuracy: 0.9262\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2309 - accuracy: 0.9146 - val_loss: 0.2469 - val_accuracy: 0.9254\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2210 - accuracy: 0.9158 - val_loss: 0.2213 - val_accuracy: 0.9276\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2213 - accuracy: 0.9163 - val_loss: 0.2203 - val_accuracy: 0.9258\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2189 - accuracy: 0.9161 - val_loss: 0.2577 - val_accuracy: 0.9189\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2136 - accuracy: 0.9168 - val_loss: 0.2564 - val_accuracy: 0.9258\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2149 - accuracy: 0.9168 - val_loss: 0.2480 - val_accuracy: 0.9268\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9170 - val_loss: 0.2257 - val_accuracy: 0.9260\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9211 - val_loss: 0.2271 - val_accuracy: 0.9260\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9209 - val_loss: 0.2550 - val_accuracy: 0.9289\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9191 - val_loss: 0.2718 - val_accuracy: 0.9256\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2016 - accuracy: 0.9193 - val_loss: 0.2186 - val_accuracy: 0.9254\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9205 - val_loss: 0.3331 - val_accuracy: 0.8909\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.2044 - accuracy: 0.9200 - val_loss: 0.2580 - val_accuracy: 0.9243\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.1939 - accuracy: 0.9215 - val_loss: 0.2820 - val_accuracy: 0.9283\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9214 - val_loss: 0.2555 - val_accuracy: 0.9283\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 1s 4ms/step - loss: 0.1918 - accuracy: 0.9216 - val_loss: 0.3882 - val_accuracy: 0.8985\n",
      "Fold 2, Best Validation Loss: 0.21860353648662567, Best Validation Accuracy: 0.9289008378982544\n",
      "Epoch 1/30\n",
      "488/488 [==============================] - 4s 5ms/step - loss: 0.3123 - accuracy: 0.9091 - val_loss: 0.2312 - val_accuracy: 0.9389\n",
      "Epoch 2/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.3017 - accuracy: 0.9091 - val_loss: 0.2285 - val_accuracy: 0.9389\n",
      "Epoch 3/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2920 - accuracy: 0.9110 - val_loss: 0.2245 - val_accuracy: 0.9389\n",
      "Epoch 4/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2792 - accuracy: 0.9139 - val_loss: 0.2469 - val_accuracy: 0.9389\n",
      "Epoch 5/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2727 - accuracy: 0.9135 - val_loss: 0.2198 - val_accuracy: 0.9412\n",
      "Epoch 6/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2627 - accuracy: 0.9151 - val_loss: 0.2073 - val_accuracy: 0.9399\n",
      "Epoch 7/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2553 - accuracy: 0.9153 - val_loss: 0.1940 - val_accuracy: 0.9400\n",
      "Epoch 8/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2441 - accuracy: 0.9169 - val_loss: 0.2359 - val_accuracy: 0.9391\n",
      "Epoch 9/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2346 - accuracy: 0.9194 - val_loss: 0.1949 - val_accuracy: 0.9399\n",
      "Epoch 10/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2288 - accuracy: 0.9183 - val_loss: 0.2061 - val_accuracy: 0.9397\n",
      "Epoch 11/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2236 - accuracy: 0.9201 - val_loss: 0.2587 - val_accuracy: 0.9347\n",
      "Epoch 12/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2165 - accuracy: 0.9210 - val_loss: 0.2415 - val_accuracy: 0.9395\n",
      "Epoch 13/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2111 - accuracy: 0.9240 - val_loss: 0.1974 - val_accuracy: 0.9397\n",
      "Epoch 14/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2092 - accuracy: 0.9229 - val_loss: 0.2585 - val_accuracy: 0.9302\n",
      "Epoch 15/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2047 - accuracy: 0.9249 - val_loss: 0.2166 - val_accuracy: 0.9395\n",
      "Epoch 16/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.2039 - accuracy: 0.9237 - val_loss: 0.2200 - val_accuracy: 0.9366\n",
      "Epoch 17/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1985 - accuracy: 0.9255 - val_loss: 0.2390 - val_accuracy: 0.9368\n",
      "Epoch 18/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1990 - accuracy: 0.9248 - val_loss: 0.2315 - val_accuracy: 0.9349\n",
      "Epoch 19/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1977 - accuracy: 0.9233 - val_loss: 0.2573 - val_accuracy: 0.9128\n",
      "Epoch 20/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1962 - accuracy: 0.9257 - val_loss: 0.2328 - val_accuracy: 0.9304\n",
      "Epoch 21/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1926 - accuracy: 0.9262 - val_loss: 0.1983 - val_accuracy: 0.9377\n",
      "Epoch 22/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1908 - accuracy: 0.9271 - val_loss: 0.2449 - val_accuracy: 0.9356\n",
      "Epoch 23/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1903 - accuracy: 0.9276 - val_loss: 0.2570 - val_accuracy: 0.9350\n",
      "Epoch 24/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1879 - accuracy: 0.9256 - val_loss: 0.1969 - val_accuracy: 0.9393\n",
      "Epoch 25/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1857 - accuracy: 0.9290 - val_loss: 0.1927 - val_accuracy: 0.9379\n",
      "Epoch 26/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1839 - accuracy: 0.9291 - val_loss: 0.2039 - val_accuracy: 0.9339\n",
      "Epoch 27/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1797 - accuracy: 0.9296 - val_loss: 0.1903 - val_accuracy: 0.9460\n",
      "Epoch 28/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1805 - accuracy: 0.9284 - val_loss: 0.2139 - val_accuracy: 0.9316\n",
      "Epoch 29/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1779 - accuracy: 0.9303 - val_loss: 0.2207 - val_accuracy: 0.9318\n",
      "Epoch 30/30\n",
      "488/488 [==============================] - 2s 4ms/step - loss: 0.1778 - accuracy: 0.9297 - val_loss: 0.2350 - val_accuracy: 0.9210\n",
      "Fold 3, Best Validation Loss: 0.19031481444835663, Best Validation Accuracy: 0.9460030794143677\n",
      "Epoch 1/30\n",
      "651/651 [==============================] - 4s 5ms/step - loss: 0.2925 - accuracy: 0.9153 - val_loss: 0.3240 - val_accuracy: 0.8972\n",
      "Epoch 2/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.2731 - accuracy: 0.9172 - val_loss: 0.3267 - val_accuracy: 0.8972\n",
      "Epoch 3/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.2585 - accuracy: 0.9199 - val_loss: 0.3711 - val_accuracy: 0.8972\n",
      "Epoch 4/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.2451 - accuracy: 0.9213 - val_loss: 0.3142 - val_accuracy: 0.8972\n",
      "Epoch 5/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.2329 - accuracy: 0.9240 - val_loss: 0.4106 - val_accuracy: 0.8972\n",
      "Epoch 6/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.2233 - accuracy: 0.9248 - val_loss: 0.3920 - val_accuracy: 0.8972\n",
      "Epoch 7/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.2176 - accuracy: 0.9259 - val_loss: 0.3111 - val_accuracy: 0.8976\n",
      "Epoch 8/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.2098 - accuracy: 0.9259 - val_loss: 0.3142 - val_accuracy: 0.8989\n",
      "Epoch 9/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.2075 - accuracy: 0.9265 - val_loss: 0.2916 - val_accuracy: 0.8993\n",
      "Epoch 10/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.2002 - accuracy: 0.9292 - val_loss: 0.3008 - val_accuracy: 0.8989\n",
      "Epoch 11/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1934 - accuracy: 0.9304 - val_loss: 0.2827 - val_accuracy: 0.9051\n",
      "Epoch 12/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1918 - accuracy: 0.9289 - val_loss: 0.3168 - val_accuracy: 0.8982\n",
      "Epoch 13/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1897 - accuracy: 0.9306 - val_loss: 0.3025 - val_accuracy: 0.9005\n",
      "Epoch 14/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1880 - accuracy: 0.9321 - val_loss: 0.2632 - val_accuracy: 0.9078\n",
      "Epoch 15/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1852 - accuracy: 0.9311 - val_loss: 0.2527 - val_accuracy: 0.9204\n",
      "Epoch 16/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1837 - accuracy: 0.9315 - val_loss: 0.2765 - val_accuracy: 0.9226\n",
      "Epoch 17/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1803 - accuracy: 0.9316 - val_loss: 0.3324 - val_accuracy: 0.9197\n",
      "Epoch 18/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1783 - accuracy: 0.9343 - val_loss: 0.2525 - val_accuracy: 0.9222\n",
      "Epoch 19/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1744 - accuracy: 0.9331 - val_loss: 0.2460 - val_accuracy: 0.9247\n",
      "Epoch 20/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1738 - accuracy: 0.9337 - val_loss: 0.2510 - val_accuracy: 0.9237\n",
      "Epoch 21/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1735 - accuracy: 0.9340 - val_loss: 0.2460 - val_accuracy: 0.9222\n",
      "Epoch 22/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1690 - accuracy: 0.9361 - val_loss: 0.2917 - val_accuracy: 0.9143\n",
      "Epoch 23/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1678 - accuracy: 0.9359 - val_loss: 0.2811 - val_accuracy: 0.9231\n",
      "Epoch 24/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1667 - accuracy: 0.9354 - val_loss: 0.3529 - val_accuracy: 0.9153\n",
      "Epoch 25/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1629 - accuracy: 0.9378 - val_loss: 0.2694 - val_accuracy: 0.9243\n",
      "Epoch 26/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1648 - accuracy: 0.9358 - val_loss: 0.2472 - val_accuracy: 0.9214\n",
      "Epoch 27/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1624 - accuracy: 0.9368 - val_loss: 0.2496 - val_accuracy: 0.9224\n",
      "Epoch 28/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1597 - accuracy: 0.9358 - val_loss: 0.2219 - val_accuracy: 0.9229\n",
      "Epoch 29/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1603 - accuracy: 0.9368 - val_loss: 0.2830 - val_accuracy: 0.9183\n",
      "Epoch 30/30\n",
      "651/651 [==============================] - 3s 4ms/step - loss: 0.1575 - accuracy: 0.9387 - val_loss: 0.3110 - val_accuracy: 0.9158\n",
      "Fold 4, Best Validation Loss: 0.22189119458198547, Best Validation Accuracy: 0.924673318862915\n",
      "Epoch 1/30\n",
      "814/814 [==============================] - 5s 5ms/step - loss: 0.3010 - accuracy: 0.9118 - val_loss: 0.4853 - val_accuracy: 0.8367\n",
      "Epoch 2/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2829 - accuracy: 0.9135 - val_loss: 0.4735 - val_accuracy: 0.8376\n",
      "Epoch 3/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2591 - accuracy: 0.9185 - val_loss: 0.4683 - val_accuracy: 0.8436\n",
      "Epoch 4/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2497 - accuracy: 0.9187 - val_loss: 0.3910 - val_accuracy: 0.8611\n",
      "Epoch 5/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2389 - accuracy: 0.9213 - val_loss: 0.4295 - val_accuracy: 0.8501\n",
      "Epoch 6/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2273 - accuracy: 0.9218 - val_loss: 0.3947 - val_accuracy: 0.8497\n",
      "Epoch 7/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2154 - accuracy: 0.9249 - val_loss: 0.3479 - val_accuracy: 0.8578\n",
      "Epoch 8/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2065 - accuracy: 0.9247 - val_loss: 0.3484 - val_accuracy: 0.8628\n",
      "Epoch 9/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.2013 - accuracy: 0.9225 - val_loss: 0.3465 - val_accuracy: 0.8530\n",
      "Epoch 10/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1950 - accuracy: 0.9257 - val_loss: 0.3273 - val_accuracy: 0.8601\n",
      "Epoch 11/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1903 - accuracy: 0.9260 - val_loss: 0.3277 - val_accuracy: 0.8618\n",
      "Epoch 12/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1878 - accuracy: 0.9270 - val_loss: 0.3061 - val_accuracy: 0.8699\n",
      "Epoch 13/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1863 - accuracy: 0.9284 - val_loss: 0.3017 - val_accuracy: 0.8839\n",
      "Epoch 14/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1838 - accuracy: 0.9280 - val_loss: 0.2976 - val_accuracy: 0.8693\n",
      "Epoch 15/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1826 - accuracy: 0.9284 - val_loss: 0.3097 - val_accuracy: 0.8691\n",
      "Epoch 16/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1789 - accuracy: 0.9308 - val_loss: 0.2833 - val_accuracy: 0.8805\n",
      "Epoch 17/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1775 - accuracy: 0.9289 - val_loss: 0.2908 - val_accuracy: 0.8768\n",
      "Epoch 18/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1764 - accuracy: 0.9298 - val_loss: 0.3311 - val_accuracy: 0.8691\n",
      "Epoch 19/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1732 - accuracy: 0.9311 - val_loss: 0.2596 - val_accuracy: 0.8972\n",
      "Epoch 20/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1708 - accuracy: 0.9311 - val_loss: 0.2628 - val_accuracy: 0.9008\n",
      "Epoch 21/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1671 - accuracy: 0.9328 - val_loss: 0.2518 - val_accuracy: 0.9060\n",
      "Epoch 22/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1631 - accuracy: 0.9334 - val_loss: 0.2511 - val_accuracy: 0.9055\n",
      "Epoch 23/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1618 - accuracy: 0.9337 - val_loss: 0.2753 - val_accuracy: 0.9018\n",
      "Epoch 24/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1563 - accuracy: 0.9354 - val_loss: 0.2454 - val_accuracy: 0.9122\n",
      "Epoch 25/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1534 - accuracy: 0.9374 - val_loss: 0.2503 - val_accuracy: 0.9101\n",
      "Epoch 26/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1518 - accuracy: 0.9385 - val_loss: 0.3155 - val_accuracy: 0.8786\n",
      "Epoch 27/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1476 - accuracy: 0.9393 - val_loss: 0.2257 - val_accuracy: 0.9174\n",
      "Epoch 28/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1434 - accuracy: 0.9426 - val_loss: 0.2303 - val_accuracy: 0.9204\n",
      "Epoch 29/30\n",
      "814/814 [==============================] - 3s 4ms/step - loss: 0.1393 - accuracy: 0.9433 - val_loss: 0.2869 - val_accuracy: 0.9062\n",
      "Epoch 30/30\n",
      "814/814 [==============================] - 4s 4ms/step - loss: 0.1366 - accuracy: 0.9435 - val_loss: 0.2568 - val_accuracy: 0.9103\n",
      "Fold 5, Best Validation Loss: 0.2257082462310791, Best Validation Accuracy: 0.9204457998275757\n",
      "Mean Best Validation Loss: 0.22535915970802306\n",
      "Mean Best Validation Accuracy: 0.9275941491127014\n",
      "54\n",
      "Epoch 1/30\n",
      "518/518 [==============================] - 3s 3ms/step - loss: 0.0368 - accuracy: 0.9999 - val_loss: 6.9126e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 5.8767e-05 - accuracy: 1.0000 - val_loss: 2.5242e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 2.7198e-05 - accuracy: 1.0000 - val_loss: 1.3939e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 1.6962e-05 - accuracy: 1.0000 - val_loss: 8.9188e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 1.1633e-05 - accuracy: 1.0000 - val_loss: 6.1756e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 8.2537e-06 - accuracy: 1.0000 - val_loss: 4.4996e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 6.3071e-06 - accuracy: 1.0000 - val_loss: 3.3494e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 4.7422e-06 - accuracy: 1.0000 - val_loss: 2.5443e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 3.7754e-06 - accuracy: 1.0000 - val_loss: 1.9396e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 2.8705e-06 - accuracy: 1.0000 - val_loss: 1.4956e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 2.3037e-06 - accuracy: 1.0000 - val_loss: 1.1507e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 1.8240e-06 - accuracy: 1.0000 - val_loss: 8.8520e-07 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 1.4152e-06 - accuracy: 1.0000 - val_loss: 6.8315e-07 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 1.1145e-06 - accuracy: 1.0000 - val_loss: 5.2639e-07 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 8.7814e-07 - accuracy: 1.0000 - val_loss: 4.0504e-07 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 6.6996e-07 - accuracy: 1.0000 - val_loss: 3.1298e-07 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 5.4943e-07 - accuracy: 1.0000 - val_loss: 2.3937e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 4.2504e-07 - accuracy: 1.0000 - val_loss: 1.8289e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 3.3427e-07 - accuracy: 1.0000 - val_loss: 1.3959e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 2.6304e-07 - accuracy: 1.0000 - val_loss: 1.0623e-07 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 2.0262e-07 - accuracy: 1.0000 - val_loss: 8.0900e-08 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 1.5700e-07 - accuracy: 1.0000 - val_loss: 6.1708e-08 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 1.2381e-07 - accuracy: 1.0000 - val_loss: 4.6872e-08 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 9.8202e-08 - accuracy: 1.0000 - val_loss: 3.5521e-08 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 7.4500e-08 - accuracy: 1.0000 - val_loss: 2.7050e-08 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 5.9033e-08 - accuracy: 1.0000 - val_loss: 2.0547e-08 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 4.5760e-08 - accuracy: 1.0000 - val_loss: 1.5616e-08 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 3.6153e-08 - accuracy: 1.0000 - val_loss: 1.1851e-08 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 2.7306e-08 - accuracy: 1.0000 - val_loss: 9.0743e-09 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 2.2118e-08 - accuracy: 1.0000 - val_loss: 6.8919e-09 - val_accuracy: 1.0000\n",
      "Fold 1, Best Validation Loss: 6.891907933237462e-09, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1036/1036 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.9494e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 2.5386e-05 - accuracy: 1.0000 - val_loss: 1.0328e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 1.1179e-05 - accuracy: 1.0000 - val_loss: 5.1455e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 6.2263e-06 - accuracy: 1.0000 - val_loss: 2.8333e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 3.6109e-06 - accuracy: 1.0000 - val_loss: 1.6386e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 2.1917e-06 - accuracy: 1.0000 - val_loss: 9.6031e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 1.3455e-06 - accuracy: 1.0000 - val_loss: 5.6320e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 8.0972e-07 - accuracy: 1.0000 - val_loss: 3.3231e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 5.0031e-07 - accuracy: 1.0000 - val_loss: 1.9376e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 3.1271e-07 - accuracy: 1.0000 - val_loss: 1.1152e-07 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8520e-07 - accuracy: 1.0000 - val_loss: 6.4745e-08 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 1.1396e-07 - accuracy: 1.0000 - val_loss: 3.7328e-08 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 6.9061e-08 - accuracy: 1.0000 - val_loss: 2.1464e-08 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 4.1563e-08 - accuracy: 1.0000 - val_loss: 1.2439e-08 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 2.5937e-08 - accuracy: 1.0000 - val_loss: 7.1466e-09 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5753e-08 - accuracy: 1.0000 - val_loss: 4.1571e-09 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 9.7114e-09 - accuracy: 1.0000 - val_loss: 2.4543e-09 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 6.3023e-09 - accuracy: 1.0000 - val_loss: 1.4602e-09 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 3.8293e-09 - accuracy: 1.0000 - val_loss: 9.1263e-10 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 2.6664e-09 - accuracy: 1.0000 - val_loss: 5.8046e-10 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7912e-09 - accuracy: 1.0000 - val_loss: 3.8828e-10 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 1.2927e-09 - accuracy: 1.0000 - val_loss: 2.7153e-10 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 9.8449e-10 - accuracy: 1.0000 - val_loss: 1.9812e-10 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 7.9649e-10 - accuracy: 1.0000 - val_loss: 1.4975e-10 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 5.9288e-10 - accuracy: 1.0000 - val_loss: 1.1922e-10 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 5.0054e-10 - accuracy: 1.0000 - val_loss: 9.7586e-11 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 4.1022e-10 - accuracy: 1.0000 - val_loss: 8.2342e-11 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 3.4733e-10 - accuracy: 1.0000 - val_loss: 7.1052e-11 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 3.3338e-10 - accuracy: 1.0000 - val_loss: 6.1710e-11 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1036/1036 [==============================] - 2s 2ms/step - loss: 2.9648e-10 - accuracy: 1.0000 - val_loss: 5.4404e-11 - val_accuracy: 1.0000\n",
      "Fold 2, Best Validation Loss: 5.440395009492782e-11, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1554/1554 [==============================] - 4s 2ms/step - loss: 0.0132 - accuracy: 0.9993 - val_loss: 3.9837 - val_accuracy: 0.6468\n",
      "Epoch 2/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.1298e-05 - accuracy: 1.0000 - val_loss: 4.3999 - val_accuracy: 0.6468\n",
      "Epoch 3/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 4.2469e-06 - accuracy: 1.0000 - val_loss: 4.7106 - val_accuracy: 0.6468\n",
      "Epoch 4/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.9500e-06 - accuracy: 1.0000 - val_loss: 5.0008 - val_accuracy: 0.6468\n",
      "Epoch 5/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 9.1978e-07 - accuracy: 1.0000 - val_loss: 5.2854 - val_accuracy: 0.6468\n",
      "Epoch 6/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 4.5315e-07 - accuracy: 1.0000 - val_loss: 5.5755 - val_accuracy: 0.6468\n",
      "Epoch 7/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 2.1507e-07 - accuracy: 1.0000 - val_loss: 5.8672 - val_accuracy: 0.6468\n",
      "Epoch 8/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.0270e-07 - accuracy: 1.0000 - val_loss: 6.1586 - val_accuracy: 0.6468\n",
      "Epoch 9/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 5.0173e-08 - accuracy: 1.0000 - val_loss: 6.4540 - val_accuracy: 0.6468\n",
      "Epoch 10/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 2.4013e-08 - accuracy: 1.0000 - val_loss: 6.7415 - val_accuracy: 0.6468\n",
      "Epoch 11/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.1822e-08 - accuracy: 1.0000 - val_loss: 7.0191 - val_accuracy: 0.6468\n",
      "Epoch 12/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 6.0746e-09 - accuracy: 1.0000 - val_loss: 7.2845 - val_accuracy: 0.6468\n",
      "Epoch 13/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 3.1471e-09 - accuracy: 1.0000 - val_loss: 7.5212 - val_accuracy: 0.6468\n",
      "Epoch 14/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.8157e-09 - accuracy: 1.0000 - val_loss: 7.7299 - val_accuracy: 0.6468\n",
      "Epoch 15/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.1970e-09 - accuracy: 1.0000 - val_loss: 7.9130 - val_accuracy: 0.6468\n",
      "Epoch 16/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 7.9730e-10 - accuracy: 1.0000 - val_loss: 8.0590 - val_accuracy: 0.6468\n",
      "Epoch 17/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 5.5892e-10 - accuracy: 1.0000 - val_loss: 8.1739 - val_accuracy: 0.6468\n",
      "Epoch 18/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 4.4352e-10 - accuracy: 1.0000 - val_loss: 8.2696 - val_accuracy: 0.6468\n",
      "Epoch 19/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 3.6497e-10 - accuracy: 1.0000 - val_loss: 8.3498 - val_accuracy: 0.6468\n",
      "Epoch 20/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 2.8828e-10 - accuracy: 1.0000 - val_loss: 8.4157 - val_accuracy: 0.6468\n",
      "Epoch 21/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 2.4291e-10 - accuracy: 1.0000 - val_loss: 8.4712 - val_accuracy: 0.6468\n",
      "Epoch 22/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 2.1269e-10 - accuracy: 1.0000 - val_loss: 8.5201 - val_accuracy: 0.6468\n",
      "Epoch 23/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.9827e-10 - accuracy: 1.0000 - val_loss: 8.5652 - val_accuracy: 0.6468\n",
      "Epoch 24/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.7484e-10 - accuracy: 1.0000 - val_loss: 8.6050 - val_accuracy: 0.6468\n",
      "Epoch 25/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.6393e-10 - accuracy: 1.0000 - val_loss: 8.6421 - val_accuracy: 0.6468\n",
      "Epoch 26/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.5590e-10 - accuracy: 1.0000 - val_loss: 8.6774 - val_accuracy: 0.6468\n",
      "Epoch 27/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.4657e-10 - accuracy: 1.0000 - val_loss: 8.7102 - val_accuracy: 0.6468\n",
      "Epoch 28/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.2772e-10 - accuracy: 1.0000 - val_loss: 8.7393 - val_accuracy: 0.6468\n",
      "Epoch 29/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.1592e-10 - accuracy: 1.0000 - val_loss: 8.7657 - val_accuracy: 0.6468\n",
      "Epoch 30/30\n",
      "1554/1554 [==============================] - 3s 2ms/step - loss: 1.0372e-10 - accuracy: 1.0000 - val_loss: 8.7895 - val_accuracy: 0.6468\n",
      "Fold 3, Best Validation Loss: 3.9837355613708496, Best Validation Accuracy: 0.6468067169189453\n",
      "Epoch 1/30\n",
      "2071/2071 [==============================] - 8s 2ms/step - loss: 0.3062 - accuracy: 0.9112 - val_loss: 2.4456 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.3005 - accuracy: 0.9117 - val_loss: 2.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.3006 - accuracy: 0.9117 - val_loss: 2.5104 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2999 - accuracy: 0.9117 - val_loss: 2.4632 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2998 - accuracy: 0.9117 - val_loss: 2.3118 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2991 - accuracy: 0.9117 - val_loss: 2.5104 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "2071/2071 [==============================] - 4s 2ms/step - loss: 0.2985 - accuracy: 0.9117 - val_loss: 2.3951 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2977 - accuracy: 0.9117 - val_loss: 2.3406 - val_accuracy: 4.2255e-04\n",
      "Epoch 9/30\n",
      "2071/2071 [==============================] - 4s 2ms/step - loss: 0.2973 - accuracy: 0.9117 - val_loss: 2.3720 - val_accuracy: 3.0182e-04\n",
      "Epoch 10/30\n",
      "2071/2071 [==============================] - 4s 2ms/step - loss: 0.2959 - accuracy: 0.9117 - val_loss: 2.3650 - val_accuracy: 3.6219e-04\n",
      "Epoch 11/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2917 - accuracy: 0.9117 - val_loss: 2.2986 - val_accuracy: 0.0030\n",
      "Epoch 12/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2880 - accuracy: 0.9117 - val_loss: 2.4842 - val_accuracy: 0.0015\n",
      "Epoch 13/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2862 - accuracy: 0.9120 - val_loss: 2.2152 - val_accuracy: 0.0102\n",
      "Epoch 14/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2834 - accuracy: 0.9119 - val_loss: 2.4284 - val_accuracy: 0.0047\n",
      "Epoch 15/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2763 - accuracy: 0.9113 - val_loss: 2.0951 - val_accuracy: 6.6401e-04\n",
      "Epoch 16/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2725 - accuracy: 0.9121 - val_loss: 2.2366 - val_accuracy: 6.6401e-04\n",
      "Epoch 17/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2703 - accuracy: 0.9120 - val_loss: 2.1673 - val_accuracy: 0.0014\n",
      "Epoch 18/30\n",
      "2071/2071 [==============================] - 4s 2ms/step - loss: 0.2684 - accuracy: 0.9118 - val_loss: 2.2444 - val_accuracy: 0.0019\n",
      "Epoch 19/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2665 - accuracy: 0.9119 - val_loss: 2.1369 - val_accuracy: 0.0022\n",
      "Epoch 20/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2643 - accuracy: 0.9121 - val_loss: 2.1157 - val_accuracy: 0.0093\n",
      "Epoch 21/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2623 - accuracy: 0.9122 - val_loss: 2.1493 - val_accuracy: 0.0086\n",
      "Epoch 22/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2611 - accuracy: 0.9126 - val_loss: 1.9642 - val_accuracy: 0.0121\n",
      "Epoch 23/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2591 - accuracy: 0.9122 - val_loss: 2.0129 - val_accuracy: 0.0113\n",
      "Epoch 24/30\n",
      "2071/2071 [==============================] - 4s 2ms/step - loss: 0.2584 - accuracy: 0.9127 - val_loss: 1.9914 - val_accuracy: 0.0420\n",
      "Epoch 25/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2569 - accuracy: 0.9132 - val_loss: 2.1445 - val_accuracy: 0.0134\n",
      "Epoch 26/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2562 - accuracy: 0.9130 - val_loss: 2.0418 - val_accuracy: 0.0287\n",
      "Epoch 27/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2559 - accuracy: 0.9126 - val_loss: 2.0599 - val_accuracy: 0.0435\n",
      "Epoch 28/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2551 - accuracy: 0.9132 - val_loss: 2.1370 - val_accuracy: 0.0375\n",
      "Epoch 29/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2558 - accuracy: 0.9137 - val_loss: 1.9788 - val_accuracy: 0.0333\n",
      "Epoch 30/30\n",
      "2071/2071 [==============================] - 3s 2ms/step - loss: 0.2544 - accuracy: 0.9139 - val_loss: 1.9553 - val_accuracy: 0.0400\n",
      "Fold 4, Best Validation Loss: 1.9553067684173584, Best Validation Accuracy: 0.04352287948131561\n",
      "Epoch 1/30\n",
      "2589/2589 [==============================] - 6s 2ms/step - loss: 0.5861 - accuracy: 0.7292 - val_loss: 1.2170 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.5845 - accuracy: 0.7294 - val_loss: 1.2537 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.5826 - accuracy: 0.7294 - val_loss: 1.3201 - val_accuracy: 0.0051\n",
      "Epoch 4/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7338 - val_loss: 1.2007 - val_accuracy: 0.0797\n",
      "Epoch 5/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.5524 - accuracy: 0.7344 - val_loss: 1.1665 - val_accuracy: 0.1295\n",
      "Epoch 6/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.5296 - accuracy: 0.7366 - val_loss: 1.1758 - val_accuracy: 0.2165\n",
      "Epoch 7/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.5151 - accuracy: 0.7411 - val_loss: 1.0936 - val_accuracy: 0.1393\n",
      "Epoch 8/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.5089 - accuracy: 0.7409 - val_loss: 1.1410 - val_accuracy: 0.1853\n",
      "Epoch 9/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.5044 - accuracy: 0.7469 - val_loss: 0.9988 - val_accuracy: 0.2694\n",
      "Epoch 10/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4992 - accuracy: 0.7528 - val_loss: 1.1149 - val_accuracy: 0.2211\n",
      "Epoch 11/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4942 - accuracy: 0.7572 - val_loss: 1.0137 - val_accuracy: 0.3143\n",
      "Epoch 12/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4908 - accuracy: 0.7597 - val_loss: 1.0945 - val_accuracy: 0.2862\n",
      "Epoch 13/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4885 - accuracy: 0.7601 - val_loss: 1.0031 - val_accuracy: 0.3580\n",
      "Epoch 14/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4858 - accuracy: 0.7630 - val_loss: 0.9915 - val_accuracy: 0.3184\n",
      "Epoch 15/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4843 - accuracy: 0.7641 - val_loss: 0.9952 - val_accuracy: 0.3579\n",
      "Epoch 16/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4833 - accuracy: 0.7651 - val_loss: 1.0892 - val_accuracy: 0.3312\n",
      "Epoch 17/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4818 - accuracy: 0.7656 - val_loss: 0.9894 - val_accuracy: 0.3861\n",
      "Epoch 18/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4811 - accuracy: 0.7662 - val_loss: 1.0325 - val_accuracy: 0.3654\n",
      "Epoch 19/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4798 - accuracy: 0.7672 - val_loss: 1.0220 - val_accuracy: 0.3797\n",
      "Epoch 20/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4790 - accuracy: 0.7672 - val_loss: 0.9760 - val_accuracy: 0.3843\n",
      "Epoch 21/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4783 - accuracy: 0.7667 - val_loss: 1.0698 - val_accuracy: 0.3208\n",
      "Epoch 22/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4764 - accuracy: 0.7686 - val_loss: 1.0109 - val_accuracy: 0.3819\n",
      "Epoch 23/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4769 - accuracy: 0.7678 - val_loss: 1.0406 - val_accuracy: 0.3627\n",
      "Epoch 24/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4755 - accuracy: 0.7694 - val_loss: 0.9392 - val_accuracy: 0.4468\n",
      "Epoch 25/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4754 - accuracy: 0.7703 - val_loss: 1.0311 - val_accuracy: 0.3714\n",
      "Epoch 26/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4745 - accuracy: 0.7709 - val_loss: 1.0213 - val_accuracy: 0.3807\n",
      "Epoch 27/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4745 - accuracy: 0.7695 - val_loss: 1.0179 - val_accuracy: 0.3604\n",
      "Epoch 28/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4742 - accuracy: 0.7709 - val_loss: 1.0185 - val_accuracy: 0.3736\n",
      "Epoch 29/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4730 - accuracy: 0.7702 - val_loss: 1.0015 - val_accuracy: 0.3997\n",
      "Epoch 30/30\n",
      "2589/2589 [==============================] - 4s 2ms/step - loss: 0.4720 - accuracy: 0.7720 - val_loss: 1.0036 - val_accuracy: 0.3691\n",
      "Fold 5, Best Validation Loss: 0.9392116665840149, Best Validation Accuracy: 0.4467584192752838\n",
      "Mean Best Validation Loss: 1.375650800663707\n",
      "Mean Best Validation Accuracy: 0.627417603135109\n",
      "56\n",
      "Epoch 1/30\n",
      "79/79 [==============================] - 2s 6ms/step - loss: 0.5482 - accuracy: 0.8484 - val_loss: 0.2856 - val_accuracy: 0.9424\n",
      "Epoch 2/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8524 - val_loss: 0.2540 - val_accuracy: 0.9424\n",
      "Epoch 3/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8524 - val_loss: 0.2545 - val_accuracy: 0.9424\n",
      "Epoch 4/30\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8524 - val_loss: 0.2625 - val_accuracy: 0.9424\n",
      "Epoch 5/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8524 - val_loss: 0.2404 - val_accuracy: 0.9424\n",
      "Epoch 6/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8524 - val_loss: 0.2514 - val_accuracy: 0.9424\n",
      "Epoch 7/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8528 - val_loss: 0.2240 - val_accuracy: 0.9424\n",
      "Epoch 8/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8532 - val_loss: 0.2222 - val_accuracy: 0.9424\n",
      "Epoch 9/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8532 - val_loss: 0.2219 - val_accuracy: 0.9424\n",
      "Epoch 10/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8532 - val_loss: 0.2300 - val_accuracy: 0.9424\n",
      "Epoch 11/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8532 - val_loss: 0.2171 - val_accuracy: 0.9424\n",
      "Epoch 12/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8528 - val_loss: 0.2204 - val_accuracy: 0.9424\n",
      "Epoch 13/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8528 - val_loss: 0.2170 - val_accuracy: 0.9424\n",
      "Epoch 14/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8524 - val_loss: 0.2067 - val_accuracy: 0.9424\n",
      "Epoch 15/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8524 - val_loss: 0.1966 - val_accuracy: 0.9424\n",
      "Epoch 16/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8524 - val_loss: 0.1806 - val_accuracy: 0.9424\n",
      "Epoch 17/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8524 - val_loss: 0.1568 - val_accuracy: 0.9424\n",
      "Epoch 18/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.8880 - val_loss: 0.1215 - val_accuracy: 0.9808\n",
      "Epoch 19/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9140 - val_loss: 0.0960 - val_accuracy: 0.9844\n",
      "Epoch 20/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9212 - val_loss: 0.0901 - val_accuracy: 0.9844\n",
      "Epoch 21/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9228 - val_loss: 0.0952 - val_accuracy: 0.9872\n",
      "Epoch 22/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9136 - val_loss: 0.0740 - val_accuracy: 0.9880\n",
      "Epoch 23/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9184 - val_loss: 0.0787 - val_accuracy: 0.9796\n",
      "Epoch 24/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9232 - val_loss: 0.0723 - val_accuracy: 0.9892\n",
      "Epoch 25/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9256 - val_loss: 0.0723 - val_accuracy: 0.9900\n",
      "Epoch 26/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9276 - val_loss: 0.0695 - val_accuracy: 0.9912\n",
      "Epoch 27/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9248 - val_loss: 0.0707 - val_accuracy: 0.9912\n",
      "Epoch 28/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9256 - val_loss: 0.0671 - val_accuracy: 0.9892\n",
      "Epoch 29/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9280 - val_loss: 0.0679 - val_accuracy: 0.9860\n",
      "Epoch 30/30\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9280 - val_loss: 0.0649 - val_accuracy: 0.9904\n",
      "Fold 1, Best Validation Loss: 0.0649275854229927, Best Validation Accuracy: 0.9911999702453613\n",
      "Epoch 1/30\n",
      "157/157 [==============================] - 2s 3ms/step - loss: 0.4202 - accuracy: 0.8960 - val_loss: 0.3171 - val_accuracy: 0.9080\n",
      "Epoch 2/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8974 - val_loss: 0.3072 - val_accuracy: 0.9080\n",
      "Epoch 3/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8974 - val_loss: 0.2950 - val_accuracy: 0.9080\n",
      "Epoch 4/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8976 - val_loss: 0.2944 - val_accuracy: 0.9080\n",
      "Epoch 5/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8976 - val_loss: 0.2894 - val_accuracy: 0.9080\n",
      "Epoch 6/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8974 - val_loss: 0.2874 - val_accuracy: 0.9080\n",
      "Epoch 7/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8976 - val_loss: 0.2831 - val_accuracy: 0.9080\n",
      "Epoch 8/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.8974 - val_loss: 0.2789 - val_accuracy: 0.9080\n",
      "Epoch 9/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8974 - val_loss: 0.2677 - val_accuracy: 0.9080\n",
      "Epoch 10/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.8974 - val_loss: 0.2504 - val_accuracy: 0.9080\n",
      "Epoch 11/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.8974 - val_loss: 0.2276 - val_accuracy: 0.9080\n",
      "Epoch 12/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2103 - accuracy: 0.8974 - val_loss: 0.1917 - val_accuracy: 0.9080\n",
      "Epoch 13/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.9108 - val_loss: 0.1299 - val_accuracy: 0.9704\n",
      "Epoch 14/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9532 - val_loss: 0.0858 - val_accuracy: 0.9660\n",
      "Epoch 15/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9562 - val_loss: 0.0933 - val_accuracy: 0.9740\n",
      "Epoch 16/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9572 - val_loss: 0.0859 - val_accuracy: 0.9788\n",
      "Epoch 17/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9584 - val_loss: 0.0816 - val_accuracy: 0.9836\n",
      "Epoch 18/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9586 - val_loss: 0.0858 - val_accuracy: 0.9812\n",
      "Epoch 19/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9620 - val_loss: 0.0783 - val_accuracy: 0.9776\n",
      "Epoch 20/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9610 - val_loss: 0.0809 - val_accuracy: 0.9824\n",
      "Epoch 21/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9608 - val_loss: 0.0764 - val_accuracy: 0.9840\n",
      "Epoch 22/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9626 - val_loss: 0.0709 - val_accuracy: 0.9812\n",
      "Epoch 23/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.9620 - val_loss: 0.0719 - val_accuracy: 0.9860\n",
      "Epoch 24/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.9626 - val_loss: 0.0685 - val_accuracy: 0.9848\n",
      "Epoch 25/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9632 - val_loss: 0.0713 - val_accuracy: 0.9792\n",
      "Epoch 26/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9656 - val_loss: 0.0656 - val_accuracy: 0.9848\n",
      "Epoch 27/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9656 - val_loss: 0.0582 - val_accuracy: 0.9828\n",
      "Epoch 28/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9650 - val_loss: 0.0616 - val_accuracy: 0.9868\n",
      "Epoch 29/30\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9638 - val_loss: 0.0533 - val_accuracy: 0.9856\n",
      "Epoch 30/30\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9644 - val_loss: 0.0772 - val_accuracy: 0.9736\n",
      "Fold 2, Best Validation Loss: 0.05327285826206207, Best Validation Accuracy: 0.9868000149726868\n",
      "Epoch 1/30\n",
      "235/235 [==============================] - 2s 3ms/step - loss: 0.3970 - accuracy: 0.8975 - val_loss: 0.3827 - val_accuracy: 0.8808\n",
      "Epoch 2/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.9009 - val_loss: 0.3439 - val_accuracy: 0.8808\n",
      "Epoch 3/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3001 - accuracy: 0.9009 - val_loss: 0.2745 - val_accuracy: 0.8808\n",
      "Epoch 4/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.9009 - val_loss: 0.2650 - val_accuracy: 0.8808\n",
      "Epoch 5/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2841 - accuracy: 0.9009 - val_loss: 0.2681 - val_accuracy: 0.8808\n",
      "Epoch 6/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.9009 - val_loss: 0.2467 - val_accuracy: 0.8808\n",
      "Epoch 7/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.9009 - val_loss: 0.2312 - val_accuracy: 0.8808\n",
      "Epoch 8/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.9009 - val_loss: 0.2074 - val_accuracy: 0.8808\n",
      "Epoch 9/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9091 - val_loss: 0.2003 - val_accuracy: 0.9092\n",
      "Epoch 10/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9605 - val_loss: 0.2653 - val_accuracy: 0.9104\n",
      "Epoch 11/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9645 - val_loss: 0.2270 - val_accuracy: 0.9244\n",
      "Epoch 12/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9647 - val_loss: 0.2357 - val_accuracy: 0.9240\n",
      "Epoch 13/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9677 - val_loss: 0.2576 - val_accuracy: 0.9164\n",
      "Epoch 14/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9664 - val_loss: 0.2307 - val_accuracy: 0.9208\n",
      "Epoch 15/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9683 - val_loss: 0.2259 - val_accuracy: 0.9200\n",
      "Epoch 16/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9689 - val_loss: 0.2397 - val_accuracy: 0.9212\n",
      "Epoch 17/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9687 - val_loss: 0.2146 - val_accuracy: 0.9260\n",
      "Epoch 18/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9689 - val_loss: 0.2156 - val_accuracy: 0.9268\n",
      "Epoch 19/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9692 - val_loss: 0.2140 - val_accuracy: 0.9264\n",
      "Epoch 20/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9692 - val_loss: 0.2021 - val_accuracy: 0.9320\n",
      "Epoch 21/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9713 - val_loss: 0.2159 - val_accuracy: 0.9248\n",
      "Epoch 22/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9707 - val_loss: 0.2044 - val_accuracy: 0.9328\n",
      "Epoch 23/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9715 - val_loss: 0.2065 - val_accuracy: 0.9268\n",
      "Epoch 24/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9719 - val_loss: 0.1898 - val_accuracy: 0.9316\n",
      "Epoch 25/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9712 - val_loss: 0.1901 - val_accuracy: 0.9328\n",
      "Epoch 26/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9717 - val_loss: 0.1822 - val_accuracy: 0.9320\n",
      "Epoch 27/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9724 - val_loss: 0.1791 - val_accuracy: 0.9336\n",
      "Epoch 28/30\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9739 - val_loss: 0.1766 - val_accuracy: 0.9324\n",
      "Epoch 29/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9732 - val_loss: 0.1523 - val_accuracy: 0.9280\n",
      "Epoch 30/30\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9736 - val_loss: 0.1557 - val_accuracy: 0.9328\n",
      "Fold 3, Best Validation Loss: 0.15228019654750824, Best Validation Accuracy: 0.9336000084877014\n",
      "Epoch 1/30\n",
      "313/313 [==============================] - 2s 2ms/step - loss: 0.3900 - accuracy: 0.8953 - val_loss: 0.3740 - val_accuracy: 0.8764\n",
      "Epoch 2/30\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8960 - val_loss: 0.3164 - val_accuracy: 0.8772\n",
      "Epoch 3/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.8963 - val_loss: 0.3094 - val_accuracy: 0.8772\n",
      "Epoch 4/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.8960 - val_loss: 0.2959 - val_accuracy: 0.8764\n",
      "Epoch 5/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.8959 - val_loss: 0.2383 - val_accuracy: 0.8764\n",
      "Epoch 6/30\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9256 - val_loss: 0.1495 - val_accuracy: 0.9360\n",
      "Epoch 7/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9470 - val_loss: 0.1433 - val_accuracy: 0.9452\n",
      "Epoch 8/30\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9519 - val_loss: 0.1357 - val_accuracy: 0.9516\n",
      "Epoch 9/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9514 - val_loss: 0.1329 - val_accuracy: 0.9516\n",
      "Epoch 10/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9523 - val_loss: 0.1290 - val_accuracy: 0.9480\n",
      "Epoch 11/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9541 - val_loss: 0.1254 - val_accuracy: 0.9584\n",
      "Epoch 12/30\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9553 - val_loss: 0.1448 - val_accuracy: 0.9372\n",
      "Epoch 13/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9560 - val_loss: 0.1249 - val_accuracy: 0.9556\n",
      "Epoch 14/30\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9578 - val_loss: 0.1239 - val_accuracy: 0.9492\n",
      "Epoch 15/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9574 - val_loss: 0.1181 - val_accuracy: 0.9552\n",
      "Epoch 16/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9574 - val_loss: 0.1226 - val_accuracy: 0.9564\n",
      "Epoch 17/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9583 - val_loss: 0.1122 - val_accuracy: 0.9568\n",
      "Epoch 18/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9586 - val_loss: 0.1130 - val_accuracy: 0.9596\n",
      "Epoch 19/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9588 - val_loss: 0.1094 - val_accuracy: 0.9532\n",
      "Epoch 20/30\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9578 - val_loss: 0.1089 - val_accuracy: 0.9592\n",
      "Epoch 21/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9580 - val_loss: 0.1361 - val_accuracy: 0.9516\n",
      "Epoch 22/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9604 - val_loss: 0.1064 - val_accuracy: 0.9552\n",
      "Epoch 23/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9608 - val_loss: 0.0930 - val_accuracy: 0.9592\n",
      "Epoch 24/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9602 - val_loss: 0.0861 - val_accuracy: 0.9600\n",
      "Epoch 25/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9603 - val_loss: 0.1509 - val_accuracy: 0.9296\n",
      "Epoch 26/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9598 - val_loss: 0.0851 - val_accuracy: 0.9604\n",
      "Epoch 27/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9607 - val_loss: 0.0793 - val_accuracy: 0.9640\n",
      "Epoch 28/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9622 - val_loss: 0.0839 - val_accuracy: 0.9532\n",
      "Epoch 29/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9645 - val_loss: 0.0731 - val_accuracy: 0.9616\n",
      "Epoch 30/30\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9660 - val_loss: 0.0681 - val_accuracy: 0.9656\n",
      "Fold 4, Best Validation Loss: 0.06813471764326096, Best Validation Accuracy: 0.9656000137329102\n",
      "Epoch 1/30\n",
      "391/391 [==============================] - 2s 2ms/step - loss: 0.3770 - accuracy: 0.8918 - val_loss: 0.2189 - val_accuracy: 0.9424\n",
      "Epoch 2/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2962 - accuracy: 0.8922 - val_loss: 0.2266 - val_accuracy: 0.9424\n",
      "Epoch 3/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2838 - accuracy: 0.8924 - val_loss: 0.2113 - val_accuracy: 0.9424\n",
      "Epoch 4/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.2478 - accuracy: 0.8922 - val_loss: 0.1330 - val_accuracy: 0.9424\n",
      "Epoch 5/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1575 - accuracy: 0.9422 - val_loss: 0.0684 - val_accuracy: 0.9828\n",
      "Epoch 6/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1388 - accuracy: 0.9473 - val_loss: 0.0682 - val_accuracy: 0.9808\n",
      "Epoch 7/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1341 - accuracy: 0.9509 - val_loss: 0.0570 - val_accuracy: 0.9896\n",
      "Epoch 8/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1317 - accuracy: 0.9516 - val_loss: 0.0561 - val_accuracy: 0.9904\n",
      "Epoch 9/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1304 - accuracy: 0.9516 - val_loss: 0.0556 - val_accuracy: 0.9896\n",
      "Epoch 10/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1305 - accuracy: 0.9529 - val_loss: 0.0531 - val_accuracy: 0.9920\n",
      "Epoch 11/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1257 - accuracy: 0.9534 - val_loss: 0.0559 - val_accuracy: 0.9852\n",
      "Epoch 12/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1220 - accuracy: 0.9549 - val_loss: 0.0474 - val_accuracy: 0.9932\n",
      "Epoch 13/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1216 - accuracy: 0.9548 - val_loss: 0.0490 - val_accuracy: 0.9916\n",
      "Epoch 14/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1173 - accuracy: 0.9546 - val_loss: 0.0383 - val_accuracy: 0.9936\n",
      "Epoch 15/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9565 - val_loss: 0.0583 - val_accuracy: 0.9936\n",
      "Epoch 16/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1076 - accuracy: 0.9579 - val_loss: 0.0360 - val_accuracy: 0.9960\n",
      "Epoch 17/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.1026 - accuracy: 0.9580 - val_loss: 0.0292 - val_accuracy: 0.9940\n",
      "Epoch 18/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0907 - accuracy: 0.9599 - val_loss: 0.0240 - val_accuracy: 0.9960\n",
      "Epoch 19/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0914 - accuracy: 0.9618 - val_loss: 0.0247 - val_accuracy: 0.9936\n",
      "Epoch 20/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0827 - accuracy: 0.9644 - val_loss: 0.0229 - val_accuracy: 0.9972\n",
      "Epoch 21/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0796 - accuracy: 0.9664 - val_loss: 0.0196 - val_accuracy: 0.9948\n",
      "Epoch 22/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0747 - accuracy: 0.9682 - val_loss: 0.0222 - val_accuracy: 0.9888\n",
      "Epoch 23/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0742 - accuracy: 0.9680 - val_loss: 0.0208 - val_accuracy: 0.9932\n",
      "Epoch 24/30\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9667 - val_loss: 0.0235 - val_accuracy: 0.9932\n",
      "Epoch 25/30\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0750 - accuracy: 0.9681 - val_loss: 0.0296 - val_accuracy: 0.9892\n",
      "Epoch 26/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0723 - accuracy: 0.9699 - val_loss: 0.0158 - val_accuracy: 0.9944\n",
      "Epoch 27/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0699 - accuracy: 0.9691 - val_loss: 0.0211 - val_accuracy: 0.9952\n",
      "Epoch 28/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0682 - accuracy: 0.9698 - val_loss: 0.0153 - val_accuracy: 0.9972\n",
      "Epoch 29/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0704 - accuracy: 0.9696 - val_loss: 0.0143 - val_accuracy: 0.9944\n",
      "Epoch 30/30\n",
      "391/391 [==============================] - 1s 1ms/step - loss: 0.0684 - accuracy: 0.9698 - val_loss: 0.0141 - val_accuracy: 0.9980\n",
      "Fold 5, Best Validation Loss: 0.0140608549118042, Best Validation Accuracy: 0.9980000257492065\n",
      "Mean Best Validation Loss: 0.07053524255752563\n",
      "Mean Best Validation Accuracy: 0.9750400066375733\n",
      "57\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 2s 4ms/step - loss: 0.4746 - accuracy: 0.8498 - val_loss: 0.2491 - val_accuracy: 0.9397\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8961 - val_loss: 0.2326 - val_accuracy: 0.9050\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.9015 - val_loss: 0.2217 - val_accuracy: 0.9399\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.8986 - val_loss: 0.2167 - val_accuracy: 0.9563\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.9055 - val_loss: 0.2271 - val_accuracy: 0.9241\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8949 - val_loss: 0.2209 - val_accuracy: 0.9449\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.9014 - val_loss: 0.2217 - val_accuracy: 0.9442\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.9043 - val_loss: 0.2355 - val_accuracy: 0.8945\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.9024 - val_loss: 0.2346 - val_accuracy: 0.8964\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8971 - val_loss: 0.2118 - val_accuracy: 0.9514\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.9021 - val_loss: 0.2343 - val_accuracy: 0.8971\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.9027 - val_loss: 0.2219 - val_accuracy: 0.9512\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.9026 - val_loss: 0.2173 - val_accuracy: 0.9584\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.9022 - val_loss: 0.2286 - val_accuracy: 0.9253\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.9005 - val_loss: 0.2265 - val_accuracy: 0.9420\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.8988 - val_loss: 0.2418 - val_accuracy: 0.8654\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8880 - val_loss: 0.2294 - val_accuracy: 0.9442\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.8925 - val_loss: 0.2285 - val_accuracy: 0.9541\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.8955 - val_loss: 0.2343 - val_accuracy: 0.9413\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8892 - val_loss: 0.2369 - val_accuracy: 0.9428\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.8971 - val_loss: 0.2423 - val_accuracy: 0.9098\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8942 - val_loss: 0.2565 - val_accuracy: 0.8226\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8783 - val_loss: 0.2450 - val_accuracy: 0.9517\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.8990 - val_loss: 0.2494 - val_accuracy: 0.9164\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9015 - val_loss: 0.2336 - val_accuracy: 0.9336\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9462 - val_loss: 0.1231 - val_accuracy: 0.9884\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9586 - val_loss: 0.1105 - val_accuracy: 0.9740\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9675 - val_loss: 0.0823 - val_accuracy: 0.9892\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9699 - val_loss: 0.0752 - val_accuracy: 0.9865\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9699 - val_loss: 0.0658 - val_accuracy: 0.9897\n",
      "Fold 1, Best Validation Loss: 0.06583476811647415, Best Validation Accuracy: 0.9897260069847107\n",
      "Epoch 1/30\n",
      "365/365 [==============================] - 2s 2ms/step - loss: 0.3360 - accuracy: 0.8976 - val_loss: 0.3804 - val_accuracy: 0.9089\n",
      "Epoch 2/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9138 - val_loss: 0.3952 - val_accuracy: 0.9089\n",
      "Epoch 3/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.2391 - accuracy: 0.9115 - val_loss: 0.3751 - val_accuracy: 0.9091\n",
      "Epoch 4/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.2383 - accuracy: 0.9128 - val_loss: 0.3903 - val_accuracy: 0.9089\n",
      "Epoch 5/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.2371 - accuracy: 0.9158 - val_loss: 0.3794 - val_accuracy: 0.9089\n",
      "Epoch 6/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.9129 - val_loss: 0.4126 - val_accuracy: 0.9089\n",
      "Epoch 7/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.2371 - accuracy: 0.9160 - val_loss: 0.3943 - val_accuracy: 0.9089\n",
      "Epoch 8/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.2366 - accuracy: 0.9154 - val_loss: 0.4030 - val_accuracy: 0.9089\n",
      "Epoch 9/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.2372 - accuracy: 0.9158 - val_loss: 0.3847 - val_accuracy: 0.9089\n",
      "Epoch 10/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9151 - val_loss: 0.3917 - val_accuracy: 0.9089\n",
      "Epoch 11/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.2354 - accuracy: 0.9200 - val_loss: 0.3979 - val_accuracy: 0.9089\n",
      "Epoch 12/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.9199 - val_loss: 0.4052 - val_accuracy: 0.9089\n",
      "Epoch 13/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.2345 - accuracy: 0.9201 - val_loss: 0.3787 - val_accuracy: 0.9089\n",
      "Epoch 14/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.2336 - accuracy: 0.9228 - val_loss: 0.4042 - val_accuracy: 0.9089\n",
      "Epoch 15/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.2280 - accuracy: 0.9277 - val_loss: 0.4129 - val_accuracy: 0.9089\n",
      "Epoch 16/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9386 - val_loss: 0.4209 - val_accuracy: 0.9089\n",
      "Epoch 17/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.1286 - accuracy: 0.9471 - val_loss: 0.4650 - val_accuracy: 0.9089\n",
      "Epoch 18/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9471 - val_loss: 0.4418 - val_accuracy: 0.9092\n",
      "Epoch 19/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.0986 - accuracy: 0.9485 - val_loss: 0.4309 - val_accuracy: 0.9094\n",
      "Epoch 20/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9567 - val_loss: 0.3991 - val_accuracy: 0.9094\n",
      "Epoch 21/30\n",
      "365/365 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9662 - val_loss: 0.3796 - val_accuracy: 0.9341\n",
      "Epoch 22/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9755 - val_loss: 0.3626 - val_accuracy: 0.9478\n",
      "Epoch 23/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.0641 - accuracy: 0.9810 - val_loss: 0.3579 - val_accuracy: 0.9416\n",
      "Epoch 24/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9814 - val_loss: 0.3483 - val_accuracy: 0.9387\n",
      "Epoch 25/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.0638 - accuracy: 0.9812 - val_loss: 0.3243 - val_accuracy: 0.9488\n",
      "Epoch 26/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.0592 - accuracy: 0.9830 - val_loss: 0.3274 - val_accuracy: 0.9461\n",
      "Epoch 27/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 0.9848 - val_loss: 0.3235 - val_accuracy: 0.9471\n",
      "Epoch 28/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9880 - val_loss: 0.3245 - val_accuracy: 0.9450\n",
      "Epoch 29/30\n",
      "365/365 [==============================] - 1s 1ms/step - loss: 0.0588 - accuracy: 0.9817 - val_loss: 0.3128 - val_accuracy: 0.9491\n",
      "Epoch 30/30\n",
      "365/365 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9844 - val_loss: 0.3201 - val_accuracy: 0.9495\n",
      "Fold 2, Best Validation Loss: 0.31281131505966187, Best Validation Accuracy: 0.9494863152503967\n",
      "Epoch 1/30\n",
      "548/548 [==============================] - 2s 2ms/step - loss: 0.3368 - accuracy: 0.9004 - val_loss: 0.3192 - val_accuracy: 0.9062\n",
      "Epoch 2/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.2778 - accuracy: 0.9024 - val_loss: 0.3195 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.2760 - accuracy: 0.9045 - val_loss: 0.3144 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.2746 - accuracy: 0.9109 - val_loss: 0.3148 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.2717 - accuracy: 0.9155 - val_loss: 0.3171 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.2664 - accuracy: 0.9254 - val_loss: 0.3220 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.2581 - accuracy: 0.9296 - val_loss: 0.3266 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.2362 - accuracy: 0.9328 - val_loss: 0.3042 - val_accuracy: 0.9060\n",
      "Epoch 9/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.2140 - accuracy: 0.9349 - val_loss: 0.2831 - val_accuracy: 0.9063\n",
      "Epoch 10/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.1995 - accuracy: 0.9356 - val_loss: 0.2609 - val_accuracy: 0.9065\n",
      "Epoch 11/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.1762 - accuracy: 0.9363 - val_loss: 0.2248 - val_accuracy: 0.9060\n",
      "Epoch 12/30\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.1497 - accuracy: 0.9496 - val_loss: 0.1845 - val_accuracy: 0.9533\n",
      "Epoch 13/30\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.1261 - accuracy: 0.9622 - val_loss: 0.1493 - val_accuracy: 0.9592\n",
      "Epoch 14/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.1077 - accuracy: 0.9644 - val_loss: 0.1164 - val_accuracy: 0.9604\n",
      "Epoch 15/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0991 - accuracy: 0.9659 - val_loss: 0.1005 - val_accuracy: 0.9623\n",
      "Epoch 16/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0835 - accuracy: 0.9700 - val_loss: 0.0858 - val_accuracy: 0.9683\n",
      "Epoch 17/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0746 - accuracy: 0.9721 - val_loss: 0.0694 - val_accuracy: 0.9666\n",
      "Epoch 18/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0736 - accuracy: 0.9727 - val_loss: 0.1026 - val_accuracy: 0.9567\n",
      "Epoch 19/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0611 - accuracy: 0.9768 - val_loss: 0.0516 - val_accuracy: 0.9776\n",
      "Epoch 20/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0567 - accuracy: 0.9771 - val_loss: 0.0454 - val_accuracy: 0.9902\n",
      "Epoch 21/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0503 - accuracy: 0.9803 - val_loss: 0.0411 - val_accuracy: 0.9899\n",
      "Epoch 22/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0476 - accuracy: 0.9808 - val_loss: 0.0400 - val_accuracy: 0.9853\n",
      "Epoch 23/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0451 - accuracy: 0.9830 - val_loss: 0.0412 - val_accuracy: 0.9822\n",
      "Epoch 24/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0456 - accuracy: 0.9825 - val_loss: 0.0348 - val_accuracy: 0.9870\n",
      "Epoch 25/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0423 - accuracy: 0.9833 - val_loss: 0.0296 - val_accuracy: 0.9950\n",
      "Epoch 26/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0374 - accuracy: 0.9862 - val_loss: 0.0507 - val_accuracy: 0.9829\n",
      "Epoch 27/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0369 - accuracy: 0.9856 - val_loss: 0.0276 - val_accuracy: 0.9908\n",
      "Epoch 28/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0356 - accuracy: 0.9853 - val_loss: 0.0280 - val_accuracy: 0.9896\n",
      "Epoch 29/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0362 - accuracy: 0.9858 - val_loss: 0.0237 - val_accuracy: 0.9937\n",
      "Epoch 30/30\n",
      "548/548 [==============================] - 1s 1ms/step - loss: 0.0351 - accuracy: 0.9857 - val_loss: 0.0303 - val_accuracy: 0.9846\n",
      "Fold 3, Best Validation Loss: 0.02373320236802101, Best Validation Accuracy: 0.9950342178344727\n",
      "Epoch 1/30\n",
      "730/730 [==============================] - 2s 2ms/step - loss: 0.3255 - accuracy: 0.9018 - val_loss: 0.3067 - val_accuracy: 0.9063\n",
      "Epoch 2/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.2876 - accuracy: 0.9025 - val_loss: 0.3152 - val_accuracy: 0.9068\n",
      "Epoch 3/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.2857 - accuracy: 0.9043 - val_loss: 0.3069 - val_accuracy: 0.9065\n",
      "Epoch 4/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.2842 - accuracy: 0.9078 - val_loss: 0.3075 - val_accuracy: 0.9079\n",
      "Epoch 5/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.2830 - accuracy: 0.9129 - val_loss: 0.3182 - val_accuracy: 0.9264\n",
      "Epoch 6/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.2813 - accuracy: 0.9173 - val_loss: 0.3089 - val_accuracy: 0.9224\n",
      "Epoch 7/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.2766 - accuracy: 0.9218 - val_loss: 0.3007 - val_accuracy: 0.9199\n",
      "Epoch 8/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.2489 - accuracy: 0.9271 - val_loss: 0.2413 - val_accuracy: 0.9243\n",
      "Epoch 9/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.2198 - accuracy: 0.9276 - val_loss: 0.2217 - val_accuracy: 0.9214\n",
      "Epoch 10/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.1904 - accuracy: 0.9292 - val_loss: 0.1669 - val_accuracy: 0.9221\n",
      "Epoch 11/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.1322 - accuracy: 0.9479 - val_loss: 0.0696 - val_accuracy: 0.9697\n",
      "Epoch 12/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0935 - accuracy: 0.9613 - val_loss: 0.0520 - val_accuracy: 0.9868\n",
      "Epoch 13/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0770 - accuracy: 0.9690 - val_loss: 0.0387 - val_accuracy: 0.9940\n",
      "Epoch 14/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0699 - accuracy: 0.9724 - val_loss: 0.0382 - val_accuracy: 0.9880\n",
      "Epoch 15/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0564 - accuracy: 0.9777 - val_loss: 0.0306 - val_accuracy: 0.9916\n",
      "Epoch 16/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0564 - accuracy: 0.9772 - val_loss: 0.0724 - val_accuracy: 0.9767\n",
      "Epoch 17/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0507 - accuracy: 0.9805 - val_loss: 0.0336 - val_accuracy: 0.9858\n",
      "Epoch 18/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0475 - accuracy: 0.9813 - val_loss: 0.0288 - val_accuracy: 0.9880\n",
      "Epoch 19/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0441 - accuracy: 0.9824 - val_loss: 0.0377 - val_accuracy: 0.9834\n",
      "Epoch 20/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0411 - accuracy: 0.9827 - val_loss: 0.0229 - val_accuracy: 0.9911\n",
      "Epoch 21/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0409 - accuracy: 0.9837 - val_loss: 0.0224 - val_accuracy: 0.9923\n",
      "Epoch 22/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0364 - accuracy: 0.9848 - val_loss: 0.0210 - val_accuracy: 0.9923\n",
      "Epoch 23/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0332 - accuracy: 0.9869 - val_loss: 0.0257 - val_accuracy: 0.9901\n",
      "Epoch 24/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0326 - accuracy: 0.9870 - val_loss: 0.0347 - val_accuracy: 0.9875\n",
      "Epoch 25/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0318 - accuracy: 0.9876 - val_loss: 0.0171 - val_accuracy: 0.9932\n",
      "Epoch 26/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0334 - accuracy: 0.9866 - val_loss: 0.0158 - val_accuracy: 0.9950\n",
      "Epoch 27/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0306 - accuracy: 0.9878 - val_loss: 0.0201 - val_accuracy: 0.9908\n",
      "Epoch 28/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0291 - accuracy: 0.9884 - val_loss: 0.0161 - val_accuracy: 0.9954\n",
      "Epoch 29/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0293 - accuracy: 0.9890 - val_loss: 0.0199 - val_accuracy: 0.9932\n",
      "Epoch 30/30\n",
      "730/730 [==============================] - 1s 1ms/step - loss: 0.0313 - accuracy: 0.9876 - val_loss: 0.0143 - val_accuracy: 0.9955\n",
      "Fold 4, Best Validation Loss: 0.014290806837379932, Best Validation Accuracy: 0.9955479502677917\n",
      "Epoch 1/30\n",
      "913/913 [==============================] - 3s 2ms/step - loss: 0.3202 - accuracy: 0.9026 - val_loss: 0.2606 - val_accuracy: 0.8878\n",
      "Epoch 2/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2911 - accuracy: 0.9031 - val_loss: 0.2573 - val_accuracy: 0.8897\n",
      "Epoch 3/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2897 - accuracy: 0.9050 - val_loss: 0.2558 - val_accuracy: 0.8902\n",
      "Epoch 4/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2872 - accuracy: 0.9106 - val_loss: 0.2482 - val_accuracy: 0.9106\n",
      "Epoch 5/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2800 - accuracy: 0.9196 - val_loss: 0.2223 - val_accuracy: 0.9312\n",
      "Epoch 6/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2422 - accuracy: 0.9260 - val_loss: 0.1418 - val_accuracy: 0.9488\n",
      "Epoch 7/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1949 - accuracy: 0.9269 - val_loss: 0.0925 - val_accuracy: 0.9493\n",
      "Epoch 8/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1306 - accuracy: 0.9409 - val_loss: 0.0580 - val_accuracy: 0.9820\n",
      "Epoch 9/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0937 - accuracy: 0.9657 - val_loss: 0.0534 - val_accuracy: 0.9788\n",
      "Epoch 10/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0756 - accuracy: 0.9721 - val_loss: 0.0352 - val_accuracy: 0.9950\n",
      "Epoch 11/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0635 - accuracy: 0.9783 - val_loss: 0.0314 - val_accuracy: 0.9904\n",
      "Epoch 12/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0553 - accuracy: 0.9803 - val_loss: 0.0482 - val_accuracy: 0.9808\n",
      "Epoch 13/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0501 - accuracy: 0.9818 - val_loss: 0.0257 - val_accuracy: 0.9935\n",
      "Epoch 14/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0440 - accuracy: 0.9839 - val_loss: 0.0229 - val_accuracy: 0.9949\n",
      "Epoch 15/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0426 - accuracy: 0.9835 - val_loss: 0.0233 - val_accuracy: 0.9904\n",
      "Epoch 16/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0377 - accuracy: 0.9855 - val_loss: 0.0360 - val_accuracy: 0.9848\n",
      "Epoch 17/30\n",
      "913/913 [==============================] - 2s 2ms/step - loss: 0.0348 - accuracy: 0.9860 - val_loss: 0.0223 - val_accuracy: 0.9902\n",
      "Epoch 18/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0317 - accuracy: 0.9870 - val_loss: 0.0176 - val_accuracy: 0.9935\n",
      "Epoch 19/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0169 - val_accuracy: 0.9925\n",
      "Epoch 20/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0331 - accuracy: 0.9868 - val_loss: 0.0167 - val_accuracy: 0.9937\n",
      "Epoch 21/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0157 - val_accuracy: 0.9961\n",
      "Epoch 22/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.0314 - val_accuracy: 0.9865\n",
      "Epoch 23/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0277 - accuracy: 0.9889 - val_loss: 0.0176 - val_accuracy: 0.9904\n",
      "Epoch 24/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0262 - accuracy: 0.9894 - val_loss: 0.0257 - val_accuracy: 0.9887\n",
      "Epoch 25/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0290 - accuracy: 0.9879 - val_loss: 0.0168 - val_accuracy: 0.9932\n",
      "Epoch 26/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0280 - accuracy: 0.9891 - val_loss: 0.0146 - val_accuracy: 0.9962\n",
      "Epoch 27/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.0154 - val_accuracy: 0.9942\n",
      "Epoch 28/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0267 - accuracy: 0.9896 - val_loss: 0.0147 - val_accuracy: 0.9967\n",
      "Epoch 29/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0255 - accuracy: 0.9899 - val_loss: 0.0194 - val_accuracy: 0.9885\n",
      "Epoch 30/30\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.0242 - accuracy: 0.9904 - val_loss: 0.0261 - val_accuracy: 0.9866\n",
      "Fold 5, Best Validation Loss: 0.014620032161474228, Best Validation Accuracy: 0.9967465996742249\n",
      "Mean Best Validation Loss: 0.08625802490860224\n",
      "Mean Best Validation Accuracy: 0.9853082180023194\n",
      "60\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 2s 83ms/step - loss: 0.6738 - accuracy: 0.7714 - val_loss: 0.6400 - val_accuracy: 0.8713\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6048 - accuracy: 0.9086 - val_loss: 0.5641 - val_accuracy: 0.8713\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4978 - accuracy: 0.9086 - val_loss: 0.4512 - val_accuracy: 0.8713\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3672 - accuracy: 0.9086 - val_loss: 0.4141 - val_accuracy: 0.8713\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3562 - accuracy: 0.9086 - val_loss: 0.4588 - val_accuracy: 0.8713\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3438 - accuracy: 0.9086 - val_loss: 0.4147 - val_accuracy: 0.8713\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.9086 - val_loss: 0.3980 - val_accuracy: 0.8713\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3183 - accuracy: 0.9086 - val_loss: 0.3990 - val_accuracy: 0.8713\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3211 - accuracy: 0.9086 - val_loss: 0.3997 - val_accuracy: 0.8713\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.9086 - val_loss: 0.3984 - val_accuracy: 0.8713\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3178 - accuracy: 0.9086 - val_loss: 0.4028 - val_accuracy: 0.8713\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3258 - accuracy: 0.9086 - val_loss: 0.4013 - val_accuracy: 0.8713\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3135 - accuracy: 0.9086 - val_loss: 0.4045 - val_accuracy: 0.8713\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3141 - accuracy: 0.9086 - val_loss: 0.3990 - val_accuracy: 0.8713\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3198 - accuracy: 0.9086 - val_loss: 0.3946 - val_accuracy: 0.8713\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3136 - accuracy: 0.9086 - val_loss: 0.3950 - val_accuracy: 0.8713\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3143 - accuracy: 0.9086 - val_loss: 0.3970 - val_accuracy: 0.8713\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3127 - accuracy: 0.9086 - val_loss: 0.3958 - val_accuracy: 0.8713\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3170 - accuracy: 0.9086 - val_loss: 0.3994 - val_accuracy: 0.8713\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.9086 - val_loss: 0.3953 - val_accuracy: 0.8713\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3142 - accuracy: 0.9086 - val_loss: 0.3940 - val_accuracy: 0.8713\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3068 - accuracy: 0.9086 - val_loss: 0.3970 - val_accuracy: 0.8713\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3125 - accuracy: 0.9086 - val_loss: 0.3988 - val_accuracy: 0.8713\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3178 - accuracy: 0.9086 - val_loss: 0.3983 - val_accuracy: 0.8713\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3136 - accuracy: 0.9086 - val_loss: 0.3942 - val_accuracy: 0.8713\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3141 - accuracy: 0.9086 - val_loss: 0.3950 - val_accuracy: 0.8713\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3120 - accuracy: 0.9086 - val_loss: 0.3954 - val_accuracy: 0.8713\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3144 - accuracy: 0.9086 - val_loss: 0.3962 - val_accuracy: 0.8713\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3153 - accuracy: 0.9086 - val_loss: 0.3909 - val_accuracy: 0.8713\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3085 - accuracy: 0.9086 - val_loss: 0.3881 - val_accuracy: 0.8713\n",
      "Fold 1, Best Validation Loss: 0.3881056606769562, Best Validation Accuracy: 0.871345043182373\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 36ms/step - loss: 0.6180 - accuracy: 0.8815 - val_loss: 0.5044 - val_accuracy: 0.9181\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8902 - val_loss: 0.2885 - val_accuracy: 0.9181\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3740 - accuracy: 0.8902 - val_loss: 0.2872 - val_accuracy: 0.9181\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.3677 - accuracy: 0.8902 - val_loss: 0.2966 - val_accuracy: 0.9181\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.8902 - val_loss: 0.2995 - val_accuracy: 0.9181\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8902 - val_loss: 0.2874 - val_accuracy: 0.9181\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8902 - val_loss: 0.2932 - val_accuracy: 0.9181\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8902 - val_loss: 0.2907 - val_accuracy: 0.9181\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8902 - val_loss: 0.2877 - val_accuracy: 0.9181\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8902 - val_loss: 0.2920 - val_accuracy: 0.9181\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3573 - accuracy: 0.8902 - val_loss: 0.2894 - val_accuracy: 0.9181\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8902 - val_loss: 0.2895 - val_accuracy: 0.9181\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3578 - accuracy: 0.8902 - val_loss: 0.2859 - val_accuracy: 0.9181\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3608 - accuracy: 0.8902 - val_loss: 0.2956 - val_accuracy: 0.9181\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8902 - val_loss: 0.2880 - val_accuracy: 0.9181\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8902 - val_loss: 0.2863 - val_accuracy: 0.9181\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8902 - val_loss: 0.2880 - val_accuracy: 0.9181\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8902 - val_loss: 0.2914 - val_accuracy: 0.9181\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3559 - accuracy: 0.8902 - val_loss: 0.2919 - val_accuracy: 0.9181\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8902 - val_loss: 0.2851 - val_accuracy: 0.9181\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3516 - accuracy: 0.8902 - val_loss: 0.2871 - val_accuracy: 0.9181\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3568 - accuracy: 0.8902 - val_loss: 0.2926 - val_accuracy: 0.9181\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8902 - val_loss: 0.2880 - val_accuracy: 0.9181\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8902 - val_loss: 0.2880 - val_accuracy: 0.9181\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8902 - val_loss: 0.2871 - val_accuracy: 0.9181\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3479 - accuracy: 0.8902 - val_loss: 0.2861 - val_accuracy: 0.9181\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8902 - val_loss: 0.2883 - val_accuracy: 0.9181\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8902 - val_loss: 0.2897 - val_accuracy: 0.9181\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8902 - val_loss: 0.2894 - val_accuracy: 0.9181\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8902 - val_loss: 0.2846 - val_accuracy: 0.9181\n",
      "Fold 2, Best Validation Loss: 0.2845577597618103, Best Validation Accuracy: 0.9181286692619324\n",
      "Epoch 1/30\n",
      "17/17 [==============================] - 2s 25ms/step - loss: 0.5942 - accuracy: 0.8279 - val_loss: 0.3913 - val_accuracy: 0.9240\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8994 - val_loss: 0.2782 - val_accuracy: 0.9240\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8994 - val_loss: 0.2849 - val_accuracy: 0.9240\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8994 - val_loss: 0.2825 - val_accuracy: 0.9240\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8994 - val_loss: 0.2745 - val_accuracy: 0.9240\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8994 - val_loss: 0.2785 - val_accuracy: 0.9240\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3375 - accuracy: 0.8994 - val_loss: 0.2739 - val_accuracy: 0.9240\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8994 - val_loss: 0.2772 - val_accuracy: 0.9240\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8994 - val_loss: 0.2757 - val_accuracy: 0.9240\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8994 - val_loss: 0.2749 - val_accuracy: 0.9240\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8994 - val_loss: 0.2761 - val_accuracy: 0.9240\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8994 - val_loss: 0.2738 - val_accuracy: 0.9240\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8994 - val_loss: 0.2736 - val_accuracy: 0.9240\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3325 - accuracy: 0.8994 - val_loss: 0.2783 - val_accuracy: 0.9240\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8994 - val_loss: 0.2743 - val_accuracy: 0.9240\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8994 - val_loss: 0.2766 - val_accuracy: 0.9240\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8994 - val_loss: 0.2786 - val_accuracy: 0.9240\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8994 - val_loss: 0.2724 - val_accuracy: 0.9240\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8994 - val_loss: 0.2718 - val_accuracy: 0.9240\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8994 - val_loss: 0.2754 - val_accuracy: 0.9240\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8994 - val_loss: 0.2709 - val_accuracy: 0.9240\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3298 - accuracy: 0.8994 - val_loss: 0.2720 - val_accuracy: 0.9240\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8994 - val_loss: 0.2698 - val_accuracy: 0.9240\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8994 - val_loss: 0.2713 - val_accuracy: 0.9240\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3237 - accuracy: 0.8994 - val_loss: 0.2692 - val_accuracy: 0.9240\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8994 - val_loss: 0.2701 - val_accuracy: 0.9240\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3230 - accuracy: 0.8994 - val_loss: 0.2688 - val_accuracy: 0.9240\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8994 - val_loss: 0.2732 - val_accuracy: 0.9240\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8994 - val_loss: 0.2688 - val_accuracy: 0.9240\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8994 - val_loss: 0.2733 - val_accuracy: 0.9240\n",
      "Fold 3, Best Validation Loss: 0.26876702904701233, Best Validation Accuracy: 0.9239766001701355\n",
      "Epoch 1/30\n",
      "22/22 [==============================] - 2s 24ms/step - loss: 0.5156 - accuracy: 0.9055 - val_loss: 0.3454 - val_accuracy: 0.9006\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.9055 - val_loss: 0.3385 - val_accuracy: 0.9006\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.9055 - val_loss: 0.3363 - val_accuracy: 0.9006\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.9055 - val_loss: 0.3333 - val_accuracy: 0.9006\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.9055 - val_loss: 0.3320 - val_accuracy: 0.9006\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3214 - accuracy: 0.9055 - val_loss: 0.3307 - val_accuracy: 0.9006\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.9055 - val_loss: 0.3318 - val_accuracy: 0.9006\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.9055 - val_loss: 0.3291 - val_accuracy: 0.9006\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.9055 - val_loss: 0.3281 - val_accuracy: 0.9006\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3198 - accuracy: 0.9055 - val_loss: 0.3273 - val_accuracy: 0.9006\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3151 - accuracy: 0.9055 - val_loss: 0.3269 - val_accuracy: 0.9006\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.9055 - val_loss: 0.3265 - val_accuracy: 0.9006\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.9055 - val_loss: 0.3253 - val_accuracy: 0.9006\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.9055 - val_loss: 0.3256 - val_accuracy: 0.9006\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.9055 - val_loss: 0.3239 - val_accuracy: 0.9006\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3142 - accuracy: 0.9055 - val_loss: 0.3236 - val_accuracy: 0.9006\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.9055 - val_loss: 0.3229 - val_accuracy: 0.9006\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.9055 - val_loss: 0.3229 - val_accuracy: 0.9006\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.9055 - val_loss: 0.3224 - val_accuracy: 0.9006\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.9055 - val_loss: 0.3204 - val_accuracy: 0.9006\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3116 - accuracy: 0.9055 - val_loss: 0.3189 - val_accuracy: 0.9006\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.9055 - val_loss: 0.3130 - val_accuracy: 0.9006\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.9055 - val_loss: 0.3093 - val_accuracy: 0.9006\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.9055 - val_loss: 0.2951 - val_accuracy: 0.9006\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.9055 - val_loss: 0.2742 - val_accuracy: 0.9006\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.9055 - val_loss: 0.3419 - val_accuracy: 0.9006\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.9055 - val_loss: 0.2844 - val_accuracy: 0.9006\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2954 - accuracy: 0.9055 - val_loss: 0.2856 - val_accuracy: 0.9006\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.9055 - val_loss: 0.2659 - val_accuracy: 0.9006\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.9055 - val_loss: 0.2672 - val_accuracy: 0.9006\n",
      "Fold 4, Best Validation Loss: 0.2659209370613098, Best Validation Accuracy: 0.9005848169326782\n",
      "Epoch 1/30\n",
      "27/27 [==============================] - 2s 19ms/step - loss: 0.5053 - accuracy: 0.9010 - val_loss: 0.4350 - val_accuracy: 0.8772\n",
      "Epoch 2/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.9045 - val_loss: 0.3883 - val_accuracy: 0.8772\n",
      "Epoch 3/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.9045 - val_loss: 0.3937 - val_accuracy: 0.8772\n",
      "Epoch 4/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.9045 - val_loss: 0.3797 - val_accuracy: 0.8772\n",
      "Epoch 5/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.9045 - val_loss: 0.3791 - val_accuracy: 0.8772\n",
      "Epoch 6/30\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3240 - accuracy: 0.9045 - val_loss: 0.3803 - val_accuracy: 0.8772\n",
      "Epoch 7/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.9045 - val_loss: 0.3809 - val_accuracy: 0.8772\n",
      "Epoch 8/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.9045 - val_loss: 0.3771 - val_accuracy: 0.8772\n",
      "Epoch 9/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.9045 - val_loss: 0.3824 - val_accuracy: 0.8772\n",
      "Epoch 10/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.9045 - val_loss: 0.3756 - val_accuracy: 0.8772\n",
      "Epoch 11/30\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3161 - accuracy: 0.9045 - val_loss: 0.3828 - val_accuracy: 0.8772\n",
      "Epoch 12/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.9045 - val_loss: 0.3790 - val_accuracy: 0.8772\n",
      "Epoch 13/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.9045 - val_loss: 0.3748 - val_accuracy: 0.8772\n",
      "Epoch 14/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.9045 - val_loss: 0.3807 - val_accuracy: 0.8772\n",
      "Epoch 15/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.9045 - val_loss: 0.3753 - val_accuracy: 0.8772\n",
      "Epoch 16/30\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.9045 - val_loss: 0.3805 - val_accuracy: 0.8772\n",
      "Epoch 17/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.9045 - val_loss: 0.3748 - val_accuracy: 0.8772\n",
      "Epoch 18/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.9045 - val_loss: 0.3797 - val_accuracy: 0.8772\n",
      "Epoch 19/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.3196 - accuracy: 0.9045 - val_loss: 0.3782 - val_accuracy: 0.8772\n",
      "Epoch 20/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.9045 - val_loss: 0.3738 - val_accuracy: 0.8772\n",
      "Epoch 21/30\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3133 - accuracy: 0.9045 - val_loss: 0.3731 - val_accuracy: 0.8772\n",
      "Epoch 22/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.9045 - val_loss: 0.3658 - val_accuracy: 0.8772\n",
      "Epoch 23/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.9045 - val_loss: 0.3202 - val_accuracy: 0.8772\n",
      "Epoch 24/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2957 - accuracy: 0.9045 - val_loss: 0.3309 - val_accuracy: 0.8772\n",
      "Epoch 25/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2790 - accuracy: 0.9045 - val_loss: 0.3141 - val_accuracy: 0.8772\n",
      "Epoch 26/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.9045 - val_loss: 0.3102 - val_accuracy: 0.8772\n",
      "Epoch 27/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.9045 - val_loss: 0.3195 - val_accuracy: 0.8772\n",
      "Epoch 28/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2782 - accuracy: 0.9045 - val_loss: 0.3439 - val_accuracy: 0.8772\n",
      "Epoch 29/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.9045 - val_loss: 0.3075 - val_accuracy: 0.8772\n",
      "Epoch 30/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.9045 - val_loss: 0.3091 - val_accuracy: 0.8772\n",
      "Fold 5, Best Validation Loss: 0.30751848220825195, Best Validation Accuracy: 0.8771929740905762\n",
      "Mean Best Validation Loss: 0.3029739737510681\n",
      "Mean Best Validation Accuracy: 0.8982456207275391\n",
      "64\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6865 - accuracy: 0.9000 - val_loss: 0.6692 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6715 - accuracy: 1.0000 - val_loss: 0.6523 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6536 - accuracy: 1.0000 - val_loss: 0.6351 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6388 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6179 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6025 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5854 - accuracy: 1.0000 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5587 - accuracy: 1.0000 - val_loss: 0.5350 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5408 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5189 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5055 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4589 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4325 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4048 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3581 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3254 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2945 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2350 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1977 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1660 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1148 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Fold 1, Best Validation Loss: 0.0029628390911966562, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6962 - accuracy: 0.5000 - val_loss: 0.6833 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6846 - accuracy: 0.8750 - val_loss: 0.6654 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6666 - accuracy: 0.9375 - val_loss: 0.6470 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6460 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6259 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6071 - accuracy: 1.0000 - val_loss: 0.5870 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5949 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5656 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5418 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5185 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4843 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4486 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4125 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3850 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3565 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3114 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2651 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1641 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1417 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Fold 2, Best Validation Loss: 0.0024245334789156914, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7013 - accuracy: 0.1364 - val_loss: 0.6760 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6775 - accuracy: 0.9545 - val_loss: 0.6542 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6536 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6357 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6115 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5899 - accuracy: 1.0000 - val_loss: 0.5630 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5667 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5370 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5166 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4916 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4574 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4226 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3927 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3524 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3090 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2747 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1925 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1420 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Fold 3, Best Validation Loss: 0.0017342983046546578, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6961 - accuracy: 0.3929 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6741 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6527 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6334 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6102 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5870 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5635 - accuracy: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5432 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5213 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4939 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4550 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4327 - accuracy: 1.0000 - val_loss: 0.7414 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3967 - accuracy: 1.0000 - val_loss: 0.7611 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3546 - accuracy: 1.0000 - val_loss: 0.7874 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3217 - accuracy: 1.0000 - val_loss: 0.8225 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2804 - accuracy: 1.0000 - val_loss: 0.8690 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2396 - accuracy: 1.0000 - val_loss: 0.9299 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1965 - accuracy: 1.0000 - val_loss: 1.0086 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1619 - accuracy: 1.0000 - val_loss: 1.1081 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1213 - accuracy: 1.0000 - val_loss: 1.2307 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1001 - accuracy: 1.0000 - val_loss: 1.3770 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 1.7290 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 1.9236 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.1221 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.3181 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.5063 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.6834 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.8477 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.9979 - val_accuracy: 0.5000\n",
      "Fold 4, Best Validation Loss: 0.6914899945259094, Best Validation Accuracy: 0.5\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 2s 327ms/step - loss: 0.6855 - accuracy: 0.8529 - val_loss: 0.6558 - val_accuracy: 0.8333\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6552 - accuracy: 0.9118 - val_loss: 0.6272 - val_accuracy: 0.8333\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6266 - accuracy: 0.9118 - val_loss: 0.5973 - val_accuracy: 0.8333\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5937 - accuracy: 0.9118 - val_loss: 0.5651 - val_accuracy: 0.8333\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5559 - accuracy: 0.9118 - val_loss: 0.5303 - val_accuracy: 0.8333\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5219 - accuracy: 0.9118 - val_loss: 0.4936 - val_accuracy: 0.8333\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4778 - accuracy: 0.9118 - val_loss: 0.4581 - val_accuracy: 0.8333\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4265 - accuracy: 0.9118 - val_loss: 0.4308 - val_accuracy: 0.8333\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3706 - accuracy: 0.9118 - val_loss: 0.4242 - val_accuracy: 0.8333\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3146 - accuracy: 0.9118 - val_loss: 0.4531 - val_accuracy: 0.8333\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3202 - accuracy: 0.9118 - val_loss: 0.5206 - val_accuracy: 0.8333\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2840 - accuracy: 0.9118 - val_loss: 0.6100 - val_accuracy: 0.8333\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3093 - accuracy: 0.9118 - val_loss: 0.6900 - val_accuracy: 0.8333\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3182 - accuracy: 0.9118 - val_loss: 0.7433 - val_accuracy: 0.8333\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3857 - accuracy: 0.9118 - val_loss: 0.7648 - val_accuracy: 0.8333\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4021 - accuracy: 0.9118 - val_loss: 0.7394 - val_accuracy: 0.8333\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3743 - accuracy: 0.9118 - val_loss: 0.6867 - val_accuracy: 0.8333\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3150 - accuracy: 0.9118 - val_loss: 0.6430 - val_accuracy: 0.8333\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3002 - accuracy: 0.9118 - val_loss: 0.5955 - val_accuracy: 0.8333\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3146 - accuracy: 0.9118 - val_loss: 0.5471 - val_accuracy: 0.8333\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3064 - accuracy: 0.9118 - val_loss: 0.5143 - val_accuracy: 0.8333\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2973 - accuracy: 0.9118 - val_loss: 0.4935 - val_accuracy: 0.8333\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3097 - accuracy: 0.9118 - val_loss: 0.4813 - val_accuracy: 0.8333\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2860 - accuracy: 0.9118 - val_loss: 0.4679 - val_accuracy: 0.8333\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3039 - accuracy: 0.9118 - val_loss: 0.4505 - val_accuracy: 0.8333\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3106 - accuracy: 0.9118 - val_loss: 0.4388 - val_accuracy: 0.8333\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3046 - accuracy: 0.9118 - val_loss: 0.4340 - val_accuracy: 0.8333\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3021 - accuracy: 0.9118 - val_loss: 0.4330 - val_accuracy: 0.8333\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3043 - accuracy: 0.9118 - val_loss: 0.4321 - val_accuracy: 0.8333\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3168 - accuracy: 0.9118 - val_loss: 0.4312 - val_accuracy: 0.8333\n",
      "Fold 5, Best Validation Loss: 0.4241574704647064, Best Validation Accuracy: 0.8333333134651184\n",
      "Mean Best Validation Loss: 0.22455382717307656\n",
      "Mean Best Validation Accuracy: 0.8666666626930237\n",
      "66\n",
      "Epoch 1/30\n",
      "64/64 [==============================] - 2s 9ms/step - loss: 0.1705 - accuracy: 0.9956 - val_loss: 1.3556e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.6061e-04 - accuracy: 1.0000 - val_loss: 9.8798e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.3069e-04 - accuracy: 1.0000 - val_loss: 8.1725e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.0852e-04 - accuracy: 1.0000 - val_loss: 6.9302e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 9.6909e-05 - accuracy: 1.0000 - val_loss: 5.9835e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 8.4506e-05 - accuracy: 1.0000 - val_loss: 5.2513e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 7.1890e-05 - accuracy: 1.0000 - val_loss: 4.6853e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.6275e-05 - accuracy: 1.0000 - val_loss: 4.2100e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 6.0091e-05 - accuracy: 1.0000 - val_loss: 3.8141e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 5.6308e-05 - accuracy: 1.0000 - val_loss: 3.4735e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.1937e-05 - accuracy: 1.0000 - val_loss: 3.1776e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.5352e-05 - accuracy: 1.0000 - val_loss: 2.9320e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 4.3554e-05 - accuracy: 1.0000 - val_loss: 2.7101e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.9519e-05 - accuracy: 1.0000 - val_loss: 2.5180e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.6912e-05 - accuracy: 1.0000 - val_loss: 2.3463e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.3287e-05 - accuracy: 1.0000 - val_loss: 2.1932e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.1678e-05 - accuracy: 1.0000 - val_loss: 2.0552e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.9979e-05 - accuracy: 1.0000 - val_loss: 1.9294e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.7653e-05 - accuracy: 1.0000 - val_loss: 1.8160e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.6796e-05 - accuracy: 1.0000 - val_loss: 1.7095e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.6341e-05 - accuracy: 1.0000 - val_loss: 1.6084e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.5509e-05 - accuracy: 1.0000 - val_loss: 1.5144e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 2.2268e-05 - accuracy: 1.0000 - val_loss: 1.4318e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1164e-05 - accuracy: 1.0000 - val_loss: 1.3567e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 2.1041e-05 - accuracy: 1.0000 - val_loss: 1.2827e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.8929e-05 - accuracy: 1.0000 - val_loss: 1.2185e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 1.8256e-05 - accuracy: 1.0000 - val_loss: 1.1573e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.7948e-05 - accuracy: 1.0000 - val_loss: 1.0983e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.7224e-05 - accuracy: 1.0000 - val_loss: 1.0435e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.5743e-05 - accuracy: 1.0000 - val_loss: 9.9337e-06 - val_accuracy: 1.0000\n",
      "Fold 1, Best Validation Loss: 9.933662113326136e-06, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "128/128 [==============================] - 2s 5ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 1.7661e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.9912e-04 - accuracy: 1.0000 - val_loss: 1.1766e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.4339e-04 - accuracy: 1.0000 - val_loss: 8.6813e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.0950e-04 - accuracy: 1.0000 - val_loss: 6.7600e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 8.8488e-05 - accuracy: 1.0000 - val_loss: 5.4277e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 7.0625e-05 - accuracy: 1.0000 - val_loss: 4.4804e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 5.9329e-05 - accuracy: 1.0000 - val_loss: 3.7640e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 5.0446e-05 - accuracy: 1.0000 - val_loss: 3.2021e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 4.1894e-05 - accuracy: 1.0000 - val_loss: 2.7646e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 3.7612e-05 - accuracy: 1.0000 - val_loss: 2.4004e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 3.3068e-05 - accuracy: 1.0000 - val_loss: 2.0980e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 2.9566e-05 - accuracy: 1.0000 - val_loss: 1.8448e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 2.5518e-05 - accuracy: 1.0000 - val_loss: 1.6358e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 2.3187e-05 - accuracy: 1.0000 - val_loss: 1.4558e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 2.0620e-05 - accuracy: 1.0000 - val_loss: 1.3020e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.8895e-05 - accuracy: 1.0000 - val_loss: 1.1689e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.6401e-05 - accuracy: 1.0000 - val_loss: 1.0542e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.5742e-05 - accuracy: 1.0000 - val_loss: 9.5127e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.3534e-05 - accuracy: 1.0000 - val_loss: 8.6355e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.3009e-05 - accuracy: 1.0000 - val_loss: 7.8264e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.1741e-05 - accuracy: 1.0000 - val_loss: 7.1158e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 1.0717e-05 - accuracy: 1.0000 - val_loss: 6.4870e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 9.6707e-06 - accuracy: 1.0000 - val_loss: 5.9370e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 9.1885e-06 - accuracy: 1.0000 - val_loss: 5.4230e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 8.5233e-06 - accuracy: 1.0000 - val_loss: 4.9616e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 7.6443e-06 - accuracy: 1.0000 - val_loss: 4.5515e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 7.2895e-06 - accuracy: 1.0000 - val_loss: 4.1773e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 6.7085e-06 - accuracy: 1.0000 - val_loss: 3.8343e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 6.0745e-06 - accuracy: 1.0000 - val_loss: 3.5315e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 5.7306e-06 - accuracy: 1.0000 - val_loss: 3.2525e-06 - val_accuracy: 1.0000\n",
      "Fold 2, Best Validation Loss: 3.2525440474273637e-06, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "192/192 [==============================] - 2s 5ms/step - loss: 0.0543 - accuracy: 0.9946 - val_loss: 9.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 6.2026e-05 - accuracy: 1.0000 - val_loss: 10.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 4.0119e-05 - accuracy: 1.0000 - val_loss: 10.7658 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 3.0116e-05 - accuracy: 1.0000 - val_loss: 11.0303 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.4010e-05 - accuracy: 1.0000 - val_loss: 11.2386 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.0250e-05 - accuracy: 1.0000 - val_loss: 11.4182 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 1.6990e-05 - accuracy: 1.0000 - val_loss: 11.5773 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 1.4527e-05 - accuracy: 1.0000 - val_loss: 11.7213 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 1.2776e-05 - accuracy: 1.0000 - val_loss: 11.8570 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 1.1377e-05 - accuracy: 1.0000 - val_loss: 11.9869 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 9.8503e-06 - accuracy: 1.0000 - val_loss: 12.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 8.7413e-06 - accuracy: 1.0000 - val_loss: 12.2271 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 7.8314e-06 - accuracy: 1.0000 - val_loss: 12.3408 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 7.0897e-06 - accuracy: 1.0000 - val_loss: 12.4536 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 6.3205e-06 - accuracy: 1.0000 - val_loss: 12.5635 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 5.6927e-06 - accuracy: 1.0000 - val_loss: 12.6716 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 5.1724e-06 - accuracy: 1.0000 - val_loss: 12.7783 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 4.6742e-06 - accuracy: 1.0000 - val_loss: 12.8848 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 4.2872e-06 - accuracy: 1.0000 - val_loss: 12.9906 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 3.7786e-06 - accuracy: 1.0000 - val_loss: 13.0932 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 3.5823e-06 - accuracy: 1.0000 - val_loss: 13.1987 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 3.1202e-06 - accuracy: 1.0000 - val_loss: 13.3017 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.8222e-06 - accuracy: 1.0000 - val_loss: 13.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.5686e-06 - accuracy: 1.0000 - val_loss: 13.5032 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.3201e-06 - accuracy: 1.0000 - val_loss: 13.6029 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.1352e-06 - accuracy: 1.0000 - val_loss: 13.7033 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.0381e-06 - accuracy: 1.0000 - val_loss: 13.8075 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 1.7246e-06 - accuracy: 1.0000 - val_loss: 13.9054 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 1.7032e-06 - accuracy: 1.0000 - val_loss: 14.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 1.4213e-06 - accuracy: 1.0000 - val_loss: 14.1082 - val_accuracy: 0.0000e+00\n",
      "Fold 3, Best Validation Loss: 9.916516304016113, Best Validation Accuracy: 0.0\n",
      "Epoch 1/30\n",
      "256/256 [==============================] - 2s 5ms/step - loss: 0.5365 - accuracy: 0.7577 - val_loss: 0.4776 - val_accuracy: 0.9443\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3685 - accuracy: 0.8278 - val_loss: 0.2288 - val_accuracy: 0.9858\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3514 - accuracy: 0.8359 - val_loss: 0.1968 - val_accuracy: 0.9834\n",
      "Epoch 4/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3492 - accuracy: 0.8391 - val_loss: 0.2455 - val_accuracy: 0.9839\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3287 - accuracy: 0.8468 - val_loss: 0.2551 - val_accuracy: 0.9814\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.8495 - val_loss: 0.2103 - val_accuracy: 0.9805\n",
      "Epoch 7/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3127 - accuracy: 0.8573 - val_loss: 0.2006 - val_accuracy: 0.9775\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.3019 - accuracy: 0.8552 - val_loss: 0.2740 - val_accuracy: 0.9756\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.8531 - val_loss: 0.1455 - val_accuracy: 0.9771\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2870 - accuracy: 0.8613 - val_loss: 0.1172 - val_accuracy: 0.9854\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2885 - accuracy: 0.8622 - val_loss: 0.1373 - val_accuracy: 0.9873\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.8668 - val_loss: 0.0781 - val_accuracy: 0.9912\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.8641 - val_loss: 0.1144 - val_accuracy: 0.9912\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.8688 - val_loss: 0.1269 - val_accuracy: 0.9878\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2752 - accuracy: 0.8661 - val_loss: 0.1184 - val_accuracy: 0.9893\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2744 - accuracy: 0.8660 - val_loss: 0.0852 - val_accuracy: 0.9932\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2693 - accuracy: 0.8734 - val_loss: 0.1470 - val_accuracy: 0.9927\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.8693 - val_loss: 0.1230 - val_accuracy: 0.9956\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.8738 - val_loss: 0.0553 - val_accuracy: 0.9980\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2580 - accuracy: 0.8812 - val_loss: 0.0496 - val_accuracy: 0.9980\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2466 - accuracy: 0.8839 - val_loss: 0.0501 - val_accuracy: 0.9995\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2204 - accuracy: 0.9009 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1360 - accuracy: 0.9430 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.1014 - accuracy: 0.9604 - val_loss: 4.4944e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9680 - val_loss: 2.7604e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9739 - val_loss: 3.9669e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9724 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0563 - accuracy: 0.9778 - val_loss: 2.0620e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9741 - val_loss: 2.7057e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.9812 - val_loss: 1.5250e-04 - val_accuracy: 1.0000\n",
      "Fold 4, Best Validation Loss: 0.0001524961116956547, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "320/320 [==============================] - 2s 4ms/step - loss: 0.4428 - accuracy: 0.7846 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.3279 - accuracy: 0.8576 - val_loss: 0.0177 - val_accuracy: 0.9990\n",
      "Epoch 3/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.3082 - accuracy: 0.8649 - val_loss: 0.0199 - val_accuracy: 0.9985\n",
      "Epoch 4/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.8677 - val_loss: 0.0300 - val_accuracy: 0.9951\n",
      "Epoch 5/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2908 - accuracy: 0.8676 - val_loss: 0.0303 - val_accuracy: 0.9854\n",
      "Epoch 6/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2717 - accuracy: 0.8768 - val_loss: 0.0179 - val_accuracy: 0.9854\n",
      "Epoch 7/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2720 - accuracy: 0.8719 - val_loss: 0.0241 - val_accuracy: 0.9814\n",
      "Epoch 8/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.8785 - val_loss: 0.0169 - val_accuracy: 0.9912\n",
      "Epoch 9/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2575 - accuracy: 0.8834 - val_loss: 0.0147 - val_accuracy: 0.9927\n",
      "Epoch 10/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2434 - accuracy: 0.8893 - val_loss: 0.0130 - val_accuracy: 0.9956\n",
      "Epoch 11/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2487 - accuracy: 0.8876 - val_loss: 0.0118 - val_accuracy: 0.9990\n",
      "Epoch 12/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2499 - accuracy: 0.8852 - val_loss: 0.0119 - val_accuracy: 0.9985\n",
      "Epoch 13/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2478 - accuracy: 0.8884 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2432 - accuracy: 0.8909 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.8908 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2345 - accuracy: 0.8933 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2308 - accuracy: 0.8958 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2299 - accuracy: 0.8950 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2264 - accuracy: 0.8953 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2250 - accuracy: 0.8988 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2203 - accuracy: 0.8991 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2078 - accuracy: 0.9044 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2155 - accuracy: 0.9022 - val_loss: 7.9902e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.2022 - accuracy: 0.9082 - val_loss: 3.8829e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9129 - val_loss: 3.3368e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.1981 - accuracy: 0.9107 - val_loss: 2.7341e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.1795 - accuracy: 0.9189 - val_loss: 1.0625e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9458 - val_loss: 1.0082e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9755 - val_loss: 8.8436e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 0.0393 - accuracy: 0.9849 - val_loss: 2.7245e-06 - val_accuracy: 1.0000\n",
      "Fold 5, Best Validation Loss: 2.7245375804341165e-06, Best Validation Accuracy: 1.0\n",
      "Mean Best Validation Loss: 1.9833369421743101\n",
      "Mean Best Validation Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 저장 경로\n",
    "csv_file_path = \"output.csv\"\n",
    "\n",
    "# CSV 파일에 저장\n",
    "file_exists = os.path.isfile(csv_file_path)\n",
    "\n",
    "size_name = (\"B\", \"KB\", \"MB\")\n",
    "header = ['index', 'fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'mean_fold', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'mean_acc']\n",
    "for file in file_list:\n",
    "    f = file.split('_')\n",
    "    g = file.split('.')\n",
    "    search_index = int(f[0])\n",
    "\n",
    "    # CSV 파일에 이미 있는 데이터는 학습하지 않음\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # 특정 번호 검색\n",
    "    result = df[df['index'] == search_index]\n",
    "    if not result.empty:\n",
    "        continue\n",
    "\n",
    "    # 파일 사이즈가 5MB 보다 큰 경우는 제외\n",
    "    file_size = os.path.getsize(dataset_path + file) \n",
    "    file_size_str = convert_size(file_size)\n",
    "    temp = file_size_str.split(' ')\n",
    "    if temp[1] not in size_name:\n",
    "        continue\n",
    "\n",
    "    if temp[1] == \"MB\" and float(temp[0]) > 5:\n",
    "        # print(temp, search_index)\n",
    "        continue\n",
    "    \n",
    "    print(search_index)\n",
    "    \n",
    "    X_t, y_t = npz_to_csv(dataset_path + file)\n",
    "    anomaly_rate = get_anomaly_rate(y_t)\n",
    "    val_losses, val_accs = train_and_evaluate_lstm(X_t, y_t)\n",
    "    \n",
    "    # plotting\n",
    "    plot_validation_metrics(g[0], val_losses, val_accs)\n",
    "    # saving losses and accs history for comparision in the future\n",
    "    # append_to_val_dict(int(f[0]), val_losses, val_accs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    index = int(f[0])\n",
    "    row = [index] + val_losses + val_accs\n",
    "    # 파일이 존재하지 않으면 헤더를 추가하고, 존재하면 행만 추가\n",
    "    with open(csv_file_path, mode='a', newline='') as file:\n",
    "        csvwriter = csv.writer(file)\n",
    "        # 파일이 비어있는 경우 헤더를 추가\n",
    "        if file.tell() == 0:\n",
    "            csvwriter.writerow(header)\n",
    "        csvwriter.writerow(row)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2911779880523682, 0.5994318127632141, 0.56441730260849, 0.04630052670836449, 0.3512033224105835, 0.5705061905086041]\n"
     ]
    }
   ],
   "source": [
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_65, y_65 = npz_to_csv(dataset_path + '65_MachineryFault.npz')\n",
    "X_1, y_1 = npz_to_csv(dataset_path + '34_Turbofan.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly rate : 10.000%\n"
     ]
    }
   ],
   "source": [
    "anomaly_rate = get_anomaly_rate(y_1)\n",
    "print(f'anomaly rate : {anomaly_rate:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "108/108 [==============================] - 3s 12ms/step - loss: 0.3923 - accuracy: 0.8875 - val_loss: 0.3272 - val_accuracy: 0.8997\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 1s 10ms/step - loss: 0.3524 - accuracy: 0.8875 - val_loss: 0.3242 - val_accuracy: 0.8997\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.3465 - accuracy: 0.8875 - val_loss: 0.2924 - val_accuracy: 0.8997\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.2612 - accuracy: 0.9053 - val_loss: 0.1804 - val_accuracy: 0.9171\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1641 - accuracy: 0.9349 - val_loss: 0.1329 - val_accuracy: 0.9520\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1616 - accuracy: 0.9349 - val_loss: 0.1763 - val_accuracy: 0.9159\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1616 - accuracy: 0.9343 - val_loss: 0.1373 - val_accuracy: 0.9482\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1420 - accuracy: 0.9459 - val_loss: 0.1402 - val_accuracy: 0.9395\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1495 - accuracy: 0.9454 - val_loss: 0.1340 - val_accuracy: 0.9497\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1338 - accuracy: 0.9494 - val_loss: 0.1272 - val_accuracy: 0.9535\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1537 - accuracy: 0.9413 - val_loss: 0.1285 - val_accuracy: 0.9552\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1290 - accuracy: 0.9515 - val_loss: 0.1240 - val_accuracy: 0.9552\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1280 - accuracy: 0.9518 - val_loss: 0.1375 - val_accuracy: 0.9476\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1258 - accuracy: 0.9529 - val_loss: 0.1242 - val_accuracy: 0.9567\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1306 - accuracy: 0.9515 - val_loss: 0.1326 - val_accuracy: 0.9500\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1294 - accuracy: 0.9512 - val_loss: 0.1191 - val_accuracy: 0.9622\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1162 - accuracy: 0.9570 - val_loss: 0.1219 - val_accuracy: 0.9587\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1271 - accuracy: 0.9541 - val_loss: 0.1197 - val_accuracy: 0.9558\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1159 - accuracy: 0.9570 - val_loss: 0.1209 - val_accuracy: 0.9538\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1321 - accuracy: 0.9500 - val_loss: 0.1195 - val_accuracy: 0.9628\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1183 - accuracy: 0.9552 - val_loss: 0.1102 - val_accuracy: 0.9631\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1188 - accuracy: 0.9582 - val_loss: 0.1098 - val_accuracy: 0.9642\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1162 - accuracy: 0.9558 - val_loss: 0.1205 - val_accuracy: 0.9552\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1274 - accuracy: 0.9544 - val_loss: 0.1125 - val_accuracy: 0.9622\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1184 - accuracy: 0.9558 - val_loss: 0.1165 - val_accuracy: 0.9610\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1140 - accuracy: 0.9570 - val_loss: 0.1250 - val_accuracy: 0.9572\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1195 - accuracy: 0.9570 - val_loss: 0.1139 - val_accuracy: 0.9596\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1145 - accuracy: 0.9596 - val_loss: 0.1154 - val_accuracy: 0.9593\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1118 - accuracy: 0.9602 - val_loss: 0.1135 - val_accuracy: 0.9613\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1079 - accuracy: 0.9628 - val_loss: 0.1156 - val_accuracy: 0.9511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Best Validation Loss: 0.10982047766447067, Best Validation Accuracy: 0.9642233848571777\n",
      "Epoch 1/30\n",
      "215/215 [==============================] - 3s 10ms/step - loss: 0.3573 - accuracy: 0.8934 - val_loss: 0.3169 - val_accuracy: 0.9029\n",
      "Epoch 2/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.3354 - accuracy: 0.8936 - val_loss: 0.2663 - val_accuracy: 0.9029\n",
      "Epoch 3/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2268 - accuracy: 0.9152 - val_loss: 0.1361 - val_accuracy: 0.9424\n",
      "Epoch 4/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1442 - accuracy: 0.9433 - val_loss: 0.1301 - val_accuracy: 0.9436\n",
      "Epoch 5/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1357 - accuracy: 0.9503 - val_loss: 0.1255 - val_accuracy: 0.9535\n",
      "Epoch 6/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1250 - accuracy: 0.9545 - val_loss: 0.1622 - val_accuracy: 0.9427\n",
      "Epoch 7/30\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1262 - accuracy: 0.9552 - val_loss: 0.1242 - val_accuracy: 0.9546\n",
      "Epoch 8/30\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1231 - accuracy: 0.9551 - val_loss: 0.1174 - val_accuracy: 0.9555\n",
      "Epoch 9/30\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1165 - accuracy: 0.9580 - val_loss: 0.1198 - val_accuracy: 0.9543\n",
      "Epoch 10/30\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1209 - accuracy: 0.9555 - val_loss: 0.1136 - val_accuracy: 0.9596\n",
      "Epoch 11/30\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1187 - accuracy: 0.9581 - val_loss: 0.1138 - val_accuracy: 0.9581\n",
      "Epoch 12/30\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1149 - accuracy: 0.9581 - val_loss: 0.1117 - val_accuracy: 0.9581\n",
      "Epoch 13/30\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1186 - accuracy: 0.9586 - val_loss: 0.1176 - val_accuracy: 0.9564\n",
      "Epoch 14/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1099 - accuracy: 0.9593 - val_loss: 0.1113 - val_accuracy: 0.9604\n",
      "Epoch 15/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1092 - accuracy: 0.9618 - val_loss: 0.1163 - val_accuracy: 0.9572\n",
      "Epoch 16/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1120 - accuracy: 0.9597 - val_loss: 0.1252 - val_accuracy: 0.9529\n",
      "Epoch 17/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1058 - accuracy: 0.9616 - val_loss: 0.1114 - val_accuracy: 0.9610\n",
      "Epoch 18/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1058 - accuracy: 0.9616 - val_loss: 0.1146 - val_accuracy: 0.9610\n",
      "Epoch 19/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1080 - accuracy: 0.9612 - val_loss: 0.1279 - val_accuracy: 0.9511\n",
      "Epoch 20/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1098 - accuracy: 0.9593 - val_loss: 0.1105 - val_accuracy: 0.9622\n",
      "Epoch 21/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1047 - accuracy: 0.9606 - val_loss: 0.1105 - val_accuracy: 0.9581\n",
      "Epoch 22/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1035 - accuracy: 0.9616 - val_loss: 0.1100 - val_accuracy: 0.9584\n",
      "Epoch 23/30\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1023 - accuracy: 0.9606 - val_loss: 0.1095 - val_accuracy: 0.9593\n",
      "Epoch 24/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1044 - accuracy: 0.9623 - val_loss: 0.1037 - val_accuracy: 0.9622\n",
      "Epoch 25/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1030 - accuracy: 0.9631 - val_loss: 0.1172 - val_accuracy: 0.9613\n",
      "Epoch 26/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1031 - accuracy: 0.9629 - val_loss: 0.1302 - val_accuracy: 0.9532\n",
      "Epoch 27/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1026 - accuracy: 0.9629 - val_loss: 0.1054 - val_accuracy: 0.9631\n",
      "Epoch 28/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1026 - accuracy: 0.9618 - val_loss: 0.1030 - val_accuracy: 0.9610\n",
      "Epoch 29/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0980 - accuracy: 0.9622 - val_loss: 0.1055 - val_accuracy: 0.9625\n",
      "Epoch 30/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1010 - accuracy: 0.9632 - val_loss: 0.1073 - val_accuracy: 0.9631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Best Validation Loss: 0.10299540311098099, Best Validation Accuracy: 0.9630599021911621\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 4s 9ms/step - loss: 0.3453 - accuracy: 0.8943 - val_loss: 0.2979 - val_accuracy: 0.9017\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.2124 - accuracy: 0.9194 - val_loss: 0.1330 - val_accuracy: 0.9497\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1376 - accuracy: 0.9484 - val_loss: 0.1203 - val_accuracy: 0.9567\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1276 - accuracy: 0.9499 - val_loss: 0.1222 - val_accuracy: 0.9567\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1254 - accuracy: 0.9546 - val_loss: 0.1270 - val_accuracy: 0.9532\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1237 - accuracy: 0.9551 - val_loss: 0.1137 - val_accuracy: 0.9593\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1170 - accuracy: 0.9583 - val_loss: 0.1237 - val_accuracy: 0.9564\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1160 - accuracy: 0.9582 - val_loss: 0.1091 - val_accuracy: 0.9604\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1179 - accuracy: 0.9566 - val_loss: 0.1089 - val_accuracy: 0.9619\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.1154 - accuracy: 0.9571 - val_loss: 0.1097 - val_accuracy: 0.9581\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1108 - accuracy: 0.9586 - val_loss: 0.1034 - val_accuracy: 0.9599\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1117 - accuracy: 0.9591 - val_loss: 0.0984 - val_accuracy: 0.9613\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1086 - accuracy: 0.9608 - val_loss: 0.1116 - val_accuracy: 0.9564\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1075 - accuracy: 0.9609 - val_loss: 0.0951 - val_accuracy: 0.9631\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1069 - accuracy: 0.9604 - val_loss: 0.0989 - val_accuracy: 0.9628\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1047 - accuracy: 0.9601 - val_loss: 0.0925 - val_accuracy: 0.9645\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1051 - accuracy: 0.9626 - val_loss: 0.1014 - val_accuracy: 0.9625\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0998 - accuracy: 0.9638 - val_loss: 0.0886 - val_accuracy: 0.9651\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0988 - accuracy: 0.9637 - val_loss: 0.0911 - val_accuracy: 0.9642\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0971 - accuracy: 0.9653 - val_loss: 0.0922 - val_accuracy: 0.9642\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0942 - accuracy: 0.9653 - val_loss: 0.0849 - val_accuracy: 0.9677\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0944 - accuracy: 0.9637 - val_loss: 0.0902 - val_accuracy: 0.9651\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0946 - accuracy: 0.9646 - val_loss: 0.0960 - val_accuracy: 0.9634\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0868 - accuracy: 0.9678 - val_loss: 0.0905 - val_accuracy: 0.9645\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0841 - accuracy: 0.9672 - val_loss: 0.0799 - val_accuracy: 0.9689\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0824 - accuracy: 0.9689 - val_loss: 0.0804 - val_accuracy: 0.9677\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0826 - accuracy: 0.9707 - val_loss: 0.0852 - val_accuracy: 0.9674\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.0774 - accuracy: 0.9713 - val_loss: 0.0834 - val_accuracy: 0.9674\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.0740 - accuracy: 0.9704 - val_loss: 0.0806 - val_accuracy: 0.9697\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 3s 9ms/step - loss: 0.0744 - accuracy: 0.9720 - val_loss: 0.0763 - val_accuracy: 0.9715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Best Validation Loss: 0.07634427398443222, Best Validation Accuracy: 0.9714950323104858\n",
      "Epoch 1/30\n",
      "430/430 [==============================] - 5s 8ms/step - loss: 0.3269 - accuracy: 0.8977 - val_loss: 0.2661 - val_accuracy: 0.8985\n",
      "Epoch 2/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1686 - accuracy: 0.9347 - val_loss: 0.1440 - val_accuracy: 0.9439\n",
      "Epoch 3/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1289 - accuracy: 0.9511 - val_loss: 0.1261 - val_accuracy: 0.9555\n",
      "Epoch 4/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1214 - accuracy: 0.9535 - val_loss: 0.1228 - val_accuracy: 0.9558\n",
      "Epoch 5/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1202 - accuracy: 0.9543 - val_loss: 0.1199 - val_accuracy: 0.9578\n",
      "Epoch 6/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1200 - accuracy: 0.9527 - val_loss: 0.1269 - val_accuracy: 0.9494\n",
      "Epoch 7/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1160 - accuracy: 0.9564 - val_loss: 0.1202 - val_accuracy: 0.9540\n",
      "Epoch 8/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1141 - accuracy: 0.9566 - val_loss: 0.1113 - val_accuracy: 0.9572\n",
      "Epoch 9/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1116 - accuracy: 0.9590 - val_loss: 0.1081 - val_accuracy: 0.9587\n",
      "Epoch 10/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1078 - accuracy: 0.9598 - val_loss: 0.1107 - val_accuracy: 0.9567\n",
      "Epoch 11/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.1070 - accuracy: 0.9592 - val_loss: 0.1014 - val_accuracy: 0.9599\n",
      "Epoch 12/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.1041 - accuracy: 0.9602 - val_loss: 0.0977 - val_accuracy: 0.9625\n",
      "Epoch 13/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.1046 - accuracy: 0.9599 - val_loss: 0.1187 - val_accuracy: 0.9514\n",
      "Epoch 14/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.1009 - accuracy: 0.9616 - val_loss: 0.0999 - val_accuracy: 0.9628\n",
      "Epoch 15/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0981 - accuracy: 0.9645 - val_loss: 0.0961 - val_accuracy: 0.9610\n",
      "Epoch 16/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0955 - accuracy: 0.9635 - val_loss: 0.0958 - val_accuracy: 0.9607\n",
      "Epoch 17/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.0925 - accuracy: 0.9656 - val_loss: 0.0853 - val_accuracy: 0.9668\n",
      "Epoch 18/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0867 - accuracy: 0.9663 - val_loss: 0.0910 - val_accuracy: 0.9628\n",
      "Epoch 19/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0826 - accuracy: 0.9676 - val_loss: 0.0818 - val_accuracy: 0.9668\n",
      "Epoch 20/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0772 - accuracy: 0.9705 - val_loss: 0.0758 - val_accuracy: 0.9712\n",
      "Epoch 21/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0745 - accuracy: 0.9718 - val_loss: 0.0730 - val_accuracy: 0.9721\n",
      "Epoch 22/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.0737 - accuracy: 0.9695 - val_loss: 0.0707 - val_accuracy: 0.9732\n",
      "Epoch 23/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.0687 - accuracy: 0.9724 - val_loss: 0.0687 - val_accuracy: 0.9715\n",
      "Epoch 24/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0681 - accuracy: 0.9743 - val_loss: 0.0757 - val_accuracy: 0.9683\n",
      "Epoch 25/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0637 - accuracy: 0.9734 - val_loss: 0.0674 - val_accuracy: 0.9721\n",
      "Epoch 26/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0617 - accuracy: 0.9746 - val_loss: 0.0661 - val_accuracy: 0.9706\n",
      "Epoch 27/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0631 - accuracy: 0.9738 - val_loss: 0.0620 - val_accuracy: 0.9767\n",
      "Epoch 28/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.0593 - accuracy: 0.9740 - val_loss: 0.0733 - val_accuracy: 0.9700\n",
      "Epoch 29/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0587 - accuracy: 0.9748 - val_loss: 0.0807 - val_accuracy: 0.9663\n",
      "Epoch 30/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0600 - accuracy: 0.9737 - val_loss: 0.0628 - val_accuracy: 0.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Best Validation Loss: 0.061980895698070526, Best Validation Accuracy: 0.9767306447029114\n",
      "Epoch 1/30\n",
      "538/538 [==============================] - 5s 7ms/step - loss: 0.2925 - accuracy: 0.9052 - val_loss: 0.1277 - val_accuracy: 0.9485\n",
      "Epoch 2/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1435 - accuracy: 0.9427 - val_loss: 0.0965 - val_accuracy: 0.9567\n",
      "Epoch 3/30\n",
      "538/538 [==============================] - 4s 8ms/step - loss: 0.1254 - accuracy: 0.9515 - val_loss: 0.0892 - val_accuracy: 0.9645\n",
      "Epoch 4/30\n",
      "538/538 [==============================] - 4s 8ms/step - loss: 0.1187 - accuracy: 0.9550 - val_loss: 0.0880 - val_accuracy: 0.9639\n",
      "Epoch 5/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1187 - accuracy: 0.9542 - val_loss: 0.0898 - val_accuracy: 0.9613\n",
      "Epoch 6/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1122 - accuracy: 0.9577 - val_loss: 0.0926 - val_accuracy: 0.9613\n",
      "Epoch 7/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1110 - accuracy: 0.9575 - val_loss: 0.0777 - val_accuracy: 0.9663\n",
      "Epoch 8/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1113 - accuracy: 0.9580 - val_loss: 0.0780 - val_accuracy: 0.9689\n",
      "Epoch 9/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1070 - accuracy: 0.9591 - val_loss: 0.0763 - val_accuracy: 0.9695\n",
      "Epoch 10/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1080 - accuracy: 0.9600 - val_loss: 0.0783 - val_accuracy: 0.9666\n",
      "Epoch 11/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1043 - accuracy: 0.9601 - val_loss: 0.0749 - val_accuracy: 0.9700\n",
      "Epoch 12/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1041 - accuracy: 0.9596 - val_loss: 0.0775 - val_accuracy: 0.9636\n",
      "Epoch 13/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1009 - accuracy: 0.9606 - val_loss: 0.0737 - val_accuracy: 0.9668\n",
      "Epoch 14/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0976 - accuracy: 0.9630 - val_loss: 0.0665 - val_accuracy: 0.9718\n",
      "Epoch 15/30\n",
      "538/538 [==============================] - 4s 8ms/step - loss: 0.0967 - accuracy: 0.9627 - val_loss: 0.0814 - val_accuracy: 0.9660\n",
      "Epoch 16/30\n",
      "538/538 [==============================] - 4s 8ms/step - loss: 0.0964 - accuracy: 0.9631 - val_loss: 0.0827 - val_accuracy: 0.9677\n",
      "Epoch 17/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0958 - accuracy: 0.9637 - val_loss: 0.0740 - val_accuracy: 0.9703\n",
      "Epoch 18/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0934 - accuracy: 0.9638 - val_loss: 0.0684 - val_accuracy: 0.9727\n",
      "Epoch 19/30\n",
      "538/538 [==============================] - 4s 8ms/step - loss: 0.0897 - accuracy: 0.9651 - val_loss: 0.0650 - val_accuracy: 0.9738\n",
      "Epoch 20/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0842 - accuracy: 0.9667 - val_loss: 0.0792 - val_accuracy: 0.9689\n",
      "Epoch 21/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0790 - accuracy: 0.9695 - val_loss: 0.0537 - val_accuracy: 0.9750\n",
      "Epoch 22/30\n",
      "538/538 [==============================] - 4s 8ms/step - loss: 0.0732 - accuracy: 0.9724 - val_loss: 0.0493 - val_accuracy: 0.9759\n",
      "Epoch 23/30\n",
      "538/538 [==============================] - 4s 8ms/step - loss: 0.0712 - accuracy: 0.9719 - val_loss: 0.0500 - val_accuracy: 0.9785\n",
      "Epoch 24/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0647 - accuracy: 0.9738 - val_loss: 0.0540 - val_accuracy: 0.9767\n",
      "Epoch 25/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0651 - accuracy: 0.9737 - val_loss: 0.0466 - val_accuracy: 0.9793\n",
      "Epoch 26/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0616 - accuracy: 0.9755 - val_loss: 0.0447 - val_accuracy: 0.9788\n",
      "Epoch 27/30\n",
      "538/538 [==============================] - 4s 8ms/step - loss: 0.0603 - accuracy: 0.9741 - val_loss: 0.0442 - val_accuracy: 0.9811\n",
      "Epoch 28/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0599 - accuracy: 0.9764 - val_loss: 0.0460 - val_accuracy: 0.9785\n",
      "Epoch 29/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0578 - accuracy: 0.9771 - val_loss: 0.0463 - val_accuracy: 0.9788\n",
      "Epoch 30/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0587 - accuracy: 0.9762 - val_loss: 0.0438 - val_accuracy: 0.9796\n",
      "Fold 5, Best Validation Loss: 0.04378343001008034, Best Validation Accuracy: 0.9810936450958252\n",
      "Mean Best Validation Loss: 0.07898489609360695\n",
      "Mean Best Validation Accuracy: 0.9713205218315124\n"
     ]
    }
   ],
   "source": [
    "val_losses, val_accs = train_and_evaluate_lstm(X_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header = ['index', 'fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'mean_fold', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'mean_acc']\n",
    "index = 65\n",
    "row = [index] + val_losses + val_accs\n",
    "# 파일이 존재하지 않으면 헤더를 추가하고, 존재하면 행만 추가\n",
    "with open(csv_file_path, mode='a', newline='') as file:\n",
    "    csvwriter = csv.writer(file)\n",
    "    # 파일이 비어있는 경우 헤더를 추가\n",
    "    if file.tell() == 0:\n",
    "        csvwriter.writerow(header)\n",
    "    csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting\n",
    "plot_validation_metrics(val_losses, val_accs)\n",
    "# saving losses and accs history for comparision in the future\n",
    "append_to_val_dict(65, val_losses, val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 완료된 경우 바로 스프레드시트에 적어주세요!\n",
    "한 데이터셋에 너무 시간을 많이 쓰실 필요는 없습니다. 학습할 내용도 많고 다른 모델도 많이 테스트해봐야 해요.\n",
    "그리고 학습은 각 데이터셋에 대해 시간이 어느정도 소요되기 때문에 학습 과정에서는 다른 공부 하시는걸 추천드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10982047766447067, 0.10299540311098099, 0.07634427398443222, 0.061980895698070526, 0.04378343001008034]\n",
      "[0.9642233848571777, 0.9630599021911621, 0.9714950323104858, 0.9767306447029114, 0.9810936450958252]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{65: ([0.10982047766447067,\n",
       "   0.10299540311098099,\n",
       "   0.07634427398443222,\n",
       "   0.061980895698070526,\n",
       "   0.04378343001008034],\n",
       "  [0.9642233848571777,\n",
       "   0.9630599021911621,\n",
       "   0.9714950323104858,\n",
       "   0.9767306447029114,\n",
       "   0.9810936450958252])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val_losses)\n",
    "print(val_accs)\n",
    "val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been appended to output.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "data = {\n",
    "    65: ([0.10982047766447067,\n",
    "          0.10299540311098099,\n",
    "          0.07634427398443222,\n",
    "          0.061980895698070526,\n",
    "          0.04378343001008034],\n",
    "         [0.9642233848571777,\n",
    "          0.9630599021911621,\n",
    "          0.9714950323104858,\n",
    "          0.9767306447029114,\n",
    "          0.9810936450958252]),\n",
    "    30: ([0.10982047766447067,\n",
    "          0.10299540311098099,\n",
    "          0.07634427398443222,\n",
    "          0.061980895698070526,\n",
    "          0.04378343001008034],\n",
    "         [0.9642233848571777,\n",
    "          0.9630599021911621,\n",
    "          0.9714950323104858,\n",
    "          0.9767306447029114,\n",
    "          0.9810936450958252])\n",
    "}\n",
    "\n",
    "# CSV 파일에 저장할 데이터 준비\n",
    "csv_data = []\n",
    "for key, (val1, val2) in data.items():\n",
    "    csv_data.append([key] + val1 + val2)\n",
    "\n",
    "# 파일 저장 경로\n",
    "csv_file_path = \"output.csv\"\n",
    "\n",
    "# CSV 파일에 저장\n",
    "file_exists = os.path.isfile(csv_file_path)\n",
    "\n",
    "with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    if not file_exists:\n",
    "        # 헤더 추가\n",
    "        header = ['index', 'fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'mean_fold', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'mean_acc']\n",
    "        csvwriter.writerow(header)\n",
    "    for row in csv_data:\n",
    "        csvwriter.writerow(row)\n",
    "\n",
    "print(f\"Data has been appended to {csv_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
