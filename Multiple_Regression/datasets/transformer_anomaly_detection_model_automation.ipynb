{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'traceback_utils' from 'keras.src.utils' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense, LayerNormalization, Dropout, Add, MultiHeadAttention\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/_tf_keras/keras/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/api/activations/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/activations/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m elu\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exponential\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/activations/activations.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.activations.relu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelu\u001b[39m(x, negative_slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, max_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/ops/__init__.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m name_scope\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m operation_utils\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/ops/image.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasTensor\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m any_symbolic_tensors\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Operation\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperation_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_conv_output_shape\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRGBToGrayscale\u001b[39;00m(Operation):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/ops/operation.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m python_utils\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m traceback_utils\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_name\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.Operation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOperation\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'traceback_utils' from 'keras.src.utils' (unknown location)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, Add, MultiHeadAttention\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npz data to pd.\n",
    "def npz_to_csv(file_path):\n",
    "    file = np.load(file_path, allow_pickle=True)\n",
    "    X_df = pd.DataFrame(file['X'])\n",
    "    y_df = pd.DataFrame(file['y'])\n",
    "    return X_df, y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series 데이터에대하여 Pandas dataframe을 입력으로 받으면 lstm모델로 학습 후, 검증 loss값들과 accuracy값들을 return해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import legacy\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = Add()([x, inputs])\n",
    "    \n",
    "    # Feed Forward Part\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return Add()([x, res])\n",
    "\n",
    "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = Dense(mlp_units, activation='relu')(x)\n",
    "    x = Dropout(mlp_dropout)(x)\n",
    "    x = Dense(mlp_units, activation='relu')(x)\n",
    "    x = Dropout(mlp_dropout)(x)\n",
    "    \n",
    "    # Use Flatten to convert the output to 2D if needed before the final Dense layer\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    outputs = x  # Ensuring the final layer outputs the correct shape\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "def train_and_evaluate_transformer(X, y, n_splits=5, epochs=30, batch_size=32):\n",
    "    # 데이터 정규화\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    fold = 1\n",
    "    for train_idx, test_idx in tscv.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Input shape 맞추기 위함\n",
    "        X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "        \n",
    "        model = build_transformer_model(\n",
    "            input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "            head_size=256,\n",
    "            num_heads=4,\n",
    "            ff_dim=4,\n",
    "            num_transformer_blocks=4,\n",
    "            mlp_units=128,\n",
    "            dropout=0.25,\n",
    "            mlp_dropout=0.4,\n",
    "        )\n",
    "\n",
    "        model.compile(optimizer=legacy.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
    "        \n",
    "        # 가장 좋은 검증 성능을 기록\n",
    "        best_val_loss = min(history.history['val_loss'])\n",
    "        best_val_acc = max(history.history['val_accuracy'])\n",
    "        val_losses.append(best_val_loss)\n",
    "        val_accs.append(best_val_acc)\n",
    "        \n",
    "        # 모델 저장\n",
    "        model_path = f'gru_model_fold_{fold}.h5'\n",
    "        model.save(model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "\n",
    "        \n",
    "        print(f\"Fold {fold}, Best Validation Loss: {best_val_loss}, Best Validation Accuracy: {best_val_acc}\")\n",
    "        \n",
    "        fold += 1\n",
    "\n",
    "    mean_val_loss = np.mean(val_losses)\n",
    "    mean_val_acc = np.mean(val_accs)\n",
    "    \n",
    "    print(f\"Mean Best Validation Loss: {mean_val_loss}\")\n",
    "    print(f\"Mean Best Validation Accuracy: {mean_val_acc}\")\n",
    "    \n",
    "    return val_losses, val_accs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val losses와 val acc를 한 번에 plotting하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_metrics(val_losses, val_accs):\n",
    "    num_folds = len(val_losses)\n",
    "    \n",
    "    folds = range(1, num_folds + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "    \n",
    "    ax1.plot(folds, val_losses, marker='o', linestyle='-', color='b')\n",
    "    ax1.set_ylabel('Validation Loss')\n",
    "    ax1.set_title('Validation Loss and Accuracy')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(folds, val_accs, marker='o', linestyle='-', color='g')\n",
    "    ax2.set_xlabel('Fold')\n",
    "    ax2.set_ylabel('Validation Accuracy')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly data 비율을 나타내는 함수.\n",
    "혹시 너무 accuracy가 정확하게 나오는 경우, 모든 데이터셋에 대하여 0이라고 판단했는데 알고보니 레이블이 0인 데이터의 개수가 엄청나게 많을 수 있음.\n",
    "따라서 항상 의심할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomaly_rate(y):\n",
    "    return y.value_counts()[1] / (y.value_counts()[0] + y.value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 val_losses와 val_accs를 데이터셋 인덱스에 따라 dictionary로 저장하기 위한 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = {}\n",
    "def append_to_val_dict(index, val_loss, val_acc):\n",
    "    val_dict[index] = (val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 완료된 경우 스프레드시트에 적어주세요!\n",
    "한 데이터셋에 너무 시간을 많이 쓰실 필요는 없습니다. 학습할 내용도 많고 다른 모델도 많이 테스트해봐야 해요.\n",
    "그리고 학습은 각 데이터셋에 대해 시간이 어느정도 소요되기 때문에 학습 과정에서는 다른 공부 하시는걸 추천드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/path/to/Classical' 각자가 저장한 폴더로 연결해주세요\n",
    "file_path = './datasets/Classical/*.npz'\n",
    "file_list = glob.glob(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/Classical/57_DutchPowerDemand.npz',\n",
       " './datasets/Classical/55_Boschline.npz',\n",
       " './datasets/Classical/39_HSEFilters2.npz',\n",
       " './datasets/Classical/45_SWAT.npz',\n",
       " './datasets/Classical/62_ECoating.npz',\n",
       " './datasets/Classical/65_MachineryFault.npz',\n",
       " './datasets/Classical/43_Motorcondition2.npz',\n",
       " './datasets/Classical/54_CNCMachining.npz',\n",
       " './datasets/Classical/42_Motorcondition1.npz',\n",
       " './datasets/Classical/50_PLAID.npz',\n",
       " './datasets/Classical/48_Ladlefurnace.npz',\n",
       " './datasets/Classical/60_Concrete.npz',\n",
       " './datasets/Classical/49_Wafer2.npz',\n",
       " './datasets/Classical/35_IMS.npz',\n",
       " './datasets/Classical/66_Cuttingblade.npz',\n",
       " './datasets/Classical/38_HSEFilters1.npz',\n",
       " './datasets/Classical/51_PowerCons.npz',\n",
       " './datasets/Classical/63_Prensas.npz',\n",
       " './datasets/Classical/40_Yahoo1.npz',\n",
       " './datasets/Classical/36_PHM.npz',\n",
       " './datasets/Classical/52_Computers.npz',\n",
       " './datasets/Classical/44_HALsteamturbine.npz',\n",
       " './datasets/Classical/46_Sm4Tankbatch.npz',\n",
       " './datasets/Classical/34_Turbofan.npz',\n",
       " './datasets/Classical/61_Biopharmaceutical.npz',\n",
       " './datasets/Classical/59_UCISecom.npz',\n",
       " './datasets/Classical/58_MiningProcess.npz',\n",
       " './datasets/Classical/56_ShuttleMarottaValve.npz',\n",
       " './datasets/Classical/37_Shutlevalve.npz',\n",
       " './datasets/Classical/41_Yahoo2.npz',\n",
       " './datasets/Classical/64_PlasmaSpray.npz',\n",
       " './datasets/Classical/47_FordB_anreal.npz',\n",
       " './datasets/Classical/53_Walk2D.npz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "폴더안에 자동으로 학습하고 기록하고싶은 데이터만 넣어두고, 이 밑에 코드 돌려두세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size: 701290 bytes\n",
      "684.85\n"
     ]
    }
   ],
   "source": [
    "# 파일 크기 확인\n",
    " \n",
    "# 파일 단위로 바꾸기\n",
    "def convert_size(size_bytes):\n",
    "    import math\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "# 사용 예제\n",
    "file_size = os.path.getsize(file_list[0]) \n",
    "print('File Size:', file_size, 'bytes')\n",
    "a = convert_size(file_size)\n",
    "a = a.split(' ')\n",
    "print(float(a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "183/183 [==============================] - 5s 6ms/step - loss: 0.6636 - accuracy: 0.8527 - val_loss: 0.6201 - val_accuracy: 0.9397\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.6109 - accuracy: 0.8527 - val_loss: 0.5584 - val_accuracy: 0.9397\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.5681 - accuracy: 0.8527 - val_loss: 0.5070 - val_accuracy: 0.9397\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.5340 - accuracy: 0.8527 - val_loss: 0.4643 - val_accuracy: 0.9397\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.5069 - accuracy: 0.8527 - val_loss: 0.4290 - val_accuracy: 0.9397\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4855 - accuracy: 0.8527 - val_loss: 0.3996 - val_accuracy: 0.9397\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.8527 - val_loss: 0.3755 - val_accuracy: 0.9397\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.4558 - accuracy: 0.8527 - val_loss: 0.3556 - val_accuracy: 0.9397\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.4458 - accuracy: 0.8527 - val_loss: 0.3389 - val_accuracy: 0.9397\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4382 - accuracy: 0.8527 - val_loss: 0.3251 - val_accuracy: 0.9397\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4325 - accuracy: 0.8527 - val_loss: 0.3138 - val_accuracy: 0.9397\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4282 - accuracy: 0.8527 - val_loss: 0.3045 - val_accuracy: 0.9397\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4250 - accuracy: 0.8527 - val_loss: 0.2968 - val_accuracy: 0.9397\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4228 - accuracy: 0.8527 - val_loss: 0.2904 - val_accuracy: 0.9397\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.4212 - accuracy: 0.8527 - val_loss: 0.2855 - val_accuracy: 0.9397\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8527 - val_loss: 0.2811 - val_accuracy: 0.9397\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4193 - accuracy: 0.8527 - val_loss: 0.2775 - val_accuracy: 0.9397\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.4189 - accuracy: 0.8527 - val_loss: 0.2751 - val_accuracy: 0.9397\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.4185 - accuracy: 0.8527 - val_loss: 0.2728 - val_accuracy: 0.9397\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8527 - val_loss: 0.2712 - val_accuracy: 0.9397\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8527 - val_loss: 0.2695 - val_accuracy: 0.9397\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4181 - accuracy: 0.8527 - val_loss: 0.2687 - val_accuracy: 0.9397\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8527 - val_loss: 0.2677 - val_accuracy: 0.9397\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8527 - val_loss: 0.2672 - val_accuracy: 0.9397\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8527 - val_loss: 0.2664 - val_accuracy: 0.9397\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4179 - accuracy: 0.8527 - val_loss: 0.2660 - val_accuracy: 0.9397\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.4180 - accuracy: 0.8527 - val_loss: 0.2658 - val_accuracy: 0.9397\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.4180 - accuracy: 0.8527 - val_loss: 0.2654 - val_accuracy: 0.9397\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.4179 - accuracy: 0.8527 - val_loss: 0.2654 - val_accuracy: 0.9397\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.4179 - accuracy: 0.8527 - val_loss: 0.2654 - val_accuracy: 0.9397\n",
      "Fold 1, Best Validation Loss: 0.2653536796569824, Best Validation Accuracy: 0.9397260546684265\n",
      "Epoch 1/30\n",
      "365/365 [==============================] - 3s 5ms/step - loss: 0.6303 - accuracy: 0.8962 - val_loss: 0.5691 - val_accuracy: 0.9089\n",
      "Epoch 2/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.5291 - accuracy: 0.8962 - val_loss: 0.4818 - val_accuracy: 0.9089\n",
      "Epoch 3/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.4600 - accuracy: 0.8962 - val_loss: 0.4222 - val_accuracy: 0.9089\n",
      "Epoch 4/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.4138 - accuracy: 0.8962 - val_loss: 0.3821 - val_accuracy: 0.9089\n",
      "Epoch 5/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3834 - accuracy: 0.8962 - val_loss: 0.3551 - val_accuracy: 0.9089\n",
      "Epoch 6/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3636 - accuracy: 0.8962 - val_loss: 0.3373 - val_accuracy: 0.9089\n",
      "Epoch 7/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3511 - accuracy: 0.8962 - val_loss: 0.3255 - val_accuracy: 0.9089\n",
      "Epoch 8/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3432 - accuracy: 0.8962 - val_loss: 0.3179 - val_accuracy: 0.9089\n",
      "Epoch 9/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3386 - accuracy: 0.8962 - val_loss: 0.3131 - val_accuracy: 0.9089\n",
      "Epoch 10/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3360 - accuracy: 0.8962 - val_loss: 0.3102 - val_accuracy: 0.9089\n",
      "Epoch 11/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3345 - accuracy: 0.8962 - val_loss: 0.3084 - val_accuracy: 0.9089\n",
      "Epoch 12/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3339 - accuracy: 0.8962 - val_loss: 0.3074 - val_accuracy: 0.9089\n",
      "Epoch 13/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3335 - accuracy: 0.8962 - val_loss: 0.3068 - val_accuracy: 0.9089\n",
      "Epoch 14/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3334 - accuracy: 0.8962 - val_loss: 0.3065 - val_accuracy: 0.9089\n",
      "Epoch 15/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3061 - val_accuracy: 0.9089\n",
      "Epoch 16/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3061 - val_accuracy: 0.9089\n",
      "Epoch 17/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 18/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 19/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 20/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 21/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3059 - val_accuracy: 0.9089\n",
      "Epoch 22/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3059 - val_accuracy: 0.9089\n",
      "Epoch 23/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 24/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3059 - val_accuracy: 0.9089\n",
      "Epoch 25/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 26/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 27/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 28/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 29/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Epoch 30/30\n",
      "365/365 [==============================] - 2s 5ms/step - loss: 0.3333 - accuracy: 0.8962 - val_loss: 0.3060 - val_accuracy: 0.9089\n",
      "Fold 2, Best Validation Loss: 0.3058878481388092, Best Validation Accuracy: 0.9089041352272034\n",
      "Epoch 1/30\n",
      "548/548 [==============================] - 4s 5ms/step - loss: 0.6004 - accuracy: 0.9005 - val_loss: 0.5203 - val_accuracy: 0.9062\n",
      "Epoch 2/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.4711 - accuracy: 0.9005 - val_loss: 0.4229 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3996 - accuracy: 0.9005 - val_loss: 0.3690 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3610 - accuracy: 0.9005 - val_loss: 0.3400 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3408 - accuracy: 0.9005 - val_loss: 0.3248 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3310 - accuracy: 0.9005 - val_loss: 0.3173 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3267 - accuracy: 0.9005 - val_loss: 0.3140 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3250 - accuracy: 0.9005 - val_loss: 0.3125 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3243 - accuracy: 0.9005 - val_loss: 0.3119 - val_accuracy: 0.9062\n",
      "Epoch 10/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3242 - accuracy: 0.9005 - val_loss: 0.3117 - val_accuracy: 0.9062\n",
      "Epoch 11/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3116 - val_accuracy: 0.9062\n",
      "Epoch 12/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 13/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 14/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 15/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 16/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 17/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 18/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 19/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3116 - val_accuracy: 0.9062\n",
      "Epoch 20/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 21/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 22/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 23/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 24/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 25/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 26/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 27/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 28/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 29/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 30/30\n",
      "548/548 [==============================] - 3s 5ms/step - loss: 0.3241 - accuracy: 0.9005 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Fold 3, Best Validation Loss: 0.3114842176437378, Best Validation Accuracy: 0.9061644077301025\n",
      "Epoch 1/30\n",
      "730/730 [==============================] - 4s 5ms/step - loss: 0.5772 - accuracy: 0.9019 - val_loss: 0.4824 - val_accuracy: 0.9063\n",
      "Epoch 2/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.4307 - accuracy: 0.9019 - val_loss: 0.3837 - val_accuracy: 0.9063\n",
      "Epoch 3/30\n",
      "730/730 [==============================] - 3s 4ms/step - loss: 0.3648 - accuracy: 0.9019 - val_loss: 0.3399 - val_accuracy: 0.9063\n",
      "Epoch 4/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3366 - accuracy: 0.9019 - val_loss: 0.3212 - val_accuracy: 0.9063\n",
      "Epoch 5/30\n",
      "730/730 [==============================] - 3s 4ms/step - loss: 0.3257 - accuracy: 0.9019 - val_loss: 0.3143 - val_accuracy: 0.9063\n",
      "Epoch 6/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3221 - accuracy: 0.9019 - val_loss: 0.3119 - val_accuracy: 0.9063\n",
      "Epoch 7/30\n",
      "730/730 [==============================] - 3s 4ms/step - loss: 0.3211 - accuracy: 0.9019 - val_loss: 0.3112 - val_accuracy: 0.9063\n",
      "Epoch 8/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3210 - accuracy: 0.9019 - val_loss: 0.3111 - val_accuracy: 0.9063\n",
      "Epoch 9/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3111 - val_accuracy: 0.9063\n",
      "Epoch 10/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 11/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 12/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 13/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 14/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 15/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 16/30\n",
      "730/730 [==============================] - 3s 4ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 17/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 18/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 19/30\n",
      "730/730 [==============================] - 3s 4ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 20/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 21/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3111 - val_accuracy: 0.9063\n",
      "Epoch 22/30\n",
      "730/730 [==============================] - 3s 4ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 23/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3111 - val_accuracy: 0.9063\n",
      "Epoch 24/30\n",
      "730/730 [==============================] - 3s 4ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3111 - val_accuracy: 0.9063\n",
      "Epoch 25/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3111 - val_accuracy: 0.9063\n",
      "Epoch 26/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 27/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3111 - val_accuracy: 0.9063\n",
      "Epoch 28/30\n",
      "730/730 [==============================] - 4s 5ms/step - loss: 0.3209 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 29/30\n",
      "730/730 [==============================] - 3s 4ms/step - loss: 0.3210 - accuracy: 0.9019 - val_loss: 0.3110 - val_accuracy: 0.9063\n",
      "Epoch 30/30\n",
      "730/730 [==============================] - 3s 5ms/step - loss: 0.3210 - accuracy: 0.9019 - val_loss: 0.3111 - val_accuracy: 0.9063\n",
      "Fold 4, Best Validation Loss: 0.31100961565971375, Best Validation Accuracy: 0.9063355922698975\n",
      "Epoch 1/30\n",
      "913/913 [==============================] - 6s 5ms/step - loss: 0.5554 - accuracy: 0.9028 - val_loss: 0.4647 - val_accuracy: 0.8878\n",
      "Epoch 2/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.4002 - accuracy: 0.9028 - val_loss: 0.3823 - val_accuracy: 0.8878\n",
      "Epoch 3/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3434 - accuracy: 0.9028 - val_loss: 0.3565 - val_accuracy: 0.8878\n",
      "Epoch 4/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3249 - accuracy: 0.9028 - val_loss: 0.3512 - val_accuracy: 0.8878\n",
      "Epoch 5/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3200 - accuracy: 0.9028 - val_loss: 0.3513 - val_accuracy: 0.8878\n",
      "Epoch 6/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3191 - accuracy: 0.9028 - val_loss: 0.3518 - val_accuracy: 0.8878\n",
      "Epoch 7/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3521 - val_accuracy: 0.8878\n",
      "Epoch 8/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3522 - val_accuracy: 0.8878\n",
      "Epoch 9/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3523 - val_accuracy: 0.8878\n",
      "Epoch 10/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3523 - val_accuracy: 0.8878\n",
      "Epoch 11/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3522 - val_accuracy: 0.8878\n",
      "Epoch 12/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3523 - val_accuracy: 0.8878\n",
      "Epoch 13/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3523 - val_accuracy: 0.8878\n",
      "Epoch 14/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3523 - val_accuracy: 0.8878\n",
      "Epoch 15/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3523 - val_accuracy: 0.8878\n",
      "Epoch 16/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3522 - val_accuracy: 0.8878\n",
      "Epoch 17/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3521 - val_accuracy: 0.8878\n",
      "Epoch 18/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3521 - val_accuracy: 0.8878\n",
      "Epoch 19/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3523 - val_accuracy: 0.8878\n",
      "Epoch 20/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3522 - val_accuracy: 0.8878\n",
      "Epoch 21/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3521 - val_accuracy: 0.8878\n",
      "Epoch 22/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3522 - val_accuracy: 0.8878\n",
      "Epoch 23/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3522 - val_accuracy: 0.8878\n",
      "Epoch 24/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3521 - val_accuracy: 0.8878\n",
      "Epoch 25/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3523 - val_accuracy: 0.8878\n",
      "Epoch 26/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3521 - val_accuracy: 0.8878\n",
      "Epoch 27/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3521 - val_accuracy: 0.8878\n",
      "Epoch 28/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3523 - val_accuracy: 0.8878\n",
      "Epoch 29/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3521 - val_accuracy: 0.8878\n",
      "Epoch 30/30\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.3520 - val_accuracy: 0.8878\n",
      "Fold 5, Best Validation Loss: 0.35122957825660706, Best Validation Accuracy: 0.8878424763679504\n",
      "Mean Best Validation Loss: 0.30899298787117\n",
      "Mean Best Validation Accuracy: 0.9097945332527161\n",
      "Epoch 1/30\n",
      "222/222 [==============================] - 3s 7ms/step - loss: 0.2698 - accuracy: 0.8906 - val_loss: 0.2672 - val_accuracy: 0.8914\n",
      "Epoch 2/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1896 - accuracy: 0.9238 - val_loss: 0.2214 - val_accuracy: 0.9231\n",
      "Epoch 3/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1696 - accuracy: 0.9262 - val_loss: 0.2657 - val_accuracy: 0.8834\n",
      "Epoch 4/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1638 - accuracy: 0.9292 - val_loss: 0.2190 - val_accuracy: 0.8904\n",
      "Epoch 5/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1531 - accuracy: 0.9377 - val_loss: 0.2231 - val_accuracy: 0.8942\n",
      "Epoch 6/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1443 - accuracy: 0.9416 - val_loss: 0.2768 - val_accuracy: 0.8825\n",
      "Epoch 7/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1446 - accuracy: 0.9422 - val_loss: 0.2218 - val_accuracy: 0.8869\n",
      "Epoch 8/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1455 - accuracy: 0.9399 - val_loss: 0.2602 - val_accuracy: 0.8797\n",
      "Epoch 9/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1462 - accuracy: 0.9388 - val_loss: 0.2827 - val_accuracy: 0.8778\n",
      "Epoch 10/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1403 - accuracy: 0.9453 - val_loss: 0.2709 - val_accuracy: 0.8783\n",
      "Epoch 11/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1358 - accuracy: 0.9446 - val_loss: 0.3104 - val_accuracy: 0.8771\n",
      "Epoch 12/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1354 - accuracy: 0.9464 - val_loss: 0.2436 - val_accuracy: 0.8739\n",
      "Epoch 13/30\n",
      "222/222 [==============================] - 2s 8ms/step - loss: 0.1366 - accuracy: 0.9457 - val_loss: 0.2881 - val_accuracy: 0.8771\n",
      "Epoch 14/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1346 - accuracy: 0.9453 - val_loss: 0.2596 - val_accuracy: 0.8869\n",
      "Epoch 15/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1301 - accuracy: 0.9457 - val_loss: 0.2826 - val_accuracy: 0.8722\n",
      "Epoch 16/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1295 - accuracy: 0.9460 - val_loss: 0.3266 - val_accuracy: 0.8832\n",
      "Epoch 17/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1238 - accuracy: 0.9483 - val_loss: 0.2885 - val_accuracy: 0.8770\n",
      "Epoch 18/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1330 - accuracy: 0.9464 - val_loss: 0.2635 - val_accuracy: 0.8975\n",
      "Epoch 19/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1157 - accuracy: 0.9549 - val_loss: 0.2552 - val_accuracy: 0.9034\n",
      "Epoch 20/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1134 - accuracy: 0.9536 - val_loss: 0.3636 - val_accuracy: 0.8793\n",
      "Epoch 21/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1175 - accuracy: 0.9522 - val_loss: 0.3211 - val_accuracy: 0.8983\n",
      "Epoch 22/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1125 - accuracy: 0.9575 - val_loss: 0.3408 - val_accuracy: 0.8856\n",
      "Epoch 23/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1060 - accuracy: 0.9586 - val_loss: 0.3645 - val_accuracy: 0.8753\n",
      "Epoch 24/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1109 - accuracy: 0.9570 - val_loss: 0.4016 - val_accuracy: 0.8756\n",
      "Epoch 25/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1062 - accuracy: 0.9573 - val_loss: 0.3079 - val_accuracy: 0.8893\n",
      "Epoch 26/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1052 - accuracy: 0.9590 - val_loss: 0.3783 - val_accuracy: 0.8873\n",
      "Epoch 27/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1033 - accuracy: 0.9579 - val_loss: 0.4052 - val_accuracy: 0.8846\n",
      "Epoch 28/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.1034 - accuracy: 0.9630 - val_loss: 0.3898 - val_accuracy: 0.8865\n",
      "Epoch 29/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.0935 - accuracy: 0.9633 - val_loss: 0.4833 - val_accuracy: 0.8842\n",
      "Epoch 30/30\n",
      "222/222 [==============================] - 2s 7ms/step - loss: 0.0938 - accuracy: 0.9648 - val_loss: 0.4894 - val_accuracy: 0.8777\n",
      "Fold 1, Best Validation Loss: 0.21896110475063324, Best Validation Accuracy: 0.9230877757072449\n",
      "Epoch 1/30\n",
      "443/443 [==============================] - 4s 6ms/step - loss: 0.2296 - accuracy: 0.9093 - val_loss: 0.1777 - val_accuracy: 0.9480\n",
      "Epoch 2/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1792 - accuracy: 0.9246 - val_loss: 0.1786 - val_accuracy: 0.9416\n",
      "Epoch 3/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1713 - accuracy: 0.9299 - val_loss: 0.1709 - val_accuracy: 0.9478\n",
      "Epoch 4/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1587 - accuracy: 0.9319 - val_loss: 0.1765 - val_accuracy: 0.9433\n",
      "Epoch 5/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1563 - accuracy: 0.9337 - val_loss: 0.1740 - val_accuracy: 0.9444\n",
      "Epoch 6/30\n",
      "443/443 [==============================] - 3s 7ms/step - loss: 0.1545 - accuracy: 0.9334 - val_loss: 0.1902 - val_accuracy: 0.9427\n",
      "Epoch 7/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1474 - accuracy: 0.9343 - val_loss: 0.1673 - val_accuracy: 0.9570\n",
      "Epoch 8/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1435 - accuracy: 0.9348 - val_loss: 0.1741 - val_accuracy: 0.9556\n",
      "Epoch 9/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1431 - accuracy: 0.9367 - val_loss: 0.1973 - val_accuracy: 0.9584\n",
      "Epoch 10/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1464 - accuracy: 0.9359 - val_loss: 0.1625 - val_accuracy: 0.9573\n",
      "Epoch 11/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1407 - accuracy: 0.9338 - val_loss: 0.1429 - val_accuracy: 0.9562\n",
      "Epoch 12/30\n",
      "443/443 [==============================] - 3s 7ms/step - loss: 0.1400 - accuracy: 0.9369 - val_loss: 0.1229 - val_accuracy: 0.9624\n",
      "Epoch 13/30\n",
      "443/443 [==============================] - 3s 7ms/step - loss: 0.1324 - accuracy: 0.9396 - val_loss: 0.1208 - val_accuracy: 0.9664\n",
      "Epoch 14/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1342 - accuracy: 0.9394 - val_loss: 0.1140 - val_accuracy: 0.9705\n",
      "Epoch 15/30\n",
      "443/443 [==============================] - 3s 7ms/step - loss: 0.1346 - accuracy: 0.9406 - val_loss: 0.1170 - val_accuracy: 0.9678\n",
      "Epoch 16/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1283 - accuracy: 0.9442 - val_loss: 0.1259 - val_accuracy: 0.9641\n",
      "Epoch 17/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1248 - accuracy: 0.9471 - val_loss: 0.1305 - val_accuracy: 0.9713\n",
      "Epoch 18/30\n",
      "443/443 [==============================] - 3s 7ms/step - loss: 0.1237 - accuracy: 0.9476 - val_loss: 0.1402 - val_accuracy: 0.9635\n",
      "Epoch 19/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1215 - accuracy: 0.9453 - val_loss: 0.1514 - val_accuracy: 0.9608\n",
      "Epoch 20/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1227 - accuracy: 0.9465 - val_loss: 0.1200 - val_accuracy: 0.9664\n",
      "Epoch 21/30\n",
      "443/443 [==============================] - 3s 7ms/step - loss: 0.1206 - accuracy: 0.9449 - val_loss: 0.1355 - val_accuracy: 0.9617\n",
      "Epoch 22/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1167 - accuracy: 0.9477 - val_loss: 0.1524 - val_accuracy: 0.9608\n",
      "Epoch 23/30\n",
      "443/443 [==============================] - 3s 7ms/step - loss: 0.1169 - accuracy: 0.9477 - val_loss: 0.1494 - val_accuracy: 0.9006\n",
      "Epoch 24/30\n",
      "443/443 [==============================] - 3s 7ms/step - loss: 0.1158 - accuracy: 0.9490 - val_loss: 0.1279 - val_accuracy: 0.9649\n",
      "Epoch 25/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1211 - accuracy: 0.9497 - val_loss: 0.1520 - val_accuracy: 0.9198\n",
      "Epoch 26/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1161 - accuracy: 0.9488 - val_loss: 0.1301 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1166 - accuracy: 0.9510 - val_loss: 0.1272 - val_accuracy: 0.9171\n",
      "Epoch 28/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1185 - accuracy: 0.9495 - val_loss: 0.1720 - val_accuracy: 0.8976\n",
      "Epoch 29/30\n",
      "443/443 [==============================] - 3s 6ms/step - loss: 0.1178 - accuracy: 0.9506 - val_loss: 0.1356 - val_accuracy: 0.9159\n",
      "Epoch 30/30\n",
      "443/443 [==============================] - 3s 7ms/step - loss: 0.1123 - accuracy: 0.9525 - val_loss: 0.1367 - val_accuracy: 0.9703\n",
      "Fold 2, Best Validation Loss: 0.11401791125535965, Best Validation Accuracy: 0.9712992906570435\n",
      "Epoch 1/30\n",
      "664/664 [==============================] - 5s 6ms/step - loss: 0.1989 - accuracy: 0.9238 - val_loss: 0.2361 - val_accuracy: 0.9481\n",
      "Epoch 2/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1585 - accuracy: 0.9381 - val_loss: 0.2018 - val_accuracy: 0.9485\n",
      "Epoch 3/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1530 - accuracy: 0.9407 - val_loss: 0.1534 - val_accuracy: 0.9494\n",
      "Epoch 4/30\n",
      "664/664 [==============================] - 4s 7ms/step - loss: 0.1444 - accuracy: 0.9415 - val_loss: 0.1168 - val_accuracy: 0.9555\n",
      "Epoch 5/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1409 - accuracy: 0.9453 - val_loss: 0.1308 - val_accuracy: 0.9495\n",
      "Epoch 6/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1319 - accuracy: 0.9476 - val_loss: 0.1291 - val_accuracy: 0.9524\n",
      "Epoch 7/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1267 - accuracy: 0.9503 - val_loss: 0.1502 - val_accuracy: 0.9516\n",
      "Epoch 8/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1251 - accuracy: 0.9511 - val_loss: 0.1449 - val_accuracy: 0.9533\n",
      "Epoch 9/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1202 - accuracy: 0.9503 - val_loss: 0.1378 - val_accuracy: 0.9574\n",
      "Epoch 10/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1160 - accuracy: 0.9545 - val_loss: 0.1490 - val_accuracy: 0.9552\n",
      "Epoch 11/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1137 - accuracy: 0.9551 - val_loss: 0.1800 - val_accuracy: 0.9498\n",
      "Epoch 12/30\n",
      "664/664 [==============================] - 4s 7ms/step - loss: 0.1099 - accuracy: 0.9583 - val_loss: 0.2188 - val_accuracy: 0.9502\n",
      "Epoch 13/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1108 - accuracy: 0.9566 - val_loss: 0.1534 - val_accuracy: 0.9587\n",
      "Epoch 14/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1113 - accuracy: 0.9575 - val_loss: 0.1522 - val_accuracy: 0.9552\n",
      "Epoch 15/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1067 - accuracy: 0.9582 - val_loss: 0.1500 - val_accuracy: 0.9563\n",
      "Epoch 16/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1028 - accuracy: 0.9601 - val_loss: 0.1515 - val_accuracy: 0.9579\n",
      "Epoch 17/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1016 - accuracy: 0.9601 - val_loss: 0.1513 - val_accuracy: 0.9579\n",
      "Epoch 18/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1019 - accuracy: 0.9587 - val_loss: 0.1329 - val_accuracy: 0.9623\n",
      "Epoch 19/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1024 - accuracy: 0.9609 - val_loss: 0.1461 - val_accuracy: 0.9596\n",
      "Epoch 20/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1020 - accuracy: 0.9607 - val_loss: 0.1622 - val_accuracy: 0.9590\n",
      "Epoch 21/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.1002 - accuracy: 0.9614 - val_loss: 0.1580 - val_accuracy: 0.9586\n",
      "Epoch 22/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0981 - accuracy: 0.9614 - val_loss: 0.2421 - val_accuracy: 0.9529\n",
      "Epoch 23/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0960 - accuracy: 0.9623 - val_loss: 0.1977 - val_accuracy: 0.9552\n",
      "Epoch 24/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0965 - accuracy: 0.9623 - val_loss: 0.1367 - val_accuracy: 0.9634\n",
      "Epoch 25/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0975 - accuracy: 0.9626 - val_loss: 0.1671 - val_accuracy: 0.9582\n",
      "Epoch 26/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0957 - accuracy: 0.9630 - val_loss: 0.1689 - val_accuracy: 0.9557\n",
      "Epoch 27/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0976 - accuracy: 0.9619 - val_loss: 0.1580 - val_accuracy: 0.9574\n",
      "Epoch 28/30\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0908 - accuracy: 0.9654 - val_loss: 0.1649 - val_accuracy: 0.9567\n",
      "Epoch 29/30\n",
      "664/664 [==============================] - 4s 7ms/step - loss: 0.0943 - accuracy: 0.9635 - val_loss: 0.1934 - val_accuracy: 0.9533\n",
      "Epoch 30/30\n",
      "664/664 [==============================] - 4s 7ms/step - loss: 0.0913 - accuracy: 0.9650 - val_loss: 0.2059 - val_accuracy: 0.9549\n",
      "Fold 3, Best Validation Loss: 0.11680148541927338, Best Validation Accuracy: 0.9633818864822388\n",
      "Epoch 1/30\n",
      "885/885 [==============================] - 7s 6ms/step - loss: 0.1972 - accuracy: 0.9312 - val_loss: 0.1537 - val_accuracy: 0.9606\n",
      "Epoch 2/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.1579 - accuracy: 0.9428 - val_loss: 0.1096 - val_accuracy: 0.9655\n",
      "Epoch 3/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1433 - accuracy: 0.9473 - val_loss: 0.1097 - val_accuracy: 0.9645\n",
      "Epoch 4/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.1339 - accuracy: 0.9507 - val_loss: 0.1041 - val_accuracy: 0.9565\n",
      "Epoch 5/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.1322 - accuracy: 0.9503 - val_loss: 0.1204 - val_accuracy: 0.9603\n",
      "Epoch 6/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.1240 - accuracy: 0.9536 - val_loss: 0.1259 - val_accuracy: 0.9655\n",
      "Epoch 7/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1239 - accuracy: 0.9518 - val_loss: 0.1251 - val_accuracy: 0.9604\n",
      "Epoch 8/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1193 - accuracy: 0.9553 - val_loss: 0.1145 - val_accuracy: 0.9606\n",
      "Epoch 9/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1153 - accuracy: 0.9568 - val_loss: 0.1105 - val_accuracy: 0.9624\n",
      "Epoch 10/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.1100 - accuracy: 0.9583 - val_loss: 0.0885 - val_accuracy: 0.9665\n",
      "Epoch 11/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.1084 - accuracy: 0.9592 - val_loss: 0.0899 - val_accuracy: 0.9647\n",
      "Epoch 12/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1082 - accuracy: 0.9587 - val_loss: 0.0887 - val_accuracy: 0.9656\n",
      "Epoch 13/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1025 - accuracy: 0.9616 - val_loss: 0.0981 - val_accuracy: 0.9628\n",
      "Epoch 14/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.1008 - accuracy: 0.9624 - val_loss: 0.1087 - val_accuracy: 0.9664\n",
      "Epoch 15/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0992 - accuracy: 0.9607 - val_loss: 0.0873 - val_accuracy: 0.9610\n",
      "Epoch 16/30\n",
      "885/885 [==============================] - 6s 7ms/step - loss: 0.0986 - accuracy: 0.9622 - val_loss: 0.0940 - val_accuracy: 0.9607\n",
      "Epoch 17/30\n",
      "885/885 [==============================] - 6s 7ms/step - loss: 0.0963 - accuracy: 0.9627 - val_loss: 0.0954 - val_accuracy: 0.9600\n",
      "Epoch 18/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0935 - accuracy: 0.9643 - val_loss: 0.1149 - val_accuracy: 0.9668\n",
      "Epoch 19/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0925 - accuracy: 0.9649 - val_loss: 0.0977 - val_accuracy: 0.9541\n",
      "Epoch 20/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0912 - accuracy: 0.9638 - val_loss: 0.0988 - val_accuracy: 0.9642\n",
      "Epoch 21/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0923 - accuracy: 0.9642 - val_loss: 0.1123 - val_accuracy: 0.9459\n",
      "Epoch 22/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0884 - accuracy: 0.9655 - val_loss: 0.1480 - val_accuracy: 0.9501\n",
      "Epoch 23/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0876 - accuracy: 0.9662 - val_loss: 0.1176 - val_accuracy: 0.9589\n",
      "Epoch 24/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0868 - accuracy: 0.9656 - val_loss: 0.1012 - val_accuracy: 0.9620\n",
      "Epoch 25/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0863 - accuracy: 0.9672 - val_loss: 0.0964 - val_accuracy: 0.9692\n",
      "Epoch 26/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0872 - accuracy: 0.9667 - val_loss: 0.1015 - val_accuracy: 0.9642\n",
      "Epoch 27/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0861 - accuracy: 0.9669 - val_loss: 0.0974 - val_accuracy: 0.9692\n",
      "Epoch 28/30\n",
      "885/885 [==============================] - 5s 6ms/step - loss: 0.0838 - accuracy: 0.9678 - val_loss: 0.0851 - val_accuracy: 0.9617\n",
      "Epoch 29/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0856 - accuracy: 0.9670 - val_loss: 0.0993 - val_accuracy: 0.9637\n",
      "Epoch 30/30\n",
      "885/885 [==============================] - 6s 6ms/step - loss: 0.0843 - accuracy: 0.9682 - val_loss: 0.0981 - val_accuracy: 0.9620\n",
      "Fold 4, Best Validation Loss: 0.08507449179887772, Best Validation Accuracy: 0.9691785573959351\n",
      "Epoch 1/30\n",
      "1106/1106 [==============================] - 8s 6ms/step - loss: 0.1744 - accuracy: 0.9414 - val_loss: 0.2631 - val_accuracy: 0.9306\n",
      "Epoch 2/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.1388 - accuracy: 0.9504 - val_loss: 0.4092 - val_accuracy: 0.9053\n",
      "Epoch 3/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.1306 - accuracy: 0.9513 - val_loss: 0.3379 - val_accuracy: 0.9253\n",
      "Epoch 4/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.1239 - accuracy: 0.9541 - val_loss: 0.4147 - val_accuracy: 0.9089\n",
      "Epoch 5/30\n",
      "1106/1106 [==============================] - 8s 7ms/step - loss: 0.1190 - accuracy: 0.9561 - val_loss: 0.3562 - val_accuracy: 0.9220\n",
      "Epoch 6/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.1147 - accuracy: 0.9574 - val_loss: 0.3801 - val_accuracy: 0.9205\n",
      "Epoch 7/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1120 - accuracy: 0.9578 - val_loss: 0.4137 - val_accuracy: 0.9130\n",
      "Epoch 8/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1116 - accuracy: 0.9571 - val_loss: 0.2455 - val_accuracy: 0.9304\n",
      "Epoch 9/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1089 - accuracy: 0.9581 - val_loss: 0.3428 - val_accuracy: 0.9307\n",
      "Epoch 10/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.1053 - accuracy: 0.9611 - val_loss: 0.3700 - val_accuracy: 0.9159\n",
      "Epoch 11/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.1035 - accuracy: 0.9610 - val_loss: 0.4271 - val_accuracy: 0.9200\n",
      "Epoch 12/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1022 - accuracy: 0.9598 - val_loss: 0.3704 - val_accuracy: 0.9174\n",
      "Epoch 13/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.1001 - accuracy: 0.9617 - val_loss: 0.2875 - val_accuracy: 0.9369\n",
      "Epoch 14/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0981 - accuracy: 0.9624 - val_loss: 0.3740 - val_accuracy: 0.9248\n",
      "Epoch 15/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.0966 - accuracy: 0.9624 - val_loss: 0.3499 - val_accuracy: 0.9227\n",
      "Epoch 16/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0914 - accuracy: 0.9643 - val_loss: 0.3030 - val_accuracy: 0.9313\n",
      "Epoch 17/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.0919 - accuracy: 0.9644 - val_loss: 0.2340 - val_accuracy: 0.9460\n",
      "Epoch 18/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.0886 - accuracy: 0.9647 - val_loss: 0.3065 - val_accuracy: 0.9395\n",
      "Epoch 19/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.0898 - accuracy: 0.9657 - val_loss: 0.2768 - val_accuracy: 0.9399\n",
      "Epoch 20/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.0877 - accuracy: 0.9662 - val_loss: 0.3277 - val_accuracy: 0.9287\n",
      "Epoch 21/30\n",
      "1106/1106 [==============================] - 8s 7ms/step - loss: 0.0864 - accuracy: 0.9664 - val_loss: 0.3393 - val_accuracy: 0.9290\n",
      "Epoch 22/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0860 - accuracy: 0.9662 - val_loss: 0.2700 - val_accuracy: 0.9377\n",
      "Epoch 23/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0845 - accuracy: 0.9662 - val_loss: 0.2944 - val_accuracy: 0.9399\n",
      "Epoch 24/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0864 - accuracy: 0.9668 - val_loss: 0.3024 - val_accuracy: 0.9347\n",
      "Epoch 25/30\n",
      "1106/1106 [==============================] - 8s 7ms/step - loss: 0.0840 - accuracy: 0.9667 - val_loss: 0.2590 - val_accuracy: 0.9422\n",
      "Epoch 26/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.0845 - accuracy: 0.9673 - val_loss: 0.2575 - val_accuracy: 0.9432\n",
      "Epoch 27/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.0843 - accuracy: 0.9673 - val_loss: 0.2485 - val_accuracy: 0.9368\n",
      "Epoch 28/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0840 - accuracy: 0.9669 - val_loss: 0.3346 - val_accuracy: 0.9303\n",
      "Epoch 29/30\n",
      "1106/1106 [==============================] - 7s 7ms/step - loss: 0.0849 - accuracy: 0.9670 - val_loss: 0.3735 - val_accuracy: 0.9214\n",
      "Epoch 30/30\n",
      "1106/1106 [==============================] - 7s 6ms/step - loss: 0.0824 - accuracy: 0.9670 - val_loss: 0.2318 - val_accuracy: 0.9429\n",
      "Fold 5, Best Validation Loss: 0.23178640007972717, Best Validation Accuracy: 0.9459918141365051\n",
      "Mean Best Validation Loss: 0.15332827866077423\n",
      "Mean Best Validation Accuracy: 0.9545878648757935\n",
      "Epoch 1/30\n",
      "19/19 [==============================] - 3s 25ms/step - loss: 0.1502 - accuracy: 0.9299 - val_loss: 3.7530 - val_accuracy: 0.5712\n",
      "Epoch 2/30\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.7487 - val_accuracy: 0.5712\n",
      "Epoch 3/30\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 5.6559e-04 - accuracy: 1.0000 - val_loss: 5.1424 - val_accuracy: 0.5712\n",
      "Epoch 4/30\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 4.7231 - val_accuracy: 0.5712\n",
      "Epoch 5/30\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 3.8938e-04 - accuracy: 1.0000 - val_loss: 5.1842 - val_accuracy: 0.5712\n",
      "Epoch 6/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.4261e-04 - accuracy: 1.0000 - val_loss: 5.4297 - val_accuracy: 0.5712\n",
      "Epoch 7/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 2.0953e-04 - accuracy: 1.0000 - val_loss: 5.5669 - val_accuracy: 0.5712\n",
      "Epoch 8/30\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 2.2314e-04 - accuracy: 1.0000 - val_loss: 5.7414 - val_accuracy: 0.5712\n",
      "Epoch 9/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 1.0189e-04 - accuracy: 1.0000 - val_loss: 5.8641 - val_accuracy: 0.5712\n",
      "Epoch 10/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.0879e-04 - accuracy: 1.0000 - val_loss: 6.0015 - val_accuracy: 0.5712\n",
      "Epoch 11/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 1.0159e-04 - accuracy: 1.0000 - val_loss: 6.1201 - val_accuracy: 0.5712\n",
      "Epoch 12/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 6.5375e-05 - accuracy: 1.0000 - val_loss: 6.1949 - val_accuracy: 0.5712\n",
      "Epoch 13/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 9.0635e-05 - accuracy: 1.0000 - val_loss: 6.2748 - val_accuracy: 0.5712\n",
      "Epoch 14/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 6.8550e-05 - accuracy: 1.0000 - val_loss: 6.3413 - val_accuracy: 0.5712\n",
      "Epoch 15/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 3.9427e-05 - accuracy: 1.0000 - val_loss: 6.3924 - val_accuracy: 0.5712\n",
      "Epoch 16/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 1.1365e-04 - accuracy: 1.0000 - val_loss: 6.4582 - val_accuracy: 0.5712\n",
      "Epoch 17/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 4.4822e-05 - accuracy: 1.0000 - val_loss: 6.4970 - val_accuracy: 0.5712\n",
      "Epoch 18/30\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 1.0177e-04 - accuracy: 1.0000 - val_loss: 6.5267 - val_accuracy: 0.5712\n",
      "Epoch 19/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 7.4387e-05 - accuracy: 1.0000 - val_loss: 6.5636 - val_accuracy: 0.5712\n",
      "Epoch 20/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 3.4364e-05 - accuracy: 1.0000 - val_loss: 6.6027 - val_accuracy: 0.5712\n",
      "Epoch 21/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 3.9187e-05 - accuracy: 1.0000 - val_loss: 6.6124 - val_accuracy: 0.5712\n",
      "Epoch 22/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.5142e-05 - accuracy: 1.0000 - val_loss: 6.6140 - val_accuracy: 0.5712\n",
      "Epoch 23/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 1.4257e-05 - accuracy: 1.0000 - val_loss: 6.6142 - val_accuracy: 0.5712\n",
      "Epoch 24/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 2.9315e-05 - accuracy: 1.0000 - val_loss: 6.6144 - val_accuracy: 0.5712\n",
      "Epoch 25/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 1.0473e-04 - accuracy: 1.0000 - val_loss: 6.6145 - val_accuracy: 0.5712\n",
      "Epoch 26/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 1.7931e-05 - accuracy: 1.0000 - val_loss: 6.6145 - val_accuracy: 0.5712\n",
      "Epoch 27/30\n",
      "19/19 [==============================] - 0s 14ms/step - loss: 1.3804e-05 - accuracy: 1.0000 - val_loss: 6.6145 - val_accuracy: 0.5712\n",
      "Epoch 28/30\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 1.1114e-05 - accuracy: 1.0000 - val_loss: 6.6145 - val_accuracy: 0.5712\n",
      "Epoch 29/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 1.5991e-05 - accuracy: 1.0000 - val_loss: 6.6145 - val_accuracy: 0.5712\n",
      "Epoch 30/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 1.8442e-05 - accuracy: 1.0000 - val_loss: 6.6145 - val_accuracy: 0.5712\n",
      "Fold 1, Best Validation Loss: 3.7530465126037598, Best Validation Accuracy: 0.5711835622787476\n",
      "Epoch 1/30\n",
      "37/37 [==============================] - 2s 17ms/step - loss: 0.1314 - accuracy: 0.9392 - val_loss: 1.4895 - val_accuracy: 0.7942\n",
      "Epoch 2/30\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0118 - accuracy: 0.9983 - val_loss: 2.1670 - val_accuracy: 0.8027\n",
      "Epoch 3/30\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 7.3068e-04 - accuracy: 1.0000 - val_loss: 2.8839 - val_accuracy: 0.7633\n",
      "Epoch 4/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 2.4469 - val_accuracy: 0.8079\n",
      "Epoch 5/30\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 8.3267e-04 - accuracy: 1.0000 - val_loss: 3.1958 - val_accuracy: 0.7581\n",
      "Epoch 6/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0444 - accuracy: 0.9906 - val_loss: 0.9820 - val_accuracy: 0.6415\n",
      "Epoch 7/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0337 - accuracy: 0.9932 - val_loss: 1.4371 - val_accuracy: 0.7787\n",
      "Epoch 8/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5343 - val_accuracy: 0.7341\n",
      "Epoch 9/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.5357e-04 - accuracy: 1.0000 - val_loss: 2.7373 - val_accuracy: 0.7324\n",
      "Epoch 10/30\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 2.3040 - val_accuracy: 0.7479\n",
      "Epoch 11/30\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 6.7436e-04 - accuracy: 1.0000 - val_loss: 2.0675 - val_accuracy: 0.7341\n",
      "Epoch 12/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 2.1485 - val_accuracy: 0.7702\n",
      "Epoch 13/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 0.9991 - val_loss: 3.9456 - val_accuracy: 0.6690\n",
      "Epoch 14/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 0.9974 - val_loss: 4.2975 - val_accuracy: 0.5969\n",
      "Epoch 15/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 4.8334 - val_accuracy: 0.6261\n",
      "Epoch 16/30\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 2.4630e-04 - accuracy: 1.0000 - val_loss: 5.2375 - val_accuracy: 0.6261\n",
      "Epoch 17/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 1.9912e-05 - accuracy: 1.0000 - val_loss: 5.3944 - val_accuracy: 0.6261\n",
      "Epoch 18/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 2.1176e-04 - accuracy: 1.0000 - val_loss: 5.3586 - val_accuracy: 0.6295\n",
      "Epoch 19/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 3.1995e-05 - accuracy: 1.0000 - val_loss: 5.3679 - val_accuracy: 0.6295\n",
      "Epoch 20/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 5.5218 - val_accuracy: 0.6209\n",
      "Epoch 21/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 6.4173e-05 - accuracy: 1.0000 - val_loss: 5.5539 - val_accuracy: 0.6209\n",
      "Epoch 22/30\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0087 - accuracy: 0.9991 - val_loss: 3.8764 - val_accuracy: 0.6278\n",
      "Epoch 23/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 2.7101e-04 - accuracy: 1.0000 - val_loss: 3.8768 - val_accuracy: 0.6278\n",
      "Epoch 24/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 3.5029 - val_accuracy: 0.6621\n",
      "Epoch 25/30\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 7.8600e-05 - accuracy: 1.0000 - val_loss: 4.0931 - val_accuracy: 0.6621\n",
      "Epoch 26/30\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 3.7955e-04 - accuracy: 1.0000 - val_loss: 4.0877 - val_accuracy: 0.6672\n",
      "Epoch 27/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 3.2607e-04 - accuracy: 1.0000 - val_loss: 3.6345 - val_accuracy: 0.7187\n",
      "Epoch 28/30\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0108 - accuracy: 0.9991 - val_loss: 5.0945 - val_accuracy: 0.6329\n",
      "Epoch 29/30\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 4.6442e-04 - accuracy: 1.0000 - val_loss: 5.1623 - val_accuracy: 0.6432\n",
      "Epoch 30/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 1.9644e-04 - accuracy: 1.0000 - val_loss: 5.0597 - val_accuracy: 0.6449\n",
      "Fold 2, Best Validation Loss: 0.9820264577865601, Best Validation Accuracy: 0.8078902363777161\n",
      "Epoch 1/30\n",
      "55/55 [==============================] - 2s 14ms/step - loss: 0.1265 - accuracy: 0.9435 - val_loss: 0.0498 - val_accuracy: 0.9897\n",
      "Epoch 2/30\n",
      "55/55 [==============================] - 1s 11ms/step - loss: 0.0324 - accuracy: 0.9926 - val_loss: 0.0766 - val_accuracy: 0.9914\n",
      "Epoch 3/30\n",
      "55/55 [==============================] - 1s 15ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.0898 - val_accuracy: 0.9880\n",
      "Epoch 4/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0251 - val_accuracy: 0.9949\n",
      "Epoch 5/30\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0187 - val_accuracy: 0.9983\n",
      "Epoch 6/30\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.0233 - val_accuracy: 0.9983\n",
      "Epoch 7/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0185 - val_accuracy: 0.9983\n",
      "Epoch 8/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0124 - accuracy: 0.9989 - val_loss: 0.0684 - val_accuracy: 0.9914\n",
      "Epoch 9/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.0403 - val_accuracy: 0.9931\n",
      "Epoch 10/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0432 - accuracy: 0.9909 - val_loss: 0.1441 - val_accuracy: 0.9863\n",
      "Epoch 11/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.0602 - val_accuracy: 0.9914\n",
      "Epoch 12/30\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0925 - val_accuracy: 0.9914\n",
      "Epoch 13/30\n",
      "55/55 [==============================] - 1s 14ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0719 - val_accuracy: 0.9914\n",
      "Epoch 14/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.0825 - val_accuracy: 0.9897\n",
      "Epoch 15/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0927 - val_accuracy: 0.9914\n",
      "Epoch 16/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1311 - val_accuracy: 0.9897\n",
      "Epoch 17/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.1025 - val_accuracy: 0.9914\n",
      "Epoch 18/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 8.9407e-04 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9914\n",
      "Epoch 19/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 1.6353e-04 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9914\n",
      "Epoch 20/30\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1101 - val_accuracy: 0.9914\n",
      "Epoch 21/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 9.9143e-04 - accuracy: 0.9989 - val_loss: 0.1330 - val_accuracy: 0.9897\n",
      "Epoch 22/30\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0851 - val_accuracy: 0.9914\n",
      "Epoch 23/30\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1109 - val_accuracy: 0.9914\n",
      "Epoch 24/30\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.0779 - val_accuracy: 0.9897\n",
      "Epoch 25/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0044 - accuracy: 0.9977 - val_loss: 0.1211 - val_accuracy: 0.9914\n",
      "Epoch 26/30\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 1.9958e-04 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9914\n",
      "Epoch 27/30\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 1.0639e-04 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9914\n",
      "Epoch 28/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.1222 - val_accuracy: 0.9914\n",
      "Epoch 29/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1157 - val_accuracy: 0.9914\n",
      "Epoch 30/30\n",
      "55/55 [==============================] - 1s 13ms/step - loss: 4.3125e-04 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9914\n",
      "Fold 3, Best Validation Loss: 0.01853722333908081, Best Validation Accuracy: 0.9982847571372986\n",
      "Epoch 1/30\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 0.1062 - accuracy: 0.9606 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.0029 - val_accuracy: 0.9983\n",
      "Epoch 3/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 1.0046e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 1.2629e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 1.1909e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 3.8365e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 4.5616e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 2.0448e-09 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 3.7821e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 1.1808e-07 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 4.4148e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 6.9933e-04 - accuracy: 1.0000 - val_loss: 6.7477e-08 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 1.5325e-07 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 3.2818e-08 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 2.0994e-04 - accuracy: 1.0000 - val_loss: 2.0448e-10 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 1.0735e-08 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 3.0671e-10 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 3.6502e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.8734 - val_accuracy: 0.9262\n",
      "Epoch 20/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0365 - accuracy: 0.9949 - val_loss: 0.0397 - val_accuracy: 0.9966\n",
      "Epoch 21/30\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.0196 - accuracy: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9983\n",
      "Epoch 22/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0156 - accuracy: 0.9979 - val_loss: 1.3585e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 3.1111e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.0193 - accuracy: 0.9970 - val_loss: 5.1753e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 2.5642e-04 - accuracy: 1.0000 - val_loss: 2.1552e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 2.8422e-08 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 7.3611e-09 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 4.2106e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 3.9474e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 5.3255e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Fold 4, Best Validation Loss: 0.0, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "92/92 [==============================] - 2s 12ms/step - loss: 0.1125 - accuracy: 0.9616 - val_loss: 0.0346 - val_accuracy: 0.9914\n",
      "Epoch 2/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0099 - accuracy: 0.9986 - val_loss: 0.0107 - val_accuracy: 0.9983\n",
      "Epoch 3/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 2.6732e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9983\n",
      "Epoch 4/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 1.2580e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9983\n",
      "Epoch 5/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0322 - accuracy: 0.9925 - val_loss: 0.4840 - val_accuracy: 0.9520\n",
      "Epoch 7/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0453 - accuracy: 0.9918 - val_loss: 0.0576 - val_accuracy: 0.9914\n",
      "Epoch 8/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.1998 - val_accuracy: 0.9640\n",
      "Epoch 9/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0152 - val_accuracy: 0.9949\n",
      "Epoch 10/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0595 - val_accuracy: 0.9914\n",
      "Epoch 11/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0010 - accuracy: 0.9993 - val_loss: 0.0784 - val_accuracy: 0.9897\n",
      "Epoch 12/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0469 - val_accuracy: 0.9914\n",
      "Epoch 13/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0337 - val_accuracy: 0.9931\n",
      "Epoch 14/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 1.0019e-04 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9931\n",
      "Epoch 15/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0201 - val_accuracy: 0.9983\n",
      "Epoch 16/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 2.6130e-04 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9949\n",
      "Epoch 17/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 7.2472e-05 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9949\n",
      "Epoch 18/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 4.8622e-05 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9949\n",
      "Epoch 19/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.0146 - val_accuracy: 0.9983\n",
      "Epoch 20/30\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.0233 - val_accuracy: 0.9966\n",
      "Epoch 21/30\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0083 - val_accuracy: 0.9966\n",
      "Epoch 22/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.0118 - val_accuracy: 0.9966\n",
      "Epoch 23/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0089 - val_accuracy: 0.9966\n",
      "Epoch 24/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0104 - val_accuracy: 0.9966\n",
      "Epoch 25/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.0092 - val_accuracy: 0.9966\n",
      "Epoch 26/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0378 - val_accuracy: 0.9966\n",
      "Epoch 27/30\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 1.1837e-04 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9966\n",
      "Epoch 28/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 3.0114e-05 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9966\n",
      "Epoch 29/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0337 - val_accuracy: 0.9966\n",
      "Epoch 30/30\n",
      "92/92 [==============================] - 1s 14ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0338 - val_accuracy: 0.9966\n",
      "Fold 5, Best Validation Loss: 0.002259626053273678, Best Validation Accuracy: 1.0\n",
      "Mean Best Validation Loss: 0.9511739639565349\n",
      "Mean Best Validation Accuracy: 0.8754717111587524\n",
      "Epoch 1/30\n",
      "518/518 [==============================] - 5s 6ms/step - loss: 0.0156 - accuracy: 0.9982 - val_loss: 8.2176e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 3.3673e-05 - accuracy: 1.0000 - val_loss: 9.6693e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 1.1575e-05 - accuracy: 1.0000 - val_loss: 1.7949e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "518/518 [==============================] - 4s 7ms/step - loss: 7.8977e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 4.1148e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 1.9176e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 1.6958e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 1.5549e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 5.9808e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 9.4701e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 7.0813e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 3.1262e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 2.5849e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 2.1584e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 2.1861e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 2.1749e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 6.4478e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 3.8064e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 4.3770e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 4.4047e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 1.1418e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 1.0671e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 3.7456e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 2.1617e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 2.1509e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 2.1939e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 9.7237e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 8.5690e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 1.2937e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "518/518 [==============================] - 3s 6ms/step - loss: 8.1232e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Fold 1, Best Validation Loss: 0.0, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1036/1036 [==============================] - 7s 6ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 1.0360e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1036/1036 [==============================] - 6s 6ms/step - loss: 1.5531e-05 - accuracy: 1.0000 - val_loss: 2.3078e-08 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1036/1036 [==============================] - 6s 6ms/step - loss: 5.6225e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1036/1036 [==============================] - 6s 6ms/step - loss: 2.3497e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1036/1036 [==============================] - 6s 6ms/step - loss: 1.2244e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1036/1036 [==============================] - 5s 5ms/step - loss: 3.9429e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 4.4079e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 1.2738e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1036/1036 [==============================] - 6s 6ms/step - loss: 7.4524e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 4.7964e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 3.3356e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1036/1036 [==============================] - 6s 6ms/step - loss: 4.0809e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1036/1036 [==============================] - 6s 6ms/step - loss: 5.1484e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 4.0294e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 1.3365e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1036/1036 [==============================] - 5s 5ms/step - loss: 9.3720e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 1.2376e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 3.0400e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 1.7988e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 9.5339e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 2.1586e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1036/1036 [==============================] - 5s 5ms/step - loss: 9.5339e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1036/1036 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 5.3965e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 1.6190e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 5.5764e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 1.2592e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 1.3132e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1036/1036 [==============================] - 6s 6ms/step - loss: 3.0580e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1036/1036 [==============================] - 6s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Fold 2, Best Validation Loss: 0.0, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1554/1554 [==============================] - 10s 5ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 5.1997 - val_accuracy: 0.6468\n",
      "Epoch 2/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 5.9251e-06 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 3/30\n",
      "1554/1554 [==============================] - 9s 6ms/step - loss: 1.4031e-06 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 4/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 6.5446e-07 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 5/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.7951e-07 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 6/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 8.7547e-08 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 7/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.1103e-08 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 8/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 1.4305e-08 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 9/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 1.1672e-08 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 10/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.9216e-09 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 11/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 2.4609e-09 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 12/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.4815e-09 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 13/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.6508e-09 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 14/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.8976e-10 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 15/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 1.5351e-10 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 16/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.4779e-11 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 17/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 1.4391e-11 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 18/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 19/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 2.2391e-09 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 20/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.8092e-09 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 21/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 1.2952e-10 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 22/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 2.0987e-10 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 23/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 4.9410e-10 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 24/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 2.8303e-10 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 25/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.0222e-10 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 26/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 3.5978e-12 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 27/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 28/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 8.3949e-12 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 29/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Epoch 30/30\n",
      "1554/1554 [==============================] - 8s 5ms/step - loss: 4.7971e-12 - accuracy: 1.0000 - val_loss: 5.4480 - val_accuracy: 0.6468\n",
      "Fold 3, Best Validation Loss: 5.199674129486084, Best Validation Accuracy: 0.6468067169189453\n",
      "Epoch 1/30\n",
      "2071/2071 [==============================] - 13s 6ms/step - loss: 0.3065 - accuracy: 0.9117 - val_loss: 2.4982 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.3017 - accuracy: 0.9117 - val_loss: 2.3975 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.3009 - accuracy: 0.9117 - val_loss: 2.5277 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.3004 - accuracy: 0.9117 - val_loss: 2.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2996 - accuracy: 0.9117 - val_loss: 2.3427 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2992 - accuracy: 0.9117 - val_loss: 2.3992 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2986 - accuracy: 0.9117 - val_loss: 2.3571 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2983 - accuracy: 0.9117 - val_loss: 2.3423 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2989 - accuracy: 0.9117 - val_loss: 2.4596 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2988 - accuracy: 0.9117 - val_loss: 2.3041 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2986 - accuracy: 0.9117 - val_loss: 2.4074 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2980 - accuracy: 0.9117 - val_loss: 2.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2983 - accuracy: 0.9117 - val_loss: 2.5184 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "2071/2071 [==============================] - 12s 6ms/step - loss: 0.2979 - accuracy: 0.9117 - val_loss: 2.4753 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "2071/2071 [==============================] - 13s 6ms/step - loss: 0.2978 - accuracy: 0.9117 - val_loss: 2.3963 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2978 - accuracy: 0.9117 - val_loss: 2.4382 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2976 - accuracy: 0.9117 - val_loss: 2.3248 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2974 - accuracy: 0.9117 - val_loss: 2.3204 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2975 - accuracy: 0.9117 - val_loss: 2.3794 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2978 - accuracy: 0.9117 - val_loss: 2.4636 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2978 - accuracy: 0.9117 - val_loss: 2.4513 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2973 - accuracy: 0.9117 - val_loss: 2.3326 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2973 - accuracy: 0.9117 - val_loss: 2.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2972 - accuracy: 0.9117 - val_loss: 2.3349 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2973 - accuracy: 0.9117 - val_loss: 2.4039 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2975 - accuracy: 0.9117 - val_loss: 2.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2974 - accuracy: 0.9117 - val_loss: 2.3031 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2974 - accuracy: 0.9117 - val_loss: 2.4642 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2975 - accuracy: 0.9117 - val_loss: 2.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "2071/2071 [==============================] - 11s 5ms/step - loss: 0.2972 - accuracy: 0.9117 - val_loss: 2.4255 - val_accuracy: 0.0000e+00\n",
      "Fold 4, Best Validation Loss: 2.3031206130981445, Best Validation Accuracy: 0.0\n",
      "Epoch 1/30\n",
      "2589/2589 [==============================] - 16s 5ms/step - loss: 0.5865 - accuracy: 0.7288 - val_loss: 1.3362 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5836 - accuracy: 0.7294 - val_loss: 1.3053 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5825 - accuracy: 0.7294 - val_loss: 1.2876 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5821 - accuracy: 0.7294 - val_loss: 1.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5821 - accuracy: 0.7294 - val_loss: 1.2710 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5816 - accuracy: 0.7294 - val_loss: 1.2150 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5807 - accuracy: 0.7294 - val_loss: 1.3045 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5806 - accuracy: 0.7294 - val_loss: 1.3135 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5805 - accuracy: 0.7294 - val_loss: 1.3019 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5801 - accuracy: 0.7294 - val_loss: 1.2928 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5802 - accuracy: 0.7294 - val_loss: 1.2865 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5807 - accuracy: 0.7294 - val_loss: 1.2911 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5802 - accuracy: 0.7294 - val_loss: 1.3396 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5802 - accuracy: 0.7294 - val_loss: 1.3095 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5803 - accuracy: 0.7294 - val_loss: 1.2831 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5806 - accuracy: 0.7294 - val_loss: 1.2973 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5803 - accuracy: 0.7294 - val_loss: 1.3059 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5803 - accuracy: 0.7294 - val_loss: 1.3053 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5804 - accuracy: 0.7294 - val_loss: 1.2845 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5801 - accuracy: 0.7294 - val_loss: 1.2855 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5799 - accuracy: 0.7294 - val_loss: 1.2759 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5799 - accuracy: 0.7294 - val_loss: 1.2724 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5797 - accuracy: 0.7294 - val_loss: 1.3242 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "2589/2589 [==============================] - 13s 5ms/step - loss: 0.5798 - accuracy: 0.7294 - val_loss: 1.3007 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5799 - accuracy: 0.7294 - val_loss: 1.2854 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5797 - accuracy: 0.7294 - val_loss: 1.3023 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5799 - accuracy: 0.7294 - val_loss: 1.3142 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5803 - accuracy: 0.7294 - val_loss: 1.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5800 - accuracy: 0.7294 - val_loss: 1.3215 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "2589/2589 [==============================] - 14s 5ms/step - loss: 0.5800 - accuracy: 0.7294 - val_loss: 1.3068 - val_accuracy: 0.0000e+00\n",
      "Fold 5, Best Validation Loss: 1.214957356452942, Best Validation Accuracy: 0.0\n",
      "Mean Best Validation Loss: 1.743550419807434\n",
      "Mean Best Validation Accuracy: 0.529361343383789\n",
      "Epoch 1/30\n",
      "219/219 [==============================] - 3s 7ms/step - loss: 0.5372 - accuracy: 0.6913 - val_loss: 1.5942 - val_accuracy: 0.5384\n",
      "Epoch 2/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.2952 - accuracy: 0.8876 - val_loss: 2.5798 - val_accuracy: 0.5543\n",
      "Epoch 3/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.2355 - accuracy: 0.9126 - val_loss: 2.8579 - val_accuracy: 0.5520\n",
      "Epoch 4/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.2163 - accuracy: 0.9230 - val_loss: 3.4589 - val_accuracy: 0.5560\n",
      "Epoch 5/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1640 - accuracy: 0.9409 - val_loss: 3.5264 - val_accuracy: 0.5601\n",
      "Epoch 6/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1587 - accuracy: 0.9449 - val_loss: 3.8436 - val_accuracy: 0.5591\n",
      "Epoch 7/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1934 - accuracy: 0.9339 - val_loss: 3.2684 - val_accuracy: 0.5590\n",
      "Epoch 8/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1456 - accuracy: 0.9486 - val_loss: 4.3279 - val_accuracy: 0.5624\n",
      "Epoch 9/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1571 - accuracy: 0.9457 - val_loss: 3.9690 - val_accuracy: 0.5604\n",
      "Epoch 10/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1236 - accuracy: 0.9623 - val_loss: 4.8978 - val_accuracy: 0.5620\n",
      "Epoch 11/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1279 - accuracy: 0.9613 - val_loss: 4.7370 - val_accuracy: 0.5619\n",
      "Epoch 12/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1303 - accuracy: 0.9589 - val_loss: 4.6599 - val_accuracy: 0.5620\n",
      "Epoch 13/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1317 - accuracy: 0.9597 - val_loss: 4.7246 - val_accuracy: 0.5629\n",
      "Epoch 14/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1371 - accuracy: 0.9573 - val_loss: 5.0286 - val_accuracy: 0.5621\n",
      "Epoch 15/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1376 - accuracy: 0.9571 - val_loss: 4.8653 - val_accuracy: 0.5626\n",
      "Epoch 16/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1266 - accuracy: 0.9606 - val_loss: 5.0951 - val_accuracy: 0.5613\n",
      "Epoch 17/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1246 - accuracy: 0.9633 - val_loss: 5.4538 - val_accuracy: 0.5617\n",
      "Epoch 18/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1076 - accuracy: 0.9687 - val_loss: 5.2274 - val_accuracy: 0.5646\n",
      "Epoch 19/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1080 - accuracy: 0.9673 - val_loss: 5.6859 - val_accuracy: 0.5624\n",
      "Epoch 20/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1236 - accuracy: 0.9651 - val_loss: 5.0120 - val_accuracy: 0.5613\n",
      "Epoch 21/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1842 - accuracy: 0.9421 - val_loss: 3.5524 - val_accuracy: 0.5523\n",
      "Epoch 22/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1737 - accuracy: 0.9446 - val_loss: 5.8316 - val_accuracy: 0.5573\n",
      "Epoch 23/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1530 - accuracy: 0.9504 - val_loss: 6.1435 - val_accuracy: 0.5580\n",
      "Epoch 24/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1532 - accuracy: 0.9539 - val_loss: 6.1678 - val_accuracy: 0.5570\n",
      "Epoch 25/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1550 - accuracy: 0.9513 - val_loss: 6.1338 - val_accuracy: 0.5611\n",
      "Epoch 26/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1360 - accuracy: 0.9574 - val_loss: 6.2094 - val_accuracy: 0.5633\n",
      "Epoch 27/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1235 - accuracy: 0.9607 - val_loss: 6.2528 - val_accuracy: 0.5633\n",
      "Epoch 28/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1171 - accuracy: 0.9643 - val_loss: 6.2167 - val_accuracy: 0.5637\n",
      "Epoch 29/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1106 - accuracy: 0.9651 - val_loss: 6.2884 - val_accuracy: 0.5627\n",
      "Epoch 30/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1132 - accuracy: 0.9653 - val_loss: 5.9336 - val_accuracy: 0.5630\n",
      "Fold 1, Best Validation Loss: 1.5942364931106567, Best Validation Accuracy: 0.5645714402198792\n",
      "Epoch 1/30\n",
      "438/438 [==============================] - 4s 6ms/step - loss: 0.6830 - accuracy: 0.5604 - val_loss: 0.6909 - val_accuracy: 0.5714\n",
      "Epoch 2/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6726 - accuracy: 0.5646 - val_loss: 0.7066 - val_accuracy: 0.5729\n",
      "Epoch 3/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6679 - accuracy: 0.5842 - val_loss: 0.7109 - val_accuracy: 0.5220\n",
      "Epoch 4/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6541 - accuracy: 0.6311 - val_loss: 0.7352 - val_accuracy: 0.5309\n",
      "Epoch 5/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6475 - accuracy: 0.6309 - val_loss: 0.7110 - val_accuracy: 0.5380\n",
      "Epoch 6/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6676 - accuracy: 0.5807 - val_loss: 0.7062 - val_accuracy: 0.5401\n",
      "Epoch 7/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6602 - accuracy: 0.6091 - val_loss: 0.7176 - val_accuracy: 0.5210\n",
      "Epoch 8/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6373 - accuracy: 0.6541 - val_loss: 0.7262 - val_accuracy: 0.5509\n",
      "Epoch 9/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6207 - accuracy: 0.6792 - val_loss: 0.7323 - val_accuracy: 0.5544\n",
      "Epoch 10/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6072 - accuracy: 0.6971 - val_loss: 0.7497 - val_accuracy: 0.5546\n",
      "Epoch 11/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6360 - accuracy: 0.6554 - val_loss: 0.7255 - val_accuracy: 0.5290\n",
      "Epoch 12/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6332 - accuracy: 0.6643 - val_loss: 0.7513 - val_accuracy: 0.5460\n",
      "Epoch 13/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6284 - accuracy: 0.6726 - val_loss: 0.7365 - val_accuracy: 0.5491\n",
      "Epoch 14/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6107 - accuracy: 0.6941 - val_loss: 0.7640 - val_accuracy: 0.5409\n",
      "Epoch 15/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6326 - accuracy: 0.6667 - val_loss: 0.7434 - val_accuracy: 0.5359\n",
      "Epoch 16/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6195 - accuracy: 0.6836 - val_loss: 0.7552 - val_accuracy: 0.5403\n",
      "Epoch 17/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6094 - accuracy: 0.6966 - val_loss: 0.7529 - val_accuracy: 0.5463\n",
      "Epoch 18/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.5988 - accuracy: 0.7082 - val_loss: 0.7500 - val_accuracy: 0.5510\n",
      "Epoch 19/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.5880 - accuracy: 0.7190 - val_loss: 0.7515 - val_accuracy: 0.5560\n",
      "Epoch 20/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.5829 - accuracy: 0.7219 - val_loss: 0.7584 - val_accuracy: 0.5531\n",
      "Epoch 21/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5831 - accuracy: 0.7220 - val_loss: 0.7611 - val_accuracy: 0.5556\n",
      "Epoch 22/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5808 - accuracy: 0.7225 - val_loss: 0.7618 - val_accuracy: 0.5501\n",
      "Epoch 23/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5847 - accuracy: 0.7178 - val_loss: 0.7528 - val_accuracy: 0.5424\n",
      "Epoch 24/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5861 - accuracy: 0.7205 - val_loss: 0.7553 - val_accuracy: 0.5529\n",
      "Epoch 25/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5606 - accuracy: 0.7396 - val_loss: 0.7503 - val_accuracy: 0.5600\n",
      "Epoch 26/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5876 - accuracy: 0.7124 - val_loss: 0.7516 - val_accuracy: 0.5561\n",
      "Epoch 27/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5506 - accuracy: 0.7466 - val_loss: 0.7506 - val_accuracy: 0.5610\n",
      "Epoch 28/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5509 - accuracy: 0.7431 - val_loss: 0.7483 - val_accuracy: 0.5544\n",
      "Epoch 29/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6193 - accuracy: 0.6830 - val_loss: 0.7361 - val_accuracy: 0.5374\n",
      "Epoch 30/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6146 - accuracy: 0.6924 - val_loss: 0.7660 - val_accuracy: 0.5381\n",
      "Fold 2, Best Validation Loss: 0.6909160614013672, Best Validation Accuracy: 0.572857141494751\n",
      "Epoch 1/30\n",
      "657/657 [==============================] - 5s 6ms/step - loss: 0.6854 - accuracy: 0.5626 - val_loss: 0.7318 - val_accuracy: 0.4286\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6827 - accuracy: 0.5688 - val_loss: 0.7210 - val_accuracy: 0.4297\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6782 - accuracy: 0.5683 - val_loss: 0.7240 - val_accuracy: 0.4346\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6786 - accuracy: 0.5743 - val_loss: 0.7308 - val_accuracy: 0.4310\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6800 - accuracy: 0.5750 - val_loss: 0.7322 - val_accuracy: 0.4287\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.6809 - accuracy: 0.5698 - val_loss: 0.7283 - val_accuracy: 0.4300\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6801 - accuracy: 0.5694 - val_loss: 0.7195 - val_accuracy: 0.4286\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6816 - accuracy: 0.5714 - val_loss: 0.7186 - val_accuracy: 0.4286\n",
      "Epoch 9/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6816 - accuracy: 0.5714 - val_loss: 0.7273 - val_accuracy: 0.4286\n",
      "Epoch 10/30\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.6819 - accuracy: 0.5716 - val_loss: 0.7174 - val_accuracy: 0.4286\n",
      "Epoch 11/30\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.6810 - accuracy: 0.5710 - val_loss: 0.7477 - val_accuracy: 0.4286\n",
      "Epoch 12/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6816 - accuracy: 0.5714 - val_loss: 0.7299 - val_accuracy: 0.4286\n",
      "Epoch 13/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6818 - accuracy: 0.5714 - val_loss: 0.7330 - val_accuracy: 0.4286\n",
      "Epoch 14/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6812 - accuracy: 0.5714 - val_loss: 0.7219 - val_accuracy: 0.4286\n",
      "Epoch 15/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6803 - accuracy: 0.5722 - val_loss: 0.7345 - val_accuracy: 0.4286\n",
      "Epoch 16/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6775 - accuracy: 0.5768 - val_loss: 0.7385 - val_accuracy: 0.4333\n",
      "Epoch 17/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6714 - accuracy: 0.5933 - val_loss: 0.7462 - val_accuracy: 0.4330\n",
      "Epoch 18/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6631 - accuracy: 0.6204 - val_loss: 0.7709 - val_accuracy: 0.4280\n",
      "Epoch 19/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6485 - accuracy: 0.6441 - val_loss: 0.7657 - val_accuracy: 0.4283\n",
      "Epoch 20/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6388 - accuracy: 0.6586 - val_loss: 0.8125 - val_accuracy: 0.4271\n",
      "Epoch 21/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6236 - accuracy: 0.6740 - val_loss: 0.7986 - val_accuracy: 0.4261\n",
      "Epoch 22/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6357 - accuracy: 0.6630 - val_loss: 0.7787 - val_accuracy: 0.4303\n",
      "Epoch 23/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6171 - accuracy: 0.6830 - val_loss: 0.8023 - val_accuracy: 0.4281\n",
      "Epoch 24/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6050 - accuracy: 0.6915 - val_loss: 0.8141 - val_accuracy: 0.4277\n",
      "Epoch 25/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6172 - accuracy: 0.6749 - val_loss: 0.7559 - val_accuracy: 0.4300\n",
      "Epoch 26/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6355 - accuracy: 0.6568 - val_loss: 0.7784 - val_accuracy: 0.4281\n",
      "Epoch 27/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6091 - accuracy: 0.6866 - val_loss: 0.7863 - val_accuracy: 0.4276\n",
      "Epoch 28/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6252 - accuracy: 0.6601 - val_loss: 0.7526 - val_accuracy: 0.4276\n",
      "Epoch 29/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6454 - accuracy: 0.6452 - val_loss: 0.7852 - val_accuracy: 0.4297\n",
      "Epoch 30/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6418 - accuracy: 0.6544 - val_loss: 0.7675 - val_accuracy: 0.4327\n",
      "Fold 3, Best Validation Loss: 0.7174426913261414, Best Validation Accuracy: 0.43457141518592834\n",
      "Epoch 1/30\n",
      "875/875 [==============================] - 6s 5ms/step - loss: 0.6930 - accuracy: 0.5250 - val_loss: 0.7085 - val_accuracy: 0.4286\n",
      "Epoch 2/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6913 - accuracy: 0.5343 - val_loss: 0.7128 - val_accuracy: 0.4286\n",
      "Epoch 3/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6903 - accuracy: 0.5365 - val_loss: 0.7042 - val_accuracy: 0.4313\n",
      "Epoch 4/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6876 - accuracy: 0.5494 - val_loss: 0.7153 - val_accuracy: 0.4613\n",
      "Epoch 5/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6856 - accuracy: 0.5605 - val_loss: 0.7043 - val_accuracy: 0.4474\n",
      "Epoch 6/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6826 - accuracy: 0.5705 - val_loss: 0.7139 - val_accuracy: 0.4760\n",
      "Epoch 7/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6861 - accuracy: 0.5531 - val_loss: 0.7013 - val_accuracy: 0.4717\n",
      "Epoch 8/30\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6902 - accuracy: 0.5396 - val_loss: 0.6949 - val_accuracy: 0.4874\n",
      "Epoch 9/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6891 - accuracy: 0.5441 - val_loss: 0.7076 - val_accuracy: 0.4513\n",
      "Epoch 10/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6886 - accuracy: 0.5452 - val_loss: 0.6966 - val_accuracy: 0.4907\n",
      "Epoch 11/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6885 - accuracy: 0.5426 - val_loss: 0.6993 - val_accuracy: 0.4559\n",
      "Epoch 12/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6877 - accuracy: 0.5485 - val_loss: 0.7026 - val_accuracy: 0.4946\n",
      "Epoch 13/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6876 - accuracy: 0.5470 - val_loss: 0.6955 - val_accuracy: 0.4871\n",
      "Epoch 14/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6877 - accuracy: 0.5472 - val_loss: 0.7043 - val_accuracy: 0.5089\n",
      "Epoch 15/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6875 - accuracy: 0.5446 - val_loss: 0.6967 - val_accuracy: 0.5007\n",
      "Epoch 16/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6881 - accuracy: 0.5425 - val_loss: 0.6896 - val_accuracy: 0.5379\n",
      "Epoch 17/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6875 - accuracy: 0.5442 - val_loss: 0.7017 - val_accuracy: 0.5081\n",
      "Epoch 18/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6863 - accuracy: 0.5486 - val_loss: 0.6930 - val_accuracy: 0.5119\n",
      "Epoch 19/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6871 - accuracy: 0.5468 - val_loss: 0.6921 - val_accuracy: 0.5076\n",
      "Epoch 20/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6862 - accuracy: 0.5515 - val_loss: 0.6926 - val_accuracy: 0.5056\n",
      "Epoch 21/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6860 - accuracy: 0.5502 - val_loss: 0.6922 - val_accuracy: 0.5001\n",
      "Epoch 22/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6861 - accuracy: 0.5504 - val_loss: 0.6891 - val_accuracy: 0.5130\n",
      "Epoch 23/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6860 - accuracy: 0.5502 - val_loss: 0.6864 - val_accuracy: 0.5384\n",
      "Epoch 24/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6861 - accuracy: 0.5498 - val_loss: 0.6848 - val_accuracy: 0.5179\n",
      "Epoch 25/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6862 - accuracy: 0.5497 - val_loss: 0.6935 - val_accuracy: 0.5127\n",
      "Epoch 26/30\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6854 - accuracy: 0.5535 - val_loss: 0.6886 - val_accuracy: 0.5206\n",
      "Epoch 27/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6866 - accuracy: 0.5523 - val_loss: 0.6957 - val_accuracy: 0.5086\n",
      "Epoch 28/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6863 - accuracy: 0.5509 - val_loss: 0.6912 - val_accuracy: 0.5114\n",
      "Epoch 29/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6870 - accuracy: 0.5474 - val_loss: 0.6932 - val_accuracy: 0.5100\n",
      "Epoch 30/30\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6861 - accuracy: 0.5490 - val_loss: 0.6950 - val_accuracy: 0.5009\n",
      "Fold 4, Best Validation Loss: 0.6847631335258484, Best Validation Accuracy: 0.538428544998169\n",
      "Epoch 1/30\n",
      "1094/1094 [==============================] - 7s 5ms/step - loss: 0.6948 - accuracy: 0.5092 - val_loss: 0.6985 - val_accuracy: 0.4286\n",
      "Epoch 2/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6927 - accuracy: 0.5149 - val_loss: 0.6937 - val_accuracy: 0.4286\n",
      "Epoch 3/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6922 - accuracy: 0.5174 - val_loss: 0.6941 - val_accuracy: 0.4536\n",
      "Epoch 4/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5754\n",
      "Epoch 5/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6917 - accuracy: 0.5250 - val_loss: 0.6965 - val_accuracy: 0.4640\n",
      "Epoch 6/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6924 - val_accuracy: 0.5511\n",
      "Epoch 7/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6946 - val_accuracy: 0.4436\n",
      "Epoch 8/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5869\n",
      "Epoch 9/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6912 - accuracy: 0.5283 - val_loss: 0.6892 - val_accuracy: 0.5881\n",
      "Epoch 10/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6898 - accuracy: 0.5394 - val_loss: 0.6873 - val_accuracy: 0.5569\n",
      "Epoch 11/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6858 - accuracy: 0.5597 - val_loss: 0.7064 - val_accuracy: 0.4586\n",
      "Epoch 12/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6868 - accuracy: 0.5521 - val_loss: 0.7064 - val_accuracy: 0.4684\n",
      "Epoch 13/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6748 - accuracy: 0.5808 - val_loss: 0.7125 - val_accuracy: 0.4543\n",
      "Epoch 14/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6727 - accuracy: 0.5795 - val_loss: 0.7104 - val_accuracy: 0.4407\n",
      "Epoch 15/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6739 - accuracy: 0.5742 - val_loss: 0.6972 - val_accuracy: 0.4770\n",
      "Epoch 16/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6748 - accuracy: 0.5775 - val_loss: 0.7032 - val_accuracy: 0.4531\n",
      "Epoch 17/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6659 - accuracy: 0.5870 - val_loss: 0.7198 - val_accuracy: 0.4441\n",
      "Epoch 18/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6654 - accuracy: 0.5820 - val_loss: 0.7088 - val_accuracy: 0.4539\n",
      "Epoch 19/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6643 - accuracy: 0.5822 - val_loss: 0.7133 - val_accuracy: 0.4429\n",
      "Epoch 20/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6601 - accuracy: 0.5864 - val_loss: 0.7120 - val_accuracy: 0.4390\n",
      "Epoch 21/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6582 - accuracy: 0.5888 - val_loss: 0.7162 - val_accuracy: 0.4384\n",
      "Epoch 22/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6592 - accuracy: 0.5844 - val_loss: 0.7145 - val_accuracy: 0.4409\n",
      "Epoch 23/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6925 - accuracy: 0.5262 - val_loss: 0.7018 - val_accuracy: 0.5071\n",
      "Epoch 24/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6892 - accuracy: 0.5426 - val_loss: 0.7001 - val_accuracy: 0.4810\n",
      "Epoch 25/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6815 - accuracy: 0.5696 - val_loss: 0.7055 - val_accuracy: 0.4497\n",
      "Epoch 26/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6797 - accuracy: 0.5739 - val_loss: 0.7004 - val_accuracy: 0.4861\n",
      "Epoch 27/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6802 - accuracy: 0.5740 - val_loss: 0.7028 - val_accuracy: 0.4647\n",
      "Epoch 28/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6794 - accuracy: 0.5688 - val_loss: 0.7041 - val_accuracy: 0.4604\n",
      "Epoch 29/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6714 - accuracy: 0.5760 - val_loss: 0.7087 - val_accuracy: 0.4446\n",
      "Epoch 30/30\n",
      "1094/1094 [==============================] - 6s 5ms/step - loss: 0.6669 - accuracy: 0.5793 - val_loss: 0.7095 - val_accuracy: 0.4471\n",
      "Fold 5, Best Validation Loss: 0.687296450138092, Best Validation Accuracy: 0.5881428718566895\n",
      "Mean Best Validation Loss: 0.8749309659004212\n",
      "Mean Best Validation Accuracy: 0.5397142827510834\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 2s 145ms/step - loss: 0.6979 - accuracy: 0.6522 - val_loss: 0.0710 - val_accuracy: 0.9888\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2331 - accuracy: 0.9457 - val_loss: 0.0829 - val_accuracy: 0.9888\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1237 - accuracy: 0.9565 - val_loss: 0.0676 - val_accuracy: 0.9888\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1303 - accuracy: 0.9565 - val_loss: 0.0726 - val_accuracy: 0.9888\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0963 - accuracy: 0.9674 - val_loss: 0.0818 - val_accuracy: 0.9888\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0984 - accuracy: 0.9674 - val_loss: 0.0862 - val_accuracy: 0.9888\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0714 - accuracy: 0.9783 - val_loss: 0.0825 - val_accuracy: 0.9888\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0528 - accuracy: 0.9891 - val_loss: 0.0788 - val_accuracy: 0.9888\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0434 - accuracy: 0.9891 - val_loss: 0.0879 - val_accuracy: 0.9888\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0516 - accuracy: 0.9783 - val_loss: 0.0913 - val_accuracy: 0.9888\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0791 - accuracy: 0.9674 - val_loss: 0.0986 - val_accuracy: 0.9888\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0778 - accuracy: 0.9783 - val_loss: 0.1015 - val_accuracy: 0.9888\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0587 - accuracy: 0.9891 - val_loss: 0.1033 - val_accuracy: 0.9888\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0377 - accuracy: 0.9891 - val_loss: 0.0968 - val_accuracy: 0.9888\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0711 - accuracy: 0.9783 - val_loss: 0.0775 - val_accuracy: 0.9888\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0615 - accuracy: 0.9891 - val_loss: 0.0622 - val_accuracy: 0.9888\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0472 - accuracy: 0.9783 - val_loss: 0.0595 - val_accuracy: 0.9888\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0450 - accuracy: 0.9783 - val_loss: 0.0585 - val_accuracy: 0.9888\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0403 - accuracy: 0.9891 - val_loss: 0.0534 - val_accuracy: 0.9888\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0421 - val_accuracy: 0.9888\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0213 - accuracy: 0.9891 - val_loss: 0.0342 - val_accuracy: 0.9888\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9888\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0322 - accuracy: 0.9891 - val_loss: 0.1228 - val_accuracy: 0.9438\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0258 - accuracy: 0.9891 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0420 - accuracy: 0.9891 - val_loss: 0.0488 - val_accuracy: 0.9888\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0590 - accuracy: 0.9783 - val_loss: 0.0185 - val_accuracy: 0.9888\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9888\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0456 - accuracy: 0.9891 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0247 - accuracy: 0.9891 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Fold 1, Best Validation Loss: 0.003973831422626972, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 2s 65ms/step - loss: 0.4862 - accuracy: 0.8066 - val_loss: 0.9051 - val_accuracy: 0.7865\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1418 - accuracy: 0.9669 - val_loss: 1.1345 - val_accuracy: 0.7865\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1116 - accuracy: 0.9558 - val_loss: 1.0223 - val_accuracy: 0.7753\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0671 - accuracy: 0.9779 - val_loss: 1.2079 - val_accuracy: 0.7753\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0843 - accuracy: 0.9779 - val_loss: 1.2335 - val_accuracy: 0.7753\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 0.9945 - val_loss: 1.0007 - val_accuracy: 0.7753\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0821 - accuracy: 0.9779 - val_loss: 1.2159 - val_accuracy: 0.7865\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0733 - accuracy: 0.9834 - val_loss: 1.1534 - val_accuracy: 0.7753\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0548 - accuracy: 0.9834 - val_loss: 1.3267 - val_accuracy: 0.7753\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0559 - accuracy: 0.9779 - val_loss: 1.4047 - val_accuracy: 0.7753\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0459 - accuracy: 0.9890 - val_loss: 1.7546 - val_accuracy: 0.7865\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0708 - accuracy: 0.9834 - val_loss: 1.6307 - val_accuracy: 0.7865\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0394 - accuracy: 0.9779 - val_loss: 1.0015 - val_accuracy: 0.7640\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.8407 - val_accuracy: 0.7640\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0534 - accuracy: 0.9779 - val_loss: 1.4289 - val_accuracy: 0.7753\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1799 - val_accuracy: 0.7865\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 0.9834 - val_loss: 1.4710 - val_accuracy: 0.7753\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0193 - accuracy: 0.9890 - val_loss: 1.7219 - val_accuracy: 0.7753\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.6449 - val_accuracy: 0.7865\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5957 - val_accuracy: 0.7640\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 1.7297 - val_accuracy: 0.7640\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.9910 - val_accuracy: 0.7753\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0860 - accuracy: 0.9945 - val_loss: 1.9382 - val_accuracy: 0.7865\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0096 - accuracy: 0.9890 - val_loss: 1.8161 - val_accuracy: 0.7865\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 2.0179 - val_accuracy: 0.7753\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0560 - accuracy: 0.9890 - val_loss: 1.8208 - val_accuracy: 0.7753\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0393 - accuracy: 0.9945 - val_loss: 1.5278 - val_accuracy: 0.7753\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 1.5760 - val_accuracy: 0.7753\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0336 - accuracy: 0.9834 - val_loss: 1.5208 - val_accuracy: 0.7753\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 1.2574 - val_accuracy: 0.7865\n",
      "Fold 2, Best Validation Loss: 0.8406974077224731, Best Validation Accuracy: 0.7865168452262878\n",
      "Epoch 1/30\n",
      "9/9 [==============================] - 2s 56ms/step - loss: 0.4208 - accuracy: 0.8778 - val_loss: 0.1632 - val_accuracy: 0.9551\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.2586 - accuracy: 0.9148 - val_loss: 0.1333 - val_accuracy: 0.9551\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.2713 - accuracy: 0.9074 - val_loss: 0.1997 - val_accuracy: 0.9551\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2805 - accuracy: 0.8556 - val_loss: 0.1634 - val_accuracy: 0.9551\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2444 - accuracy: 0.9000 - val_loss: 0.1572 - val_accuracy: 0.9551\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2334 - accuracy: 0.9000 - val_loss: 0.1484 - val_accuracy: 0.9551\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2049 - accuracy: 0.8889 - val_loss: 0.1202 - val_accuracy: 0.9551\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2175 - accuracy: 0.9222 - val_loss: 0.1343 - val_accuracy: 0.9551\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2171 - accuracy: 0.9185 - val_loss: 0.1462 - val_accuracy: 0.9551\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1690 - accuracy: 0.9296 - val_loss: 0.0982 - val_accuracy: 0.9551\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1523 - accuracy: 0.9370 - val_loss: 0.2477 - val_accuracy: 0.8427\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.2230 - accuracy: 0.9000 - val_loss: 0.0987 - val_accuracy: 0.9551\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1983 - accuracy: 0.9074 - val_loss: 0.1556 - val_accuracy: 0.9551\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1832 - accuracy: 0.9185 - val_loss: 0.1021 - val_accuracy: 0.9551\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.2060 - accuracy: 0.9111 - val_loss: 0.1094 - val_accuracy: 0.9551\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.1529 - accuracy: 0.9333 - val_loss: 0.0879 - val_accuracy: 0.9551\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1460 - accuracy: 0.9333 - val_loss: 0.0768 - val_accuracy: 0.9551\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1589 - accuracy: 0.9185 - val_loss: 0.0703 - val_accuracy: 0.9663\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1328 - accuracy: 0.9481 - val_loss: 0.0871 - val_accuracy: 0.9551\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.1112 - accuracy: 0.9407 - val_loss: 0.0681 - val_accuracy: 0.9663\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1371 - accuracy: 0.9444 - val_loss: 0.0868 - val_accuracy: 0.9551\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1600 - accuracy: 0.9259 - val_loss: 0.0734 - val_accuracy: 0.9551\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.1580 - accuracy: 0.9185 - val_loss: 0.1423 - val_accuracy: 0.9326\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1538 - accuracy: 0.9259 - val_loss: 0.0885 - val_accuracy: 0.9663\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1386 - accuracy: 0.9407 - val_loss: 0.1253 - val_accuracy: 0.9213\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1295 - accuracy: 0.9333 - val_loss: 0.0976 - val_accuracy: 0.9326\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1308 - accuracy: 0.9407 - val_loss: 0.0669 - val_accuracy: 0.9551\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0996 - accuracy: 0.9630 - val_loss: 0.1348 - val_accuracy: 0.9663\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.1094 - accuracy: 0.9556 - val_loss: 0.0735 - val_accuracy: 0.9663\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0845 - accuracy: 0.9741 - val_loss: 0.0610 - val_accuracy: 0.9888\n",
      "Fold 3, Best Validation Loss: 0.0610114224255085, Best Validation Accuracy: 0.9887640476226807\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 2s 32ms/step - loss: 0.3627 - accuracy: 0.8440 - val_loss: 0.0710 - val_accuracy: 0.9775\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2610 - accuracy: 0.9053 - val_loss: 0.0735 - val_accuracy: 0.9775\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2633 - accuracy: 0.8997 - val_loss: 0.0845 - val_accuracy: 0.9775\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2257 - accuracy: 0.9192 - val_loss: 0.0979 - val_accuracy: 0.9775\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1957 - accuracy: 0.9331 - val_loss: 0.0993 - val_accuracy: 0.9775\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.1850 - accuracy: 0.9220 - val_loss: 0.1210 - val_accuracy: 0.9551\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1445 - accuracy: 0.9387 - val_loss: 0.0892 - val_accuracy: 0.9551\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1590 - accuracy: 0.9192 - val_loss: 0.1034 - val_accuracy: 0.9775\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1764 - accuracy: 0.9276 - val_loss: 0.0881 - val_accuracy: 0.9775\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1681 - accuracy: 0.9443 - val_loss: 0.1431 - val_accuracy: 0.9438\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.1505 - accuracy: 0.9276 - val_loss: 0.1384 - val_accuracy: 0.9438\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1442 - accuracy: 0.9304 - val_loss: 0.1840 - val_accuracy: 0.9438\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1765 - accuracy: 0.9443 - val_loss: 0.1612 - val_accuracy: 0.9438\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1428 - accuracy: 0.9471 - val_loss: 0.2588 - val_accuracy: 0.9213\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1161 - accuracy: 0.9582 - val_loss: 0.2442 - val_accuracy: 0.9438\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1082 - accuracy: 0.9387 - val_loss: 0.3190 - val_accuracy: 0.9438\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1012 - accuracy: 0.9694 - val_loss: 0.2083 - val_accuracy: 0.9551\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1727 - accuracy: 0.9359 - val_loss: 0.1753 - val_accuracy: 0.9438\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1611 - accuracy: 0.9304 - val_loss: 0.1630 - val_accuracy: 0.9551\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1243 - accuracy: 0.9471 - val_loss: 0.2026 - val_accuracy: 0.9438\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1266 - accuracy: 0.9443 - val_loss: 0.1948 - val_accuracy: 0.9551\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1143 - accuracy: 0.9526 - val_loss: 0.1375 - val_accuracy: 0.9775\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1825 - accuracy: 0.9331 - val_loss: 0.1466 - val_accuracy: 0.9551\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1114 - accuracy: 0.9359 - val_loss: 0.1717 - val_accuracy: 0.9326\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0997 - accuracy: 0.9554 - val_loss: 0.2877 - val_accuracy: 0.8764\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1310 - accuracy: 0.9359 - val_loss: 0.1722 - val_accuracy: 0.9663\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1236 - accuracy: 0.9387 - val_loss: 0.1726 - val_accuracy: 0.9101\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0993 - accuracy: 0.9610 - val_loss: 0.1390 - val_accuracy: 0.9663\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0775 - accuracy: 0.9471 - val_loss: 0.2749 - val_accuracy: 0.9551\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0606 - accuracy: 0.9777 - val_loss: 0.3397 - val_accuracy: 0.9551\n",
      "Fold 4, Best Validation Loss: 0.07100562006235123, Best Validation Accuracy: 0.9775280952453613\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - 1s 30ms/step - loss: 0.2756 - accuracy: 0.9085 - val_loss: 0.5902 - val_accuracy: 0.7528\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2344 - accuracy: 0.9174 - val_loss: 0.5469 - val_accuracy: 0.7528\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2147 - accuracy: 0.9263 - val_loss: 0.5028 - val_accuracy: 0.7528\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2194 - accuracy: 0.9085 - val_loss: 0.8364 - val_accuracy: 0.7528\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2142 - accuracy: 0.9241 - val_loss: 0.4952 - val_accuracy: 0.7528\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1834 - accuracy: 0.9286 - val_loss: 0.4652 - val_accuracy: 0.7528\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1809 - accuracy: 0.9263 - val_loss: 0.4436 - val_accuracy: 0.7528\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1714 - accuracy: 0.9330 - val_loss: 0.6980 - val_accuracy: 0.7528\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1537 - accuracy: 0.9375 - val_loss: 0.4559 - val_accuracy: 0.8202\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.1998 - accuracy: 0.9152 - val_loss: 0.6089 - val_accuracy: 0.7640\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1792 - accuracy: 0.9263 - val_loss: 0.6125 - val_accuracy: 0.7528\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1558 - accuracy: 0.9375 - val_loss: 0.4423 - val_accuracy: 0.7528\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.1289 - accuracy: 0.9397 - val_loss: 0.4267 - val_accuracy: 0.7416\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1417 - accuracy: 0.9375 - val_loss: 0.4304 - val_accuracy: 0.7640\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1272 - accuracy: 0.9308 - val_loss: 0.5167 - val_accuracy: 0.7865\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.1337 - accuracy: 0.9308 - val_loss: 0.5266 - val_accuracy: 0.7753\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.1310 - accuracy: 0.9308 - val_loss: 0.5522 - val_accuracy: 0.7978\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.1624 - accuracy: 0.9085 - val_loss: 0.5054 - val_accuracy: 0.8090\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.1470 - accuracy: 0.9420 - val_loss: 0.5022 - val_accuracy: 0.7978\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.1174 - accuracy: 0.9375 - val_loss: 0.5954 - val_accuracy: 0.8315\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0944 - accuracy: 0.9464 - val_loss: 0.5757 - val_accuracy: 0.8427\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1129 - accuracy: 0.9464 - val_loss: 0.3868 - val_accuracy: 0.8876\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0855 - accuracy: 0.9554 - val_loss: 0.4127 - val_accuracy: 0.8427\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0739 - accuracy: 0.9777 - val_loss: 0.7891 - val_accuracy: 0.8427\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0880 - accuracy: 0.9621 - val_loss: 0.4861 - val_accuracy: 0.8315\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1119 - accuracy: 0.9621 - val_loss: 0.3100 - val_accuracy: 0.8539\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1068 - accuracy: 0.9509 - val_loss: 0.3549 - val_accuracy: 0.8315\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0765 - accuracy: 0.9665 - val_loss: 0.3551 - val_accuracy: 0.8202\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0601 - accuracy: 0.9710 - val_loss: 0.4574 - val_accuracy: 0.8315\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0555 - accuracy: 0.9754 - val_loss: 0.6226 - val_accuracy: 0.8202\n",
      "Fold 5, Best Validation Loss: 0.3099687695503235, Best Validation Accuracy: 0.8876404762268066\n",
      "Mean Best Validation Loss: 0.2573314102366567\n",
      "Mean Best Validation Accuracy: 0.9280898928642273\n",
      "Epoch 1/30\n",
      "78/78 [==============================] - 2s 8ms/step - loss: 0.3517 - accuracy: 0.8960 - val_loss: 0.3378 - val_accuracy: 0.8947\n",
      "Epoch 2/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3213 - accuracy: 0.9081 - val_loss: 0.3387 - val_accuracy: 0.8947\n",
      "Epoch 3/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3130 - accuracy: 0.9081 - val_loss: 0.3367 - val_accuracy: 0.8947\n",
      "Epoch 4/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3161 - accuracy: 0.9081 - val_loss: 0.3367 - val_accuracy: 0.8947\n",
      "Epoch 5/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3140 - accuracy: 0.9081 - val_loss: 0.3367 - val_accuracy: 0.8947\n",
      "Epoch 6/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3148 - accuracy: 0.9081 - val_loss: 0.3392 - val_accuracy: 0.8947\n",
      "Epoch 7/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3159 - accuracy: 0.9081 - val_loss: 0.3386 - val_accuracy: 0.8947\n",
      "Epoch 8/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3142 - accuracy: 0.9081 - val_loss: 0.3408 - val_accuracy: 0.8947\n",
      "Epoch 9/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3134 - accuracy: 0.9081 - val_loss: 0.3373 - val_accuracy: 0.8947\n",
      "Epoch 10/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3114 - accuracy: 0.9081 - val_loss: 0.3366 - val_accuracy: 0.8947\n",
      "Epoch 11/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3129 - accuracy: 0.9081 - val_loss: 0.3392 - val_accuracy: 0.8947\n",
      "Epoch 12/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3184 - accuracy: 0.9081 - val_loss: 0.3393 - val_accuracy: 0.8947\n",
      "Epoch 13/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3158 - accuracy: 0.9081 - val_loss: 0.3365 - val_accuracy: 0.8947\n",
      "Epoch 14/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3167 - accuracy: 0.9081 - val_loss: 0.3395 - val_accuracy: 0.8947\n",
      "Epoch 15/30\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3160 - accuracy: 0.9081 - val_loss: 0.3366 - val_accuracy: 0.8947\n",
      "Epoch 16/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3126 - accuracy: 0.9081 - val_loss: 0.3392 - val_accuracy: 0.8947\n",
      "Epoch 17/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3121 - accuracy: 0.9081 - val_loss: 0.3375 - val_accuracy: 0.8947\n",
      "Epoch 18/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3111 - accuracy: 0.9081 - val_loss: 0.3410 - val_accuracy: 0.8947\n",
      "Epoch 19/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3148 - accuracy: 0.9081 - val_loss: 0.3366 - val_accuracy: 0.8947\n",
      "Epoch 20/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3164 - accuracy: 0.9081 - val_loss: 0.3375 - val_accuracy: 0.8947\n",
      "Epoch 21/30\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3100 - accuracy: 0.9081 - val_loss: 0.3370 - val_accuracy: 0.8947\n",
      "Epoch 22/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3149 - accuracy: 0.9081 - val_loss: 0.3378 - val_accuracy: 0.8947\n",
      "Epoch 23/30\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.9081 - val_loss: 0.3377 - val_accuracy: 0.8947\n",
      "Epoch 24/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3071 - accuracy: 0.9081 - val_loss: 0.3392 - val_accuracy: 0.8947\n",
      "Epoch 25/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3123 - accuracy: 0.9081 - val_loss: 0.3415 - val_accuracy: 0.8947\n",
      "Epoch 26/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3140 - accuracy: 0.9081 - val_loss: 0.3378 - val_accuracy: 0.8947\n",
      "Epoch 27/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3143 - accuracy: 0.9081 - val_loss: 0.3386 - val_accuracy: 0.8947\n",
      "Epoch 28/30\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.9081 - val_loss: 0.3370 - val_accuracy: 0.8947\n",
      "Epoch 29/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3127 - accuracy: 0.9081 - val_loss: 0.3366 - val_accuracy: 0.8947\n",
      "Epoch 30/30\n",
      "78/78 [==============================] - 0s 6ms/step - loss: 0.3091 - accuracy: 0.9081 - val_loss: 0.3368 - val_accuracy: 0.8947\n",
      "Fold 1, Best Validation Loss: 0.33654797077178955, Best Validation Accuracy: 0.8947156071662903\n",
      "Epoch 1/30\n",
      "155/155 [==============================] - 2s 6ms/step - loss: 0.3461 - accuracy: 0.9006 - val_loss: 0.2999 - val_accuracy: 0.9109\n",
      "Epoch 2/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3312 - accuracy: 0.9014 - val_loss: 0.3047 - val_accuracy: 0.9109\n",
      "Epoch 3/30\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.3293 - accuracy: 0.9014 - val_loss: 0.2852 - val_accuracy: 0.9109\n",
      "Epoch 4/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3293 - accuracy: 0.9014 - val_loss: 0.3034 - val_accuracy: 0.9109\n",
      "Epoch 5/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3300 - accuracy: 0.9014 - val_loss: 0.3005 - val_accuracy: 0.9109\n",
      "Epoch 6/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3326 - accuracy: 0.9014 - val_loss: 0.3096 - val_accuracy: 0.9109\n",
      "Epoch 7/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3261 - accuracy: 0.9014 - val_loss: 0.3025 - val_accuracy: 0.9109\n",
      "Epoch 8/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3279 - accuracy: 0.9014 - val_loss: 0.3013 - val_accuracy: 0.9109\n",
      "Epoch 9/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3324 - accuracy: 0.9014 - val_loss: 0.3017 - val_accuracy: 0.9109\n",
      "Epoch 10/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3285 - accuracy: 0.9014 - val_loss: 0.3002 - val_accuracy: 0.9109\n",
      "Epoch 11/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3268 - accuracy: 0.9014 - val_loss: 0.3006 - val_accuracy: 0.9109\n",
      "Epoch 12/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3293 - accuracy: 0.9014 - val_loss: 0.3006 - val_accuracy: 0.9109\n",
      "Epoch 13/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3306 - accuracy: 0.9014 - val_loss: 0.3006 - val_accuracy: 0.9109\n",
      "Epoch 14/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3258 - accuracy: 0.9014 - val_loss: 0.3012 - val_accuracy: 0.9109\n",
      "Epoch 15/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3279 - accuracy: 0.9014 - val_loss: 0.3012 - val_accuracy: 0.9109\n",
      "Epoch 16/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3295 - accuracy: 0.9014 - val_loss: 0.3003 - val_accuracy: 0.9109\n",
      "Epoch 17/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3257 - accuracy: 0.9014 - val_loss: 0.3083 - val_accuracy: 0.9109\n",
      "Epoch 18/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3294 - accuracy: 0.9014 - val_loss: 0.3178 - val_accuracy: 0.9109\n",
      "Epoch 19/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3261 - accuracy: 0.9014 - val_loss: 0.2980 - val_accuracy: 0.9109\n",
      "Epoch 20/30\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.3279 - accuracy: 0.9014 - val_loss: 0.3088 - val_accuracy: 0.9109\n",
      "Epoch 21/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3253 - accuracy: 0.9014 - val_loss: 0.2985 - val_accuracy: 0.9109\n",
      "Epoch 22/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3259 - accuracy: 0.9014 - val_loss: 0.3197 - val_accuracy: 0.9109\n",
      "Epoch 23/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3269 - accuracy: 0.9014 - val_loss: 0.3020 - val_accuracy: 0.9109\n",
      "Epoch 24/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.9014 - val_loss: 0.2915 - val_accuracy: 0.9109\n",
      "Epoch 25/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.9014 - val_loss: 0.3016 - val_accuracy: 0.9109\n",
      "Epoch 26/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.9014 - val_loss: 0.3057 - val_accuracy: 0.9109\n",
      "Epoch 27/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3251 - accuracy: 0.9014 - val_loss: 0.2942 - val_accuracy: 0.9109\n",
      "Epoch 28/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3251 - accuracy: 0.9014 - val_loss: 0.3059 - val_accuracy: 0.9109\n",
      "Epoch 29/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3239 - accuracy: 0.9014 - val_loss: 0.3022 - val_accuracy: 0.9109\n",
      "Epoch 30/30\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3245 - accuracy: 0.9014 - val_loss: 0.3008 - val_accuracy: 0.9109\n",
      "Fold 2, Best Validation Loss: 0.28520122170448303, Best Validation Accuracy: 0.9108511209487915\n",
      "Epoch 1/30\n",
      "233/233 [==============================] - 3s 6ms/step - loss: 0.3388 - accuracy: 0.9019 - val_loss: 0.3314 - val_accuracy: 0.8975\n",
      "Epoch 2/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3239 - accuracy: 0.9046 - val_loss: 0.3306 - val_accuracy: 0.8975\n",
      "Epoch 3/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3234 - accuracy: 0.9046 - val_loss: 0.3326 - val_accuracy: 0.8975\n",
      "Epoch 4/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3215 - accuracy: 0.9046 - val_loss: 0.3347 - val_accuracy: 0.8975\n",
      "Epoch 5/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3210 - accuracy: 0.9046 - val_loss: 0.3336 - val_accuracy: 0.8975\n",
      "Epoch 6/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3194 - accuracy: 0.9046 - val_loss: 0.3305 - val_accuracy: 0.8975\n",
      "Epoch 7/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3204 - accuracy: 0.9046 - val_loss: 0.3312 - val_accuracy: 0.8975\n",
      "Epoch 8/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3227 - accuracy: 0.9046 - val_loss: 0.3302 - val_accuracy: 0.8975\n",
      "Epoch 9/30\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.3195 - accuracy: 0.9046 - val_loss: 0.3352 - val_accuracy: 0.8975\n",
      "Epoch 10/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3207 - accuracy: 0.9046 - val_loss: 0.3319 - val_accuracy: 0.8975\n",
      "Epoch 11/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3197 - accuracy: 0.9046 - val_loss: 0.3310 - val_accuracy: 0.8975\n",
      "Epoch 12/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3195 - accuracy: 0.9046 - val_loss: 0.3308 - val_accuracy: 0.8975\n",
      "Epoch 13/30\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.3219 - accuracy: 0.9046 - val_loss: 0.3308 - val_accuracy: 0.8975\n",
      "Epoch 14/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3188 - accuracy: 0.9046 - val_loss: 0.3335 - val_accuracy: 0.8975\n",
      "Epoch 15/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3196 - accuracy: 0.9046 - val_loss: 0.3305 - val_accuracy: 0.8975\n",
      "Epoch 16/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3189 - accuracy: 0.9046 - val_loss: 0.3322 - val_accuracy: 0.8975\n",
      "Epoch 17/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3179 - accuracy: 0.9046 - val_loss: 0.3318 - val_accuracy: 0.8975\n",
      "Epoch 18/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3176 - accuracy: 0.9046 - val_loss: 0.3308 - val_accuracy: 0.8975\n",
      "Epoch 19/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3180 - accuracy: 0.9046 - val_loss: 0.3310 - val_accuracy: 0.8975\n",
      "Epoch 20/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3174 - accuracy: 0.9046 - val_loss: 0.3307 - val_accuracy: 0.8975\n",
      "Epoch 21/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3169 - accuracy: 0.9046 - val_loss: 0.3327 - val_accuracy: 0.8975\n",
      "Epoch 22/30\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.3183 - accuracy: 0.9046 - val_loss: 0.3305 - val_accuracy: 0.8975\n",
      "Epoch 23/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3170 - accuracy: 0.9046 - val_loss: 0.3305 - val_accuracy: 0.8975\n",
      "Epoch 24/30\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.3183 - accuracy: 0.9046 - val_loss: 0.3305 - val_accuracy: 0.8975\n",
      "Epoch 25/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3171 - accuracy: 0.9046 - val_loss: 0.3308 - val_accuracy: 0.8975\n",
      "Epoch 26/30\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.3162 - accuracy: 0.9046 - val_loss: 0.3332 - val_accuracy: 0.8975\n",
      "Epoch 27/30\n",
      "233/233 [==============================] - 1s 6ms/step - loss: 0.3173 - accuracy: 0.9046 - val_loss: 0.3308 - val_accuracy: 0.8975\n",
      "Epoch 28/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3168 - accuracy: 0.9046 - val_loss: 0.3312 - val_accuracy: 0.8975\n",
      "Epoch 29/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3169 - accuracy: 0.9046 - val_loss: 0.3309 - val_accuracy: 0.8975\n",
      "Epoch 30/30\n",
      "233/233 [==============================] - 1s 5ms/step - loss: 0.3173 - accuracy: 0.9046 - val_loss: 0.3306 - val_accuracy: 0.8975\n",
      "Fold 3, Best Validation Loss: 0.330249547958374, Best Validation Accuracy: 0.8975393176078796\n",
      "Epoch 1/30\n",
      "310/310 [==============================] - 3s 5ms/step - loss: 0.3390 - accuracy: 0.8976 - val_loss: 0.3212 - val_accuracy: 0.9020\n",
      "Epoch 2/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3269 - accuracy: 0.9028 - val_loss: 0.3218 - val_accuracy: 0.9020\n",
      "Epoch 3/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3244 - accuracy: 0.9028 - val_loss: 0.3244 - val_accuracy: 0.9020\n",
      "Epoch 4/30\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.9028 - val_loss: 0.3222 - val_accuracy: 0.9020\n",
      "Epoch 5/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3257 - accuracy: 0.9028 - val_loss: 0.3254 - val_accuracy: 0.9020\n",
      "Epoch 6/30\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.9028 - val_loss: 0.3207 - val_accuracy: 0.9020\n",
      "Epoch 7/30\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3237 - accuracy: 0.9028 - val_loss: 0.3222 - val_accuracy: 0.9020\n",
      "Epoch 8/30\n",
      "310/310 [==============================] - 2s 6ms/step - loss: 0.3234 - accuracy: 0.9028 - val_loss: 0.3213 - val_accuracy: 0.9020\n",
      "Epoch 9/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3237 - accuracy: 0.9028 - val_loss: 0.3211 - val_accuracy: 0.9020\n",
      "Epoch 10/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3252 - accuracy: 0.9028 - val_loss: 0.3207 - val_accuracy: 0.9020\n",
      "Epoch 11/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3245 - accuracy: 0.9028 - val_loss: 0.3210 - val_accuracy: 0.9020\n",
      "Epoch 12/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3231 - accuracy: 0.9028 - val_loss: 0.3212 - val_accuracy: 0.9020\n",
      "Epoch 13/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3230 - accuracy: 0.9028 - val_loss: 0.3215 - val_accuracy: 0.9020\n",
      "Epoch 14/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3228 - accuracy: 0.9028 - val_loss: 0.3219 - val_accuracy: 0.9020\n",
      "Epoch 15/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3224 - accuracy: 0.9028 - val_loss: 0.3223 - val_accuracy: 0.9020\n",
      "Epoch 16/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3228 - accuracy: 0.9028 - val_loss: 0.3207 - val_accuracy: 0.9020\n",
      "Epoch 17/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3230 - accuracy: 0.9028 - val_loss: 0.3212 - val_accuracy: 0.9020\n",
      "Epoch 18/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3210 - accuracy: 0.9028 - val_loss: 0.3211 - val_accuracy: 0.9020\n",
      "Epoch 19/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3223 - accuracy: 0.9028 - val_loss: 0.3216 - val_accuracy: 0.9020\n",
      "Epoch 20/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3217 - accuracy: 0.9028 - val_loss: 0.3209 - val_accuracy: 0.9020\n",
      "Epoch 21/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3225 - accuracy: 0.9028 - val_loss: 0.3209 - val_accuracy: 0.9020\n",
      "Epoch 22/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3212 - accuracy: 0.9028 - val_loss: 0.3221 - val_accuracy: 0.9020\n",
      "Epoch 23/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3212 - accuracy: 0.9028 - val_loss: 0.3213 - val_accuracy: 0.9020\n",
      "Epoch 24/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3208 - accuracy: 0.9028 - val_loss: 0.3216 - val_accuracy: 0.9020\n",
      "Epoch 25/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3211 - accuracy: 0.9028 - val_loss: 0.3207 - val_accuracy: 0.9020\n",
      "Epoch 26/30\n",
      "310/310 [==============================] - 2s 6ms/step - loss: 0.3210 - accuracy: 0.9028 - val_loss: 0.3209 - val_accuracy: 0.9020\n",
      "Epoch 27/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3209 - accuracy: 0.9028 - val_loss: 0.3207 - val_accuracy: 0.9020\n",
      "Epoch 28/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3202 - accuracy: 0.9028 - val_loss: 0.3208 - val_accuracy: 0.9020\n",
      "Epoch 29/30\n",
      "310/310 [==============================] - 2s 6ms/step - loss: 0.3206 - accuracy: 0.9028 - val_loss: 0.3207 - val_accuracy: 0.9020\n",
      "Epoch 30/30\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3203 - accuracy: 0.9028 - val_loss: 0.3207 - val_accuracy: 0.9020\n",
      "Fold 4, Best Validation Loss: 0.320722371339798, Best Validation Accuracy: 0.9019765853881836\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 4s 5ms/step - loss: 0.3375 - accuracy: 0.8996 - val_loss: 0.3565 - val_accuracy: 0.8866\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3256 - accuracy: 0.9026 - val_loss: 0.3556 - val_accuracy: 0.8866\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3251 - accuracy: 0.9026 - val_loss: 0.3566 - val_accuracy: 0.8866\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3257 - accuracy: 0.9026 - val_loss: 0.3574 - val_accuracy: 0.8866\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3249 - accuracy: 0.9026 - val_loss: 0.3535 - val_accuracy: 0.8866\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3240 - accuracy: 0.9026 - val_loss: 0.3553 - val_accuracy: 0.8866\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3249 - accuracy: 0.9026 - val_loss: 0.3535 - val_accuracy: 0.8866\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3236 - accuracy: 0.9026 - val_loss: 0.3549 - val_accuracy: 0.8866\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3228 - accuracy: 0.9026 - val_loss: 0.3536 - val_accuracy: 0.8866\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3233 - accuracy: 0.9026 - val_loss: 0.3550 - val_accuracy: 0.8866\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3227 - accuracy: 0.9026 - val_loss: 0.3552 - val_accuracy: 0.8866\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3230 - accuracy: 0.9026 - val_loss: 0.3562 - val_accuracy: 0.8866\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3224 - accuracy: 0.9026 - val_loss: 0.3573 - val_accuracy: 0.8866\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3224 - accuracy: 0.9026 - val_loss: 0.3535 - val_accuracy: 0.8866\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3223 - accuracy: 0.9026 - val_loss: 0.3546 - val_accuracy: 0.8866\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3203 - accuracy: 0.9026 - val_loss: 0.3582 - val_accuracy: 0.8866\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3220 - accuracy: 0.9026 - val_loss: 0.3547 - val_accuracy: 0.8866\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3215 - accuracy: 0.9026 - val_loss: 0.3537 - val_accuracy: 0.8866\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3215 - accuracy: 0.9026 - val_loss: 0.3544 - val_accuracy: 0.8866\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3216 - accuracy: 0.9026 - val_loss: 0.3553 - val_accuracy: 0.8866\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3211 - accuracy: 0.9026 - val_loss: 0.3546 - val_accuracy: 0.8866\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3207 - accuracy: 0.9026 - val_loss: 0.3539 - val_accuracy: 0.8866\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3204 - accuracy: 0.9026 - val_loss: 0.3583 - val_accuracy: 0.8866\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3204 - accuracy: 0.9026 - val_loss: 0.3570 - val_accuracy: 0.8866\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3205 - accuracy: 0.9026 - val_loss: 0.3547 - val_accuracy: 0.8866\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3201 - accuracy: 0.9026 - val_loss: 0.3552 - val_accuracy: 0.8866\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3205 - accuracy: 0.9026 - val_loss: 0.3542 - val_accuracy: 0.8866\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3207 - accuracy: 0.9026 - val_loss: 0.3558 - val_accuracy: 0.8866\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3205 - accuracy: 0.9026 - val_loss: 0.3561 - val_accuracy: 0.8866\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.3206 - accuracy: 0.9026 - val_loss: 0.3545 - val_accuracy: 0.8866\n",
      "Fold 5, Best Validation Loss: 0.35346683859825134, Best Validation Accuracy: 0.8866478204727173\n",
      "Mean Best Validation Loss: 0.3252375900745392\n",
      "Mean Best Validation Accuracy: 0.8983460903167725\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 4s 59ms/step - loss: 0.5953 - accuracy: 0.7029 - val_loss: 0.4025 - val_accuracy: 0.8713\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.9086 - val_loss: 0.3841 - val_accuracy: 0.8713\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3168 - accuracy: 0.9086 - val_loss: 0.4093 - val_accuracy: 0.8713\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3081 - accuracy: 0.9086 - val_loss: 0.3903 - val_accuracy: 0.8713\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2820 - accuracy: 0.9086 - val_loss: 0.3122 - val_accuracy: 0.8713\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3099 - accuracy: 0.9086 - val_loss: 0.3004 - val_accuracy: 0.8713\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2808 - accuracy: 0.9086 - val_loss: 0.2993 - val_accuracy: 0.8713\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2182 - accuracy: 0.9086 - val_loss: 0.2774 - val_accuracy: 0.8713\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2537 - accuracy: 0.9029 - val_loss: 0.2639 - val_accuracy: 0.8713\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2356 - accuracy: 0.9143 - val_loss: 0.2590 - val_accuracy: 0.8713\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2029 - accuracy: 0.9257 - val_loss: 0.2781 - val_accuracy: 0.8947\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2147 - accuracy: 0.9429 - val_loss: 0.2830 - val_accuracy: 0.8947\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1690 - accuracy: 0.9200 - val_loss: 0.2738 - val_accuracy: 0.8596\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1835 - accuracy: 0.9486 - val_loss: 0.2550 - val_accuracy: 0.8655\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1394 - accuracy: 0.9429 - val_loss: 0.2190 - val_accuracy: 0.8830\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1864 - accuracy: 0.9314 - val_loss: 0.2139 - val_accuracy: 0.9006\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1522 - accuracy: 0.9314 - val_loss: 0.2008 - val_accuracy: 0.9123\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1623 - accuracy: 0.9543 - val_loss: 0.1961 - val_accuracy: 0.9357\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1875 - accuracy: 0.9314 - val_loss: 0.2090 - val_accuracy: 0.9357\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1304 - accuracy: 0.9314 - val_loss: 0.2088 - val_accuracy: 0.9123\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1388 - accuracy: 0.9314 - val_loss: 0.2298 - val_accuracy: 0.8889\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1492 - accuracy: 0.9371 - val_loss: 0.2384 - val_accuracy: 0.8947\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1619 - accuracy: 0.9143 - val_loss: 0.2352 - val_accuracy: 0.9064\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1498 - accuracy: 0.9257 - val_loss: 0.2219 - val_accuracy: 0.9357\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1357 - accuracy: 0.9486 - val_loss: 0.2176 - val_accuracy: 0.9415\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1419 - accuracy: 0.9257 - val_loss: 0.2099 - val_accuracy: 0.9474\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1184 - accuracy: 0.9486 - val_loss: 0.2014 - val_accuracy: 0.9298\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1054 - accuracy: 0.9600 - val_loss: 0.2037 - val_accuracy: 0.9298\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1770 - accuracy: 0.9257 - val_loss: 0.2137 - val_accuracy: 0.9123\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1048 - accuracy: 0.9657 - val_loss: 0.2045 - val_accuracy: 0.9240\n",
      "Fold 1, Best Validation Loss: 0.19605058431625366, Best Validation Accuracy: 0.9473684430122375\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 31ms/step - loss: 0.4627 - accuracy: 0.8410 - val_loss: 0.2905 - val_accuracy: 0.9181\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.3693 - accuracy: 0.8902 - val_loss: 0.2693 - val_accuracy: 0.9181\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3206 - accuracy: 0.8902 - val_loss: 0.2729 - val_accuracy: 0.9181\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3103 - accuracy: 0.8902 - val_loss: 0.2585 - val_accuracy: 0.9181\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2431 - accuracy: 0.8902 - val_loss: 0.2647 - val_accuracy: 0.9181\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2378 - accuracy: 0.9075 - val_loss: 0.2709 - val_accuracy: 0.9240\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.2293 - accuracy: 0.9104 - val_loss: 0.2641 - val_accuracy: 0.9357\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1860 - accuracy: 0.9191 - val_loss: 0.3060 - val_accuracy: 0.8889\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2230 - accuracy: 0.9017 - val_loss: 0.3184 - val_accuracy: 0.8889\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2022 - accuracy: 0.9104 - val_loss: 0.2945 - val_accuracy: 0.8830\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1814 - accuracy: 0.9191 - val_loss: 0.2876 - val_accuracy: 0.9006\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1683 - accuracy: 0.9364 - val_loss: 0.2928 - val_accuracy: 0.9181\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1911 - accuracy: 0.9220 - val_loss: 0.2825 - val_accuracy: 0.9064\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1779 - accuracy: 0.9422 - val_loss: 0.2819 - val_accuracy: 0.9181\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1583 - accuracy: 0.9422 - val_loss: 0.2865 - val_accuracy: 0.9181\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1581 - accuracy: 0.9335 - val_loss: 0.2976 - val_accuracy: 0.9123\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1601 - accuracy: 0.9335 - val_loss: 0.2894 - val_accuracy: 0.9064\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1578 - accuracy: 0.9451 - val_loss: 0.3206 - val_accuracy: 0.8830\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1435 - accuracy: 0.9277 - val_loss: 0.3372 - val_accuracy: 0.8889\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1472 - accuracy: 0.9364 - val_loss: 0.3355 - val_accuracy: 0.8947\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1716 - accuracy: 0.9335 - val_loss: 0.3294 - val_accuracy: 0.9006\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1415 - accuracy: 0.9364 - val_loss: 0.2930 - val_accuracy: 0.9123\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1575 - accuracy: 0.9480 - val_loss: 0.2798 - val_accuracy: 0.9415\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1654 - accuracy: 0.9451 - val_loss: 0.2669 - val_accuracy: 0.9123\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1456 - accuracy: 0.9538 - val_loss: 0.2867 - val_accuracy: 0.9064\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1356 - accuracy: 0.9480 - val_loss: 0.3071 - val_accuracy: 0.9123\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1327 - accuracy: 0.9566 - val_loss: 0.3063 - val_accuracy: 0.9240\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1540 - accuracy: 0.9422 - val_loss: 0.2911 - val_accuracy: 0.9240\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1461 - accuracy: 0.9364 - val_loss: 0.2643 - val_accuracy: 0.9240\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1396 - accuracy: 0.9480 - val_loss: 0.2880 - val_accuracy: 0.9181\n",
      "Fold 2, Best Validation Loss: 0.2585424482822418, Best Validation Accuracy: 0.9415204524993896\n",
      "Epoch 1/30\n",
      "17/17 [==============================] - 2s 21ms/step - loss: 0.4371 - accuracy: 0.8511 - val_loss: 0.2633 - val_accuracy: 0.9240\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3134 - accuracy: 0.8994 - val_loss: 0.2407 - val_accuracy: 0.9240\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2992 - accuracy: 0.8975 - val_loss: 0.2024 - val_accuracy: 0.9240\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2913 - accuracy: 0.8975 - val_loss: 0.1925 - val_accuracy: 0.9298\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2523 - accuracy: 0.8975 - val_loss: 0.1795 - val_accuracy: 0.9240\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2465 - accuracy: 0.9052 - val_loss: 0.1801 - val_accuracy: 0.9357\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2529 - accuracy: 0.9110 - val_loss: 0.1874 - val_accuracy: 0.9240\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2656 - accuracy: 0.9052 - val_loss: 0.1773 - val_accuracy: 0.9298\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2299 - accuracy: 0.9130 - val_loss: 0.1861 - val_accuracy: 0.9357\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2335 - accuracy: 0.9439 - val_loss: 0.1758 - val_accuracy: 0.9357\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2425 - accuracy: 0.9149 - val_loss: 0.1856 - val_accuracy: 0.9123\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2088 - accuracy: 0.9284 - val_loss: 0.1807 - val_accuracy: 0.9298\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2123 - accuracy: 0.9304 - val_loss: 0.1838 - val_accuracy: 0.9415\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2256 - accuracy: 0.9188 - val_loss: 0.1614 - val_accuracy: 0.9415\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2040 - accuracy: 0.9284 - val_loss: 0.1644 - val_accuracy: 0.9357\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2236 - accuracy: 0.9323 - val_loss: 0.1841 - val_accuracy: 0.9298\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2089 - accuracy: 0.9304 - val_loss: 0.1887 - val_accuracy: 0.9298\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2041 - accuracy: 0.9342 - val_loss: 0.1972 - val_accuracy: 0.9181\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2024 - accuracy: 0.9323 - val_loss: 0.2072 - val_accuracy: 0.9181\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1897 - accuracy: 0.9381 - val_loss: 0.1980 - val_accuracy: 0.9240\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2006 - accuracy: 0.9304 - val_loss: 0.1751 - val_accuracy: 0.9298\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2114 - accuracy: 0.9188 - val_loss: 0.1686 - val_accuracy: 0.9357\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1898 - accuracy: 0.9323 - val_loss: 0.1735 - val_accuracy: 0.9298\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1891 - accuracy: 0.9323 - val_loss: 0.1792 - val_accuracy: 0.9298\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1971 - accuracy: 0.9304 - val_loss: 0.1986 - val_accuracy: 0.9357\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1828 - accuracy: 0.9362 - val_loss: 0.1737 - val_accuracy: 0.9357\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1987 - accuracy: 0.9323 - val_loss: 0.1780 - val_accuracy: 0.9240\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1735 - accuracy: 0.9458 - val_loss: 0.1970 - val_accuracy: 0.9357\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1773 - accuracy: 0.9420 - val_loss: 0.2113 - val_accuracy: 0.9298\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1963 - accuracy: 0.9342 - val_loss: 0.1775 - val_accuracy: 0.9357\n",
      "Fold 3, Best Validation Loss: 0.16138383746147156, Best Validation Accuracy: 0.9415204524993896\n",
      "Epoch 1/30\n",
      "22/22 [==============================] - 2s 15ms/step - loss: 0.3981 - accuracy: 0.8721 - val_loss: 0.3175 - val_accuracy: 0.9006\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.9055 - val_loss: 0.2653 - val_accuracy: 0.9006\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2759 - accuracy: 0.9055 - val_loss: 0.2278 - val_accuracy: 0.9006\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.2359 - accuracy: 0.9055 - val_loss: 0.2043 - val_accuracy: 0.9006\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2461 - accuracy: 0.9099 - val_loss: 0.1921 - val_accuracy: 0.9006\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2398 - accuracy: 0.9055 - val_loss: 0.1885 - val_accuracy: 0.9123\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2379 - accuracy: 0.9026 - val_loss: 0.1539 - val_accuracy: 0.9415\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.2477 - accuracy: 0.9142 - val_loss: 0.1686 - val_accuracy: 0.9474\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.2334 - accuracy: 0.9259 - val_loss: 0.1626 - val_accuracy: 0.9532\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2287 - accuracy: 0.9201 - val_loss: 0.1561 - val_accuracy: 0.9532\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2116 - accuracy: 0.9288 - val_loss: 0.1609 - val_accuracy: 0.9474\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9375 - val_loss: 0.1618 - val_accuracy: 0.9415\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1951 - accuracy: 0.9360 - val_loss: 0.1476 - val_accuracy: 0.9357\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2052 - accuracy: 0.9346 - val_loss: 0.1319 - val_accuracy: 0.9474\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2026 - accuracy: 0.9331 - val_loss: 0.1569 - val_accuracy: 0.9357\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.2049 - accuracy: 0.9273 - val_loss: 0.1739 - val_accuracy: 0.9123\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2075 - accuracy: 0.9302 - val_loss: 0.1772 - val_accuracy: 0.9240\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.2005 - accuracy: 0.9346 - val_loss: 0.1789 - val_accuracy: 0.9123\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.9404 - val_loss: 0.1704 - val_accuracy: 0.9357\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.2235 - accuracy: 0.9157 - val_loss: 0.1640 - val_accuracy: 0.9298\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1980 - accuracy: 0.9244 - val_loss: 0.1621 - val_accuracy: 0.9298\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1851 - accuracy: 0.9273 - val_loss: 0.1668 - val_accuracy: 0.9298\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1950 - accuracy: 0.9259 - val_loss: 0.1589 - val_accuracy: 0.9298\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1852 - accuracy: 0.9390 - val_loss: 0.1765 - val_accuracy: 0.9240\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1786 - accuracy: 0.9346 - val_loss: 0.1580 - val_accuracy: 0.9240\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1925 - accuracy: 0.9317 - val_loss: 0.1569 - val_accuracy: 0.9298\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1788 - accuracy: 0.9331 - val_loss: 0.1433 - val_accuracy: 0.9357\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1861 - accuracy: 0.9360 - val_loss: 0.1446 - val_accuracy: 0.9298\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.1782 - accuracy: 0.9302 - val_loss: 0.1601 - val_accuracy: 0.9181\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1688 - accuracy: 0.9448 - val_loss: 0.1632 - val_accuracy: 0.9298\n",
      "Fold 4, Best Validation Loss: 0.13185793161392212, Best Validation Accuracy: 0.9532163739204407\n",
      "Epoch 1/30\n",
      "27/27 [==============================] - 2s 14ms/step - loss: 0.3760 - accuracy: 0.8801 - val_loss: 0.3822 - val_accuracy: 0.8772\n",
      "Epoch 2/30\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3057 - accuracy: 0.9045 - val_loss: 0.3350 - val_accuracy: 0.8772\n",
      "Epoch 3/30\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.9045 - val_loss: 0.2961 - val_accuracy: 0.8772\n",
      "Epoch 4/30\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2528 - accuracy: 0.9010 - val_loss: 0.3214 - val_accuracy: 0.8889\n",
      "Epoch 5/30\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.2528 - accuracy: 0.9139 - val_loss: 0.2306 - val_accuracy: 0.9181\n",
      "Epoch 6/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2402 - accuracy: 0.9150 - val_loss: 0.2143 - val_accuracy: 0.9240\n",
      "Epoch 7/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2096 - accuracy: 0.9139 - val_loss: 0.2259 - val_accuracy: 0.9298\n",
      "Epoch 8/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2296 - accuracy: 0.9185 - val_loss: 0.2213 - val_accuracy: 0.9298\n",
      "Epoch 9/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2253 - accuracy: 0.9267 - val_loss: 0.2127 - val_accuracy: 0.9298\n",
      "Epoch 10/30\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.2021 - accuracy: 0.9313 - val_loss: 0.1938 - val_accuracy: 0.9415\n",
      "Epoch 11/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1895 - accuracy: 0.9325 - val_loss: 0.2146 - val_accuracy: 0.9240\n",
      "Epoch 12/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2054 - accuracy: 0.9255 - val_loss: 0.2116 - val_accuracy: 0.9240\n",
      "Epoch 13/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1936 - accuracy: 0.9360 - val_loss: 0.1954 - val_accuracy: 0.9415\n",
      "Epoch 14/30\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1822 - accuracy: 0.9418 - val_loss: 0.1832 - val_accuracy: 0.9415\n",
      "Epoch 15/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1783 - accuracy: 0.9395 - val_loss: 0.1789 - val_accuracy: 0.9415\n",
      "Epoch 16/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1824 - accuracy: 0.9418 - val_loss: 0.1914 - val_accuracy: 0.9240\n",
      "Epoch 17/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1860 - accuracy: 0.9360 - val_loss: 0.1672 - val_accuracy: 0.9415\n",
      "Epoch 18/30\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1832 - accuracy: 0.9360 - val_loss: 0.1715 - val_accuracy: 0.9532\n",
      "Epoch 19/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1821 - accuracy: 0.9325 - val_loss: 0.1889 - val_accuracy: 0.9415\n",
      "Epoch 20/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1578 - accuracy: 0.9325 - val_loss: 0.2086 - val_accuracy: 0.9474\n",
      "Epoch 21/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1810 - accuracy: 0.9348 - val_loss: 0.1625 - val_accuracy: 0.9532\n",
      "Epoch 22/30\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1847 - accuracy: 0.9313 - val_loss: 0.1650 - val_accuracy: 0.9415\n",
      "Epoch 23/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1908 - accuracy: 0.9360 - val_loss: 0.1734 - val_accuracy: 0.9474\n",
      "Epoch 24/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1796 - accuracy: 0.9360 - val_loss: 0.1845 - val_accuracy: 0.9474\n",
      "Epoch 25/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1727 - accuracy: 0.9406 - val_loss: 0.1674 - val_accuracy: 0.9474\n",
      "Epoch 26/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1576 - accuracy: 0.9406 - val_loss: 0.1667 - val_accuracy: 0.9415\n",
      "Epoch 27/30\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1784 - accuracy: 0.9348 - val_loss: 0.1710 - val_accuracy: 0.9415\n",
      "Epoch 28/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1643 - accuracy: 0.9441 - val_loss: 0.1831 - val_accuracy: 0.9357\n",
      "Epoch 29/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1825 - accuracy: 0.9302 - val_loss: 0.1626 - val_accuracy: 0.9474\n",
      "Epoch 30/30\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1550 - accuracy: 0.9441 - val_loss: 0.1710 - val_accuracy: 0.9415\n",
      "Fold 5, Best Validation Loss: 0.1624559760093689, Best Validation Accuracy: 0.9532163739204407\n",
      "Mean Best Validation Loss: 0.1820581555366516\n",
      "Mean Best Validation Accuracy: 0.9473684191703796\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 0.7843 - accuracy: 0.6000 - val_loss: 0.2213 - val_accuracy: 0.9337\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4550 - accuracy: 0.8529 - val_loss: 0.1564 - val_accuracy: 0.9398\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2980 - accuracy: 0.9176 - val_loss: 0.1221 - val_accuracy: 0.9699\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2867 - accuracy: 0.9176 - val_loss: 0.0929 - val_accuracy: 0.9699\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1987 - accuracy: 0.9294 - val_loss: 0.0718 - val_accuracy: 0.9699\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1478 - accuracy: 0.9529 - val_loss: 0.0559 - val_accuracy: 0.9699\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1308 - accuracy: 0.9588 - val_loss: 0.0406 - val_accuracy: 0.9699\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1007 - accuracy: 0.9588 - val_loss: 0.0329 - val_accuracy: 0.9819\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0788 - accuracy: 0.9588 - val_loss: 0.0322 - val_accuracy: 0.9880\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0590 - accuracy: 0.9824 - val_loss: 0.0323 - val_accuracy: 0.9880\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0549 - accuracy: 0.9765 - val_loss: 0.0330 - val_accuracy: 0.9880\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0750 - accuracy: 0.9824 - val_loss: 0.0232 - val_accuracy: 0.9880\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0405 - accuracy: 0.9882 - val_loss: 0.0198 - val_accuracy: 0.9940\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0288 - accuracy: 0.9941 - val_loss: 0.0243 - val_accuracy: 0.9880\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9880\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0578 - accuracy: 0.9765 - val_loss: 0.0564 - val_accuracy: 0.9880\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0571 - accuracy: 0.9765 - val_loss: 0.0259 - val_accuracy: 0.9940\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0830 - accuracy: 0.9706 - val_loss: 0.0247 - val_accuracy: 0.9940\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0451 - accuracy: 0.9824 - val_loss: 0.0363 - val_accuracy: 0.9880\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0358 - accuracy: 0.9824 - val_loss: 0.0698 - val_accuracy: 0.9880\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0541 - accuracy: 0.9824 - val_loss: 0.0306 - val_accuracy: 0.9880\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0262 - accuracy: 0.9882 - val_loss: 0.0227 - val_accuracy: 0.9880\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0378 - accuracy: 0.9882 - val_loss: 0.0241 - val_accuracy: 0.9880\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0105 - accuracy: 0.9941 - val_loss: 0.0250 - val_accuracy: 0.9880\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9940\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.0341 - val_accuracy: 0.9880\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9880\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9880\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9880\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9940\n",
      "Fold 1, Best Validation Loss: 0.01978909969329834, Best Validation Accuracy: 0.9939758777618408\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 34ms/step - loss: 0.3916 - accuracy: 0.8750 - val_loss: 0.1520 - val_accuracy: 0.9578\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1953 - accuracy: 0.9464 - val_loss: 0.0953 - val_accuracy: 0.9699\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1420 - accuracy: 0.9494 - val_loss: 0.0643 - val_accuracy: 0.9639\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0930 - accuracy: 0.9613 - val_loss: 0.0361 - val_accuracy: 0.9759\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 0.9792 - val_loss: 0.0539 - val_accuracy: 0.9819\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0530 - accuracy: 0.9732 - val_loss: 0.0179 - val_accuracy: 0.9880\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9821 - val_loss: 0.0144 - val_accuracy: 0.9940\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0058 - val_accuracy: 0.9940\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.0144 - val_accuracy: 0.9940\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0422 - accuracy: 0.9851 - val_loss: 0.0077 - val_accuracy: 0.9940\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0482 - accuracy: 0.9792 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.0576 - accuracy: 0.9881 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 0.0138 - val_accuracy: 0.9940\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 0.9881 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0286 - accuracy: 0.9851 - val_loss: 0.0190 - val_accuracy: 0.9940\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0274 - accuracy: 0.9881 - val_loss: 4.8590e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 0.9881 - val_loss: 0.0076 - val_accuracy: 0.9940\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 2.3344e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0216 - accuracy: 0.9970 - val_loss: 2.4826e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0277 - accuracy: 0.9940 - val_loss: 4.4192e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 5.4300e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 3.0136e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2321e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 2.4028e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 4.8026e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 5.1900e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.6571e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.2882e-04 - val_accuracy: 1.0000\n",
      "Fold 2, Best Validation Loss: 0.00022320880088955164, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 2s 26ms/step - loss: 0.4007 - accuracy: 0.8267 - val_loss: 0.1188 - val_accuracy: 0.9759\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1757 - accuracy: 0.9462 - val_loss: 0.0601 - val_accuracy: 0.9699\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0722 - accuracy: 0.9761 - val_loss: 0.0227 - val_accuracy: 0.9940\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0635 - accuracy: 0.9701 - val_loss: 0.0149 - val_accuracy: 0.9940\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0602 - accuracy: 0.9821 - val_loss: 0.0354 - val_accuracy: 0.9819\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9900 - val_loss: 0.0214 - val_accuracy: 0.9940\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9880 - val_loss: 0.0132 - val_accuracy: 0.9940\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.0140 - val_accuracy: 0.9940\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9980 - val_loss: 0.0333 - val_accuracy: 0.9940\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0108 - accuracy: 0.9960 - val_loss: 0.0226 - val_accuracy: 0.9940\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0621 - accuracy: 0.9880 - val_loss: 0.0382 - val_accuracy: 0.9940\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0251 - accuracy: 0.9880 - val_loss: 0.0282 - val_accuracy: 0.9940\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.0171 - val_accuracy: 0.9940\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0199 - accuracy: 0.9900 - val_loss: 0.0210 - val_accuracy: 0.9940\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9900 - val_loss: 0.0254 - val_accuracy: 0.9880\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0430 - accuracy: 0.9900 - val_loss: 0.2361 - val_accuracy: 0.9578\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1123 - accuracy: 0.9721 - val_loss: 0.0190 - val_accuracy: 0.9880\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0821 - accuracy: 0.9681 - val_loss: 0.0315 - val_accuracy: 0.9880\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0483 - accuracy: 0.9861 - val_loss: 0.0126 - val_accuracy: 0.9880\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0128 - val_accuracy: 0.9940\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0112 - accuracy: 0.9940 - val_loss: 0.0118 - val_accuracy: 0.9940\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0172 - val_accuracy: 0.9940\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0308 - val_accuracy: 0.9940\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9960 - val_loss: 0.0138 - val_accuracy: 0.9940\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9940\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9940\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9880\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0492 - val_accuracy: 0.9940\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.9960 - val_loss: 0.0187 - val_accuracy: 0.9940\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 0.9980 - val_loss: 0.0197 - val_accuracy: 0.9940\n",
      "Fold 3, Best Validation Loss: 0.011811699718236923, Best Validation Accuracy: 0.9939758777618408\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 23ms/step - loss: 0.4439 - accuracy: 0.8398 - val_loss: 0.1067 - val_accuracy: 0.9759\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.1858 - accuracy: 0.9431 - val_loss: 0.0577 - val_accuracy: 0.9759\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9656 - val_loss: 0.0259 - val_accuracy: 0.9880\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.0573 - accuracy: 0.9775 - val_loss: 0.0296 - val_accuracy: 0.9940\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 0.0283 - val_accuracy: 0.9940\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9835 - val_loss: 0.0487 - val_accuracy: 0.9880\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0383 - accuracy: 0.9850 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0349 - accuracy: 0.9865 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0359 - accuracy: 0.9865 - val_loss: 9.5605e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 0.0063 - val_accuracy: 0.9940\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.0154 - val_accuracy: 0.9940\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.0321 - val_accuracy: 0.9940\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0233 - val_accuracy: 0.9940\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0256 - val_accuracy: 0.9940\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0169 - accuracy: 0.9910 - val_loss: 0.0143 - val_accuracy: 0.9940\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 1.2782e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 1.4960e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0452 - accuracy: 0.9865 - val_loss: 3.0166e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0474 - accuracy: 0.9910 - val_loss: 0.0172 - val_accuracy: 0.9940\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0317 - accuracy: 0.9940 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9910 - val_loss: 5.2446e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.0561 - val_accuracy: 0.9880\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0305 - val_accuracy: 0.9880\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 2.6606e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 2.8580e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9955 - val_loss: 1.6555e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 9.5906e-05 - val_accuracy: 1.0000\n",
      "Fold 4, Best Validation Loss: 9.590629633748904e-05, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "27/27 [==============================] - 2s 18ms/step - loss: 0.2092 - accuracy: 0.9185 - val_loss: 0.0496 - val_accuracy: 0.9819\n",
      "Epoch 2/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0602 - accuracy: 0.9748 - val_loss: 0.0293 - val_accuracy: 0.9880\n",
      "Epoch 3/30\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1055 - accuracy: 0.9628 - val_loss: 0.0683 - val_accuracy: 0.9639\n",
      "Epoch 4/30\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0920 - accuracy: 0.9700 - val_loss: 0.0665 - val_accuracy: 0.9819\n",
      "Epoch 5/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0620 - accuracy: 0.9760 - val_loss: 0.0976 - val_accuracy: 0.9639\n",
      "Epoch 6/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 0.9868 - val_loss: 0.0301 - val_accuracy: 0.9880\n",
      "Epoch 7/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0768 - val_accuracy: 0.9880\n",
      "Epoch 8/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.0563 - val_accuracy: 0.9880\n",
      "Epoch 9/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0292 - accuracy: 0.9892 - val_loss: 0.0776 - val_accuracy: 0.9880\n",
      "Epoch 10/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0261 - accuracy: 0.9940 - val_loss: 0.0154 - val_accuracy: 0.9940\n",
      "Epoch 11/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 0.0462 - val_accuracy: 0.9880\n",
      "Epoch 12/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9916 - val_loss: 0.0516 - val_accuracy: 0.9880\n",
      "Epoch 13/30\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0469 - val_accuracy: 0.9940\n",
      "Epoch 14/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9940 - val_loss: 0.0598 - val_accuracy: 0.9940\n",
      "Epoch 15/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.0170 - val_accuracy: 0.9880\n",
      "Epoch 16/30\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 0.9928 - val_loss: 0.0293 - val_accuracy: 0.9940\n",
      "Epoch 17/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0325 - accuracy: 0.9940 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0415 - accuracy: 0.9868 - val_loss: 0.0512 - val_accuracy: 0.9880\n",
      "Epoch 19/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 0.9940 - val_loss: 0.0161 - val_accuracy: 0.9940\n",
      "Epoch 20/30\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.1058 - val_accuracy: 0.9880\n",
      "Epoch 22/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 3.7159e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.1198 - val_accuracy: 0.9819\n",
      "Epoch 24/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0598 - val_accuracy: 0.9880\n",
      "Epoch 25/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 0.9928 - val_loss: 5.6205e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 0.0107 - val_accuracy: 0.9940\n",
      "Epoch 27/30\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 5.1068e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 9.8999e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.9940 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Fold 5, Best Validation Loss: 5.62048917345237e-05, Best Validation Accuracy: 1.0\n",
      "Mean Best Validation Loss: 0.006395223880099365\n",
      "Mean Best Validation Accuracy: 0.9975903511047364\n",
      "Epoch 1/30\n",
      "64/64 [==============================] - 1s 7ms/step - loss: 0.0810 - accuracy: 0.9858 - val_loss: 2.7972e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 5.5054e-04 - accuracy: 1.0000 - val_loss: 8.5687e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 2.7433e-04 - accuracy: 1.0000 - val_loss: 3.1415e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.2707e-04 - accuracy: 1.0000 - val_loss: 1.4558e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 7.5934e-05 - accuracy: 1.0000 - val_loss: 7.8095e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 6.1390e-05 - accuracy: 1.0000 - val_loss: 4.3244e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 3.9119e-05 - accuracy: 1.0000 - val_loss: 2.6999e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 3.9210e-05 - accuracy: 1.0000 - val_loss: 1.6273e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 3.3246e-05 - accuracy: 1.0000 - val_loss: 1.0231e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.7257e-05 - accuracy: 1.0000 - val_loss: 6.8027e-07 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.7726e-05 - accuracy: 1.0000 - val_loss: 4.7451e-07 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.2486e-05 - accuracy: 1.0000 - val_loss: 2.9802e-07 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.4053e-05 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 9.1772e-06 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 9.0356e-06 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 7.3732e-06 - accuracy: 1.0000 - val_loss: 2.5291e-08 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 6.0403e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 5.4317e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 4.2640e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 3.2411e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 3.3187e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 3.2072e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 2.3515e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.7201e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.9946e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.8567e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.4617e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.8717e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.1505e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.5943e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Fold 1, Best Validation Loss: 0.0, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "128/128 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9893 - val_loss: 1.5135e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 3.0523e-04 - accuracy: 1.0000 - val_loss: 3.6106e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.3725e-04 - accuracy: 1.0000 - val_loss: 1.3074e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 6.6350e-05 - accuracy: 1.0000 - val_loss: 6.1736e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 3.9699e-05 - accuracy: 1.0000 - val_loss: 3.4121e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 3.1045e-05 - accuracy: 1.0000 - val_loss: 1.9405e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.8899e-05 - accuracy: 1.0000 - val_loss: 1.2334e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.4576e-05 - accuracy: 1.0000 - val_loss: 8.2079e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0944e-05 - accuracy: 1.0000 - val_loss: 5.5265e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.0213e-05 - accuracy: 1.0000 - val_loss: 3.5772e-07 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 8.8299e-06 - accuracy: 1.0000 - val_loss: 2.3845e-07 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 6.3027e-06 - accuracy: 1.0000 - val_loss: 1.3408e-07 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 6.1237e-06 - accuracy: 1.0000 - val_loss: 6.0681e-08 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 3.7120e-06 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 3.8171e-06 - accuracy: 1.0000 - val_loss: 2.9104e-11 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 4.0242e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 3.0031e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 2.0044e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 2.1057e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.9233e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.7664e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.9226e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.7951e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.2568e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 1.1710e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 9.3126e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 1.1443e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 8.3900e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 9.0368e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "128/128 [==============================] - 1s 6ms/step - loss: 5.1196e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Fold 2, Best Validation Loss: 0.0, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "192/192 [==============================] - 2s 6ms/step - loss: 0.0207 - accuracy: 0.9967 - val_loss: 10.2069 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 1.4966e-04 - accuracy: 1.0000 - val_loss: 11.7326 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 4.0965e-05 - accuracy: 1.0000 - val_loss: 12.7256 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 2.6728e-05 - accuracy: 1.0000 - val_loss: 13.4503 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 1.4085e-05 - accuracy: 1.0000 - val_loss: 14.0163 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 8.8450e-06 - accuracy: 1.0000 - val_loss: 14.4418 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 6.8144e-06 - accuracy: 1.0000 - val_loss: 14.8043 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 8.0915e-06 - accuracy: 1.0000 - val_loss: 15.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 3.9939e-06 - accuracy: 1.0000 - val_loss: 15.3134 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 3.7249e-06 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 2.3686e-06 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 2.2627e-06 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 1.3852e-06 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 1.2257e-06 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 1.0830e-06 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 7.6923e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 7.5428e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 8.4999e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 6.3774e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 1.1199e-05 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 4.2504e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 4.8637e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 2.8733e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 2.6403e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 2.2193e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 2.3775e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 1.9629e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 1.3754e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 2.0853e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "192/192 [==============================] - 1s 6ms/step - loss: 1.5217e-07 - accuracy: 1.0000 - val_loss: 15.4249 - val_accuracy: 0.0000e+00\n",
      "Fold 3, Best Validation Loss: 10.206899642944336, Best Validation Accuracy: 0.0\n",
      "Epoch 1/30\n",
      "256/256 [==============================] - 3s 6ms/step - loss: 0.4866 - accuracy: 0.7633 - val_loss: 0.2128 - val_accuracy: 0.9980\n",
      "Epoch 2/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.3046 - accuracy: 0.8746 - val_loss: 0.0710 - val_accuracy: 0.9995\n",
      "Epoch 3/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.2667 - accuracy: 0.8929 - val_loss: 0.1410 - val_accuracy: 0.9985\n",
      "Epoch 4/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.2575 - accuracy: 0.8975 - val_loss: 0.0771 - val_accuracy: 0.9995\n",
      "Epoch 5/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.2361 - accuracy: 0.9077 - val_loss: 0.0385 - val_accuracy: 0.9995\n",
      "Epoch 6/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.2389 - accuracy: 0.9061 - val_loss: 0.0458 - val_accuracy: 0.9995\n",
      "Epoch 7/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.2277 - accuracy: 0.9135 - val_loss: 0.0408 - val_accuracy: 0.9995\n",
      "Epoch 8/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.2171 - accuracy: 0.9141 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.2218 - accuracy: 0.9109 - val_loss: 0.0411 - val_accuracy: 0.9995\n",
      "Epoch 10/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.2053 - accuracy: 0.9156 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.2106 - accuracy: 0.9155 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1990 - accuracy: 0.9198 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.2090 - accuracy: 0.9161 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1955 - accuracy: 0.9224 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.1940 - accuracy: 0.9203 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.1953 - accuracy: 0.9186 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1919 - accuracy: 0.9203 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1799 - accuracy: 0.9250 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1858 - accuracy: 0.9281 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.1906 - accuracy: 0.9236 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1783 - accuracy: 0.9282 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.1807 - accuracy: 0.9310 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9272 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1666 - accuracy: 0.9302 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.1815 - accuracy: 0.9268 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.1719 - accuracy: 0.9321 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.1668 - accuracy: 0.9338 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1750 - accuracy: 0.9303 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.1729 - accuracy: 0.9341 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - 1s 6ms/step - loss: 0.1632 - accuracy: 0.9363 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Fold 4, Best Validation Loss: 0.00625260453671217, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "320/320 [==============================] - 3s 6ms/step - loss: 0.4457 - accuracy: 0.7926 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.2532 - accuracy: 0.9036 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.2505 - accuracy: 0.8974 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.2146 - accuracy: 0.9146 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1957 - accuracy: 0.9257 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1985 - accuracy: 0.9238 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 0.1887 - accuracy: 0.9299 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1834 - accuracy: 0.9277 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1818 - accuracy: 0.9278 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1794 - accuracy: 0.9313 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1661 - accuracy: 0.9362 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1651 - accuracy: 0.9364 - val_loss: 7.7179e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1635 - accuracy: 0.9366 - val_loss: 8.0339e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1618 - accuracy: 0.9334 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1695 - accuracy: 0.9315 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1671 - accuracy: 0.9327 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1707 - accuracy: 0.9304 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1599 - accuracy: 0.9367 - val_loss: 6.9153e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1552 - accuracy: 0.9390 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1461 - accuracy: 0.9420 - val_loss: 9.2012e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1518 - accuracy: 0.9374 - val_loss: 6.6652e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1437 - accuracy: 0.9419 - val_loss: 6.3249e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1457 - accuracy: 0.9400 - val_loss: 9.6371e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1481 - accuracy: 0.9404 - val_loss: 1.7445e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1392 - accuracy: 0.9445 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1326 - accuracy: 0.9463 - val_loss: 3.4513e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1332 - accuracy: 0.9448 - val_loss: 1.8837e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1366 - accuracy: 0.9442 - val_loss: 5.9202e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1348 - accuracy: 0.9431 - val_loss: 8.3623e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 0.1407 - accuracy: 0.9449 - val_loss: 3.6120e-04 - val_accuracy: 1.0000\n",
      "Fold 5, Best Validation Loss: 8.362280641449615e-05, Best Validation Accuracy: 1.0\n",
      "Mean Best Validation Loss: 2.0426471740574925\n",
      "Mean Best Validation Accuracy: 0.8\n",
      "Epoch 1/30\n",
      "206/206 [==============================] - 3s 7ms/step - loss: 0.2369 - accuracy: 0.9199 - val_loss: 0.4180 - val_accuracy: 0.8869\n",
      "Epoch 2/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1677 - accuracy: 0.9472 - val_loss: 0.5897 - val_accuracy: 0.8566\n",
      "Epoch 3/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1506 - accuracy: 0.9554 - val_loss: 0.5751 - val_accuracy: 0.8548\n",
      "Epoch 4/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1185 - accuracy: 0.9647 - val_loss: 0.6675 - val_accuracy: 0.8502\n",
      "Epoch 5/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1103 - accuracy: 0.9689 - val_loss: 0.5502 - val_accuracy: 0.8472\n",
      "Epoch 6/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1133 - accuracy: 0.9696 - val_loss: 0.5063 - val_accuracy: 0.8553\n",
      "Epoch 7/30\n",
      "206/206 [==============================] - 2s 8ms/step - loss: 0.1104 - accuracy: 0.9679 - val_loss: 0.3789 - val_accuracy: 0.8412\n",
      "Epoch 8/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1001 - accuracy: 0.9708 - val_loss: 0.3664 - val_accuracy: 0.8530\n",
      "Epoch 9/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1025 - accuracy: 0.9697 - val_loss: 0.3638 - val_accuracy: 0.8426\n",
      "Epoch 10/30\n",
      "206/206 [==============================] - 2s 8ms/step - loss: 0.1063 - accuracy: 0.9651 - val_loss: 0.3275 - val_accuracy: 0.8487\n",
      "Epoch 11/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1044 - accuracy: 0.9686 - val_loss: 0.3821 - val_accuracy: 0.8339\n",
      "Epoch 12/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1014 - accuracy: 0.9696 - val_loss: 0.3637 - val_accuracy: 0.8412\n",
      "Epoch 13/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1017 - accuracy: 0.9702 - val_loss: 0.4701 - val_accuracy: 0.8382\n",
      "Epoch 14/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0961 - accuracy: 0.9696 - val_loss: 0.4758 - val_accuracy: 0.8387\n",
      "Epoch 15/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0936 - accuracy: 0.9715 - val_loss: 0.3637 - val_accuracy: 0.8425\n",
      "Epoch 16/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0950 - accuracy: 0.9712 - val_loss: 0.4145 - val_accuracy: 0.8286\n",
      "Epoch 17/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0978 - accuracy: 0.9686 - val_loss: 0.3756 - val_accuracy: 0.8405\n",
      "Epoch 18/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0906 - accuracy: 0.9718 - val_loss: 0.3423 - val_accuracy: 0.8440\n",
      "Epoch 19/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0921 - accuracy: 0.9725 - val_loss: 0.4133 - val_accuracy: 0.8387\n",
      "Epoch 20/30\n",
      "206/206 [==============================] - 2s 7ms/step - loss: 0.1005 - accuracy: 0.9674 - val_loss: 0.3175 - val_accuracy: 0.8591\n",
      "Epoch 21/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0934 - accuracy: 0.9703 - val_loss: 0.4027 - val_accuracy: 0.8385\n",
      "Epoch 22/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0853 - accuracy: 0.9731 - val_loss: 0.4306 - val_accuracy: 0.8376\n",
      "Epoch 23/30\n",
      "206/206 [==============================] - 2s 7ms/step - loss: 0.0948 - accuracy: 0.9697 - val_loss: 0.3932 - val_accuracy: 0.8405\n",
      "Epoch 24/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0865 - accuracy: 0.9721 - val_loss: 0.3908 - val_accuracy: 0.8347\n",
      "Epoch 25/30\n",
      "206/206 [==============================] - 2s 8ms/step - loss: 0.0891 - accuracy: 0.9711 - val_loss: 0.4037 - val_accuracy: 0.8329\n",
      "Epoch 26/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.1005 - accuracy: 0.9671 - val_loss: 0.3583 - val_accuracy: 0.8180\n",
      "Epoch 27/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0987 - accuracy: 0.9670 - val_loss: 0.4507 - val_accuracy: 0.8306\n",
      "Epoch 28/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0887 - accuracy: 0.9711 - val_loss: 0.4280 - val_accuracy: 0.8311\n",
      "Epoch 29/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0884 - accuracy: 0.9721 - val_loss: 0.4757 - val_accuracy: 0.8315\n",
      "Epoch 30/30\n",
      "206/206 [==============================] - 1s 7ms/step - loss: 0.0880 - accuracy: 0.9726 - val_loss: 0.5281 - val_accuracy: 0.8239\n",
      "Fold 1, Best Validation Loss: 0.31753382086753845, Best Validation Accuracy: 0.8869102001190186\n",
      "Epoch 1/30\n",
      "411/411 [==============================] - 4s 7ms/step - loss: 0.1900 - accuracy: 0.9349 - val_loss: 0.0239 - val_accuracy: 0.9910\n",
      "Epoch 2/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.1275 - accuracy: 0.9592 - val_loss: 0.1132 - val_accuracy: 0.9630\n",
      "Epoch 3/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.1165 - accuracy: 0.9664 - val_loss: 0.1013 - val_accuracy: 0.9664\n",
      "Epoch 4/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.1145 - accuracy: 0.9674 - val_loss: 0.0214 - val_accuracy: 0.9922\n",
      "Epoch 5/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.1075 - accuracy: 0.9696 - val_loss: 0.0787 - val_accuracy: 0.9770\n",
      "Epoch 6/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0992 - accuracy: 0.9714 - val_loss: 0.0764 - val_accuracy: 0.9746\n",
      "Epoch 7/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0992 - accuracy: 0.9704 - val_loss: 0.1189 - val_accuracy: 0.9665\n",
      "Epoch 8/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0960 - accuracy: 0.9699 - val_loss: 0.0357 - val_accuracy: 0.9889\n",
      "Epoch 9/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0934 - accuracy: 0.9720 - val_loss: 0.0327 - val_accuracy: 0.9868\n",
      "Epoch 10/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0926 - accuracy: 0.9707 - val_loss: 0.0217 - val_accuracy: 0.9941\n",
      "Epoch 11/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0909 - accuracy: 0.9733 - val_loss: 0.0204 - val_accuracy: 0.9910\n",
      "Epoch 12/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0864 - accuracy: 0.9740 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
      "Epoch 13/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0804 - accuracy: 0.9745 - val_loss: 0.0380 - val_accuracy: 0.9840\n",
      "Epoch 14/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0827 - accuracy: 0.9727 - val_loss: 0.0554 - val_accuracy: 0.9823\n",
      "Epoch 15/30\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.0819 - accuracy: 0.9737 - val_loss: 0.0546 - val_accuracy: 0.9819\n",
      "Epoch 16/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0813 - accuracy: 0.9745 - val_loss: 0.0598 - val_accuracy: 0.9784\n",
      "Epoch 17/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0790 - accuracy: 0.9747 - val_loss: 0.0608 - val_accuracy: 0.9784\n",
      "Epoch 18/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0768 - accuracy: 0.9752 - val_loss: 0.0898 - val_accuracy: 0.9714\n",
      "Epoch 19/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0752 - accuracy: 0.9753 - val_loss: 0.0321 - val_accuracy: 0.9860\n",
      "Epoch 20/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0783 - accuracy: 0.9740 - val_loss: 0.0202 - val_accuracy: 0.9903\n",
      "Epoch 21/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0764 - accuracy: 0.9748 - val_loss: 0.0267 - val_accuracy: 0.9874\n",
      "Epoch 22/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0725 - accuracy: 0.9777 - val_loss: 0.0304 - val_accuracy: 0.9887\n",
      "Epoch 23/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0726 - accuracy: 0.9741 - val_loss: 0.0301 - val_accuracy: 0.9883\n",
      "Epoch 24/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0728 - accuracy: 0.9761 - val_loss: 0.0592 - val_accuracy: 0.9769\n",
      "Epoch 25/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0775 - accuracy: 0.9734 - val_loss: 0.0381 - val_accuracy: 0.9828\n",
      "Epoch 26/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0744 - accuracy: 0.9756 - val_loss: 0.0153 - val_accuracy: 0.9936\n",
      "Epoch 27/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0721 - accuracy: 0.9752 - val_loss: 0.0253 - val_accuracy: 0.9886\n",
      "Epoch 28/30\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.0701 - accuracy: 0.9768 - val_loss: 0.0608 - val_accuracy: 0.9773\n",
      "Epoch 29/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0693 - accuracy: 0.9775 - val_loss: 0.0346 - val_accuracy: 0.9833\n",
      "Epoch 30/30\n",
      "411/411 [==============================] - 3s 6ms/step - loss: 0.0685 - accuracy: 0.9770 - val_loss: 0.0249 - val_accuracy: 0.9874\n",
      "Fold 2, Best Validation Loss: 0.0152574572712183, Best Validation Accuracy: 0.9940639138221741\n",
      "Epoch 1/30\n",
      "616/616 [==============================] - 8s 6ms/step - loss: 0.1302 - accuracy: 0.9610 - val_loss: 0.3605 - val_accuracy: 0.9126\n",
      "Epoch 2/30\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.0964 - accuracy: 0.9705 - val_loss: 0.3374 - val_accuracy: 0.9146\n",
      "Epoch 3/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0851 - accuracy: 0.9719 - val_loss: 0.3082 - val_accuracy: 0.9301\n",
      "Epoch 4/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0820 - accuracy: 0.9743 - val_loss: 0.3263 - val_accuracy: 0.9301\n",
      "Epoch 5/30\n",
      "616/616 [==============================] - 5s 8ms/step - loss: 0.0808 - accuracy: 0.9752 - val_loss: 0.3006 - val_accuracy: 0.9312\n",
      "Epoch 6/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0759 - accuracy: 0.9783 - val_loss: 0.2736 - val_accuracy: 0.9377\n",
      "Epoch 7/30\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 0.2924 - val_accuracy: 0.9368\n",
      "Epoch 8/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0685 - accuracy: 0.9797 - val_loss: 0.2529 - val_accuracy: 0.9416\n",
      "Epoch 9/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.2962 - val_accuracy: 0.9399\n",
      "Epoch 10/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0643 - accuracy: 0.9791 - val_loss: 0.3324 - val_accuracy: 0.9388\n",
      "Epoch 11/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0635 - accuracy: 0.9803 - val_loss: 0.3556 - val_accuracy: 0.9250\n",
      "Epoch 12/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.3316 - val_accuracy: 0.9397\n",
      "Epoch 13/30\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.0580 - accuracy: 0.9820 - val_loss: 0.3076 - val_accuracy: 0.9387\n",
      "Epoch 14/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0573 - accuracy: 0.9820 - val_loss: 0.3593 - val_accuracy: 0.9349\n",
      "Epoch 15/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0597 - accuracy: 0.9801 - val_loss: 0.5267 - val_accuracy: 0.9311\n",
      "Epoch 16/30\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.0570 - accuracy: 0.9812 - val_loss: 0.5181 - val_accuracy: 0.9043\n",
      "Epoch 17/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0542 - accuracy: 0.9830 - val_loss: 0.6837 - val_accuracy: 0.8752\n",
      "Epoch 18/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 0.6193 - val_accuracy: 0.8149\n",
      "Epoch 19/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0552 - accuracy: 0.9812 - val_loss: 0.7982 - val_accuracy: 0.8414\n",
      "Epoch 20/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0528 - accuracy: 0.9822 - val_loss: 1.0405 - val_accuracy: 0.6855\n",
      "Epoch 21/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0518 - accuracy: 0.9824 - val_loss: 0.9893 - val_accuracy: 0.5729\n",
      "Epoch 22/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 1.2696 - val_accuracy: 0.5728\n",
      "Epoch 23/30\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.0510 - accuracy: 0.9831 - val_loss: 1.2848 - val_accuracy: 0.5630\n",
      "Epoch 24/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 1.2702 - val_accuracy: 0.5728\n",
      "Epoch 25/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0517 - accuracy: 0.9822 - val_loss: 1.1169 - val_accuracy: 0.5728\n",
      "Epoch 26/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0509 - accuracy: 0.9831 - val_loss: 1.4931 - val_accuracy: 0.5679\n",
      "Epoch 27/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0505 - accuracy: 0.9831 - val_loss: 2.0627 - val_accuracy: 0.5024\n",
      "Epoch 28/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 1.5463 - val_accuracy: 0.5024\n",
      "Epoch 29/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0493 - accuracy: 0.9837 - val_loss: 2.4068 - val_accuracy: 0.5041\n",
      "Epoch 30/30\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0488 - accuracy: 0.9842 - val_loss: 2.5231 - val_accuracy: 0.5024\n",
      "Fold 3, Best Validation Loss: 0.25290584564208984, Best Validation Accuracy: 0.9415525197982788\n",
      "Epoch 1/30\n",
      "822/822 [==============================] - 7s 6ms/step - loss: 0.1606 - accuracy: 0.9525 - val_loss: 0.1250 - val_accuracy: 0.9636\n",
      "Epoch 2/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.1309 - accuracy: 0.9591 - val_loss: 0.0771 - val_accuracy: 0.9802\n",
      "Epoch 3/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.1089 - accuracy: 0.9624 - val_loss: 0.0670 - val_accuracy: 0.9737\n",
      "Epoch 4/30\n",
      "822/822 [==============================] - 5s 7ms/step - loss: 0.0983 - accuracy: 0.9650 - val_loss: 0.0614 - val_accuracy: 0.9711\n",
      "Epoch 5/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0985 - accuracy: 0.9647 - val_loss: 0.0818 - val_accuracy: 0.9609\n",
      "Epoch 6/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0968 - accuracy: 0.9666 - val_loss: 0.0699 - val_accuracy: 0.9715\n",
      "Epoch 7/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0936 - accuracy: 0.9668 - val_loss: 0.0730 - val_accuracy: 0.9760\n",
      "Epoch 8/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0902 - accuracy: 0.9687 - val_loss: 0.0572 - val_accuracy: 0.9805\n",
      "Epoch 9/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0906 - accuracy: 0.9690 - val_loss: 0.0546 - val_accuracy: 0.9775\n",
      "Epoch 10/30\n",
      "822/822 [==============================] - 5s 7ms/step - loss: 0.0900 - accuracy: 0.9683 - val_loss: 0.0597 - val_accuracy: 0.9741\n",
      "Epoch 11/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0878 - accuracy: 0.9712 - val_loss: 0.0864 - val_accuracy: 0.9648\n",
      "Epoch 12/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0861 - accuracy: 0.9705 - val_loss: 0.0826 - val_accuracy: 0.9691\n",
      "Epoch 13/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0828 - accuracy: 0.9710 - val_loss: 0.0800 - val_accuracy: 0.9668\n",
      "Epoch 14/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0830 - accuracy: 0.9723 - val_loss: 0.0827 - val_accuracy: 0.9680\n",
      "Epoch 15/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0831 - accuracy: 0.9719 - val_loss: 0.0763 - val_accuracy: 0.9685\n",
      "Epoch 16/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0826 - accuracy: 0.9718 - val_loss: 0.0484 - val_accuracy: 0.9836\n",
      "Epoch 17/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0791 - accuracy: 0.9715 - val_loss: 0.1087 - val_accuracy: 0.9359\n",
      "Epoch 18/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0826 - accuracy: 0.9716 - val_loss: 0.0499 - val_accuracy: 0.9823\n",
      "Epoch 19/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0812 - accuracy: 0.9722 - val_loss: 0.0738 - val_accuracy: 0.9708\n",
      "Epoch 20/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0795 - accuracy: 0.9726 - val_loss: 0.0636 - val_accuracy: 0.9756\n",
      "Epoch 21/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0801 - accuracy: 0.9726 - val_loss: 0.0603 - val_accuracy: 0.9802\n",
      "Epoch 22/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0809 - accuracy: 0.9719 - val_loss: 0.0721 - val_accuracy: 0.9700\n",
      "Epoch 23/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0804 - accuracy: 0.9728 - val_loss: 0.0810 - val_accuracy: 0.9682\n",
      "Epoch 24/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0786 - accuracy: 0.9726 - val_loss: 0.1380 - val_accuracy: 0.9298\n",
      "Epoch 25/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0776 - accuracy: 0.9739 - val_loss: 0.3058 - val_accuracy: 0.8936\n",
      "Epoch 26/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 0.1100 - val_accuracy: 0.9539\n",
      "Epoch 27/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0796 - accuracy: 0.9737 - val_loss: 0.1408 - val_accuracy: 0.9237\n",
      "Epoch 28/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0778 - accuracy: 0.9735 - val_loss: 0.1442 - val_accuracy: 0.9225\n",
      "Epoch 29/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0793 - accuracy: 0.9728 - val_loss: 0.1690 - val_accuracy: 0.9218\n",
      "Epoch 30/30\n",
      "822/822 [==============================] - 5s 6ms/step - loss: 0.0773 - accuracy: 0.9744 - val_loss: 0.1870 - val_accuracy: 0.9212\n",
      "Fold 4, Best Validation Loss: 0.04844658076763153, Best Validation Accuracy: 0.983561635017395\n",
      "Epoch 1/30\n",
      "1027/1027 [==============================] - 8s 6ms/step - loss: 0.1566 - accuracy: 0.9528 - val_loss: 0.4776 - val_accuracy: 0.8758\n",
      "Epoch 2/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.1229 - accuracy: 0.9654 - val_loss: 0.4142 - val_accuracy: 0.8866\n",
      "Epoch 3/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.1078 - accuracy: 0.9663 - val_loss: 0.4196 - val_accuracy: 0.8735\n",
      "Epoch 4/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0989 - accuracy: 0.9669 - val_loss: 0.3915 - val_accuracy: 0.8965\n",
      "Epoch 5/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0933 - accuracy: 0.9682 - val_loss: 0.3937 - val_accuracy: 0.8872\n",
      "Epoch 6/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0894 - accuracy: 0.9695 - val_loss: 0.4295 - val_accuracy: 0.9015\n",
      "Epoch 7/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0876 - accuracy: 0.9702 - val_loss: 0.4162 - val_accuracy: 0.9044\n",
      "Epoch 8/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0853 - accuracy: 0.9718 - val_loss: 0.4264 - val_accuracy: 0.9035\n",
      "Epoch 9/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0812 - accuracy: 0.9729 - val_loss: 0.3592 - val_accuracy: 0.9020\n",
      "Epoch 10/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0804 - accuracy: 0.9729 - val_loss: 0.3640 - val_accuracy: 0.9122\n",
      "Epoch 11/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0790 - accuracy: 0.9739 - val_loss: 0.3421 - val_accuracy: 0.9021\n",
      "Epoch 12/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0777 - accuracy: 0.9748 - val_loss: 0.3965 - val_accuracy: 0.9020\n",
      "Epoch 13/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0755 - accuracy: 0.9754 - val_loss: 0.3626 - val_accuracy: 0.9073\n",
      "Epoch 14/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0776 - accuracy: 0.9751 - val_loss: 0.3399 - val_accuracy: 0.9170\n",
      "Epoch 15/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0732 - accuracy: 0.9759 - val_loss: 0.4040 - val_accuracy: 0.8918\n",
      "Epoch 16/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0763 - accuracy: 0.9754 - val_loss: 0.3541 - val_accuracy: 0.9151\n",
      "Epoch 17/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0739 - accuracy: 0.9762 - val_loss: 0.3635 - val_accuracy: 0.8936\n",
      "Epoch 18/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0774 - accuracy: 0.9748 - val_loss: 0.3979 - val_accuracy: 0.9067\n",
      "Epoch 19/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0736 - accuracy: 0.9759 - val_loss: 0.3531 - val_accuracy: 0.8974\n",
      "Epoch 20/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0703 - accuracy: 0.9770 - val_loss: 0.4155 - val_accuracy: 0.9078\n",
      "Epoch 21/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0714 - accuracy: 0.9770 - val_loss: 0.3881 - val_accuracy: 0.8866\n",
      "Epoch 22/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0698 - accuracy: 0.9771 - val_loss: 0.3706 - val_accuracy: 0.8980\n",
      "Epoch 23/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0703 - accuracy: 0.9768 - val_loss: 0.3972 - val_accuracy: 0.9114\n",
      "Epoch 24/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0716 - accuracy: 0.9771 - val_loss: 0.3836 - val_accuracy: 0.9068\n",
      "Epoch 25/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0694 - accuracy: 0.9772 - val_loss: 0.3634 - val_accuracy: 0.9002\n",
      "Epoch 26/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0695 - accuracy: 0.9782 - val_loss: 0.3846 - val_accuracy: 0.8932\n",
      "Epoch 27/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0689 - accuracy: 0.9784 - val_loss: 0.3928 - val_accuracy: 0.8944\n",
      "Epoch 28/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0684 - accuracy: 0.9787 - val_loss: 0.4007 - val_accuracy: 0.9157\n",
      "Epoch 29/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0679 - accuracy: 0.9783 - val_loss: 0.3540 - val_accuracy: 0.9027\n",
      "Epoch 30/30\n",
      "1027/1027 [==============================] - 6s 6ms/step - loss: 0.0673 - accuracy: 0.9785 - val_loss: 0.3678 - val_accuracy: 0.9058\n",
      "Fold 5, Best Validation Loss: 0.3398980498313904, Best Validation Accuracy: 0.9170472025871277\n",
      "Mean Best Validation Loss: 0.1948083508759737\n",
      "Mean Best Validation Accuracy: 0.9446270942687989\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7608 - accuracy: 0.5000 - val_loss: 0.4545 - val_accuracy: 0.8667\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.5843 - val_accuracy: 0.8667\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8667\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.8667\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8717 - val_accuracy: 0.8667\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.8667\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0033 - val_accuracy: 0.8667\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0563 - val_accuracy: 0.8667\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.1048 - val_accuracy: 0.8667\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.6336e-04 - accuracy: 1.0000 - val_loss: 1.1477 - val_accuracy: 0.8667\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.8667\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6055e-04 - accuracy: 1.0000 - val_loss: 1.2219 - val_accuracy: 0.8667\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2469e-04 - accuracy: 1.0000 - val_loss: 1.2535 - val_accuracy: 0.8667\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.0995e-04 - accuracy: 1.0000 - val_loss: 1.2816 - val_accuracy: 0.8667\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.3922e-04 - accuracy: 1.0000 - val_loss: 1.3070 - val_accuracy: 0.8667\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6794e-04 - accuracy: 1.0000 - val_loss: 1.3298 - val_accuracy: 0.8667\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4407e-04 - accuracy: 1.0000 - val_loss: 1.3502 - val_accuracy: 0.8667\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.6958e-04 - accuracy: 1.0000 - val_loss: 1.3683 - val_accuracy: 0.8667\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2430e-04 - accuracy: 1.0000 - val_loss: 1.3845 - val_accuracy: 0.8667\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3849e-04 - accuracy: 1.0000 - val_loss: 1.3988 - val_accuracy: 0.8667\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1401e-04 - accuracy: 1.0000 - val_loss: 1.4115 - val_accuracy: 0.8667\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4033e-04 - accuracy: 1.0000 - val_loss: 1.4228 - val_accuracy: 0.8667\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7480e-04 - accuracy: 1.0000 - val_loss: 1.4330 - val_accuracy: 0.8667\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5401e-05 - accuracy: 1.0000 - val_loss: 1.4420 - val_accuracy: 0.8667\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.5564e-05 - accuracy: 1.0000 - val_loss: 1.4499 - val_accuracy: 0.8667\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.4734e-05 - accuracy: 1.0000 - val_loss: 1.4570 - val_accuracy: 0.8667\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.2951e-05 - accuracy: 1.0000 - val_loss: 1.4632 - val_accuracy: 0.8667\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.7666e-05 - accuracy: 1.0000 - val_loss: 1.4687 - val_accuracy: 0.8667\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2418e-05 - accuracy: 1.0000 - val_loss: 1.4736 - val_accuracy: 0.8667\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.2684e-05 - accuracy: 1.0000 - val_loss: 1.4777 - val_accuracy: 0.8667\n",
      "Fold 1, Best Validation Loss: 0.45447805523872375, Best Validation Accuracy: 0.8666666746139526\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 2s 290ms/step - loss: 0.6009 - accuracy: 0.7333 - val_loss: 0.1062 - val_accuracy: 0.9667\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2199 - accuracy: 0.9167 - val_loss: 0.0628 - val_accuracy: 0.9667\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1798 - accuracy: 0.9500 - val_loss: 0.0590 - val_accuracy: 0.9667\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2239 - accuracy: 0.9333 - val_loss: 0.0467 - val_accuracy: 0.9667\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2339 - accuracy: 0.9500 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1728 - accuracy: 0.9500 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1867 - accuracy: 0.9667 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1614 - accuracy: 0.9500 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1610 - accuracy: 0.9500 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1504 - accuracy: 0.9667 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1931 - accuracy: 0.9667 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0992 - accuracy: 0.9500 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0852 - accuracy: 0.9667 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1054 - accuracy: 0.9667 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1897 - accuracy: 0.9667 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1573 - accuracy: 0.9500 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1867 - accuracy: 0.9667 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1247 - accuracy: 0.9667 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1787 - accuracy: 0.9167 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1245 - accuracy: 0.9667 - val_loss: 0.0365 - val_accuracy: 0.9667\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1039 - accuracy: 0.9667 - val_loss: 0.0637 - val_accuracy: 0.9667\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1621 - accuracy: 0.9500 - val_loss: 0.0720 - val_accuracy: 0.9667\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0875 - accuracy: 0.9667 - val_loss: 0.0617 - val_accuracy: 0.9667\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0806 - accuracy: 0.9667 - val_loss: 0.0511 - val_accuracy: 0.9667\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1199 - accuracy: 0.9500 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1012 - accuracy: 0.9667 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0884 - accuracy: 0.9667 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0582 - accuracy: 0.9667 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1598 - accuracy: 0.9667 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1233 - accuracy: 0.9333 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Fold 2, Best Validation Loss: 0.007185763213783503, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 2s 144ms/step - loss: 0.6840 - accuracy: 0.6556 - val_loss: 0.5795 - val_accuracy: 0.8333\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1386 - accuracy: 0.9556 - val_loss: 0.8207 - val_accuracy: 0.8667\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1873 - accuracy: 0.9778 - val_loss: 0.9284 - val_accuracy: 0.8667\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2132 - accuracy: 0.9778 - val_loss: 0.8546 - val_accuracy: 0.8667\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1816 - accuracy: 0.9778 - val_loss: 0.7664 - val_accuracy: 0.8667\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1117 - accuracy: 0.9778 - val_loss: 0.6935 - val_accuracy: 0.8667\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1542 - accuracy: 0.9556 - val_loss: 0.5905 - val_accuracy: 0.8667\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0985 - accuracy: 0.9778 - val_loss: 0.5378 - val_accuracy: 0.8667\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1020 - accuracy: 0.9778 - val_loss: 0.5067 - val_accuracy: 0.8667\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0944 - accuracy: 0.9778 - val_loss: 0.4821 - val_accuracy: 0.8667\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1187 - accuracy: 0.9778 - val_loss: 0.4573 - val_accuracy: 0.8667\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1199 - accuracy: 0.9667 - val_loss: 0.4542 - val_accuracy: 0.8667\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0895 - accuracy: 0.9778 - val_loss: 0.4842 - val_accuracy: 0.8667\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0542 - accuracy: 0.9778 - val_loss: 0.5254 - val_accuracy: 0.8667\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0775 - accuracy: 0.9778 - val_loss: 0.5457 - val_accuracy: 0.9000\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1309 - accuracy: 0.9778 - val_loss: 0.4531 - val_accuracy: 0.9000\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1044 - accuracy: 0.9556 - val_loss: 0.3716 - val_accuracy: 0.9000\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0811 - accuracy: 0.9667 - val_loss: 0.4686 - val_accuracy: 0.9000\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0606 - accuracy: 0.9778 - val_loss: 0.6032 - val_accuracy: 0.9000\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0843 - accuracy: 0.9778 - val_loss: 0.5744 - val_accuracy: 0.9000\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0988 - accuracy: 0.9667 - val_loss: 0.6399 - val_accuracy: 0.9000\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0627 - accuracy: 0.9778 - val_loss: 0.6419 - val_accuracy: 0.9000\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0982 - accuracy: 0.9889 - val_loss: 0.5453 - val_accuracy: 0.9000\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0730 - accuracy: 0.9778 - val_loss: 0.4837 - val_accuracy: 0.9000\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0873 - accuracy: 0.9778 - val_loss: 0.3850 - val_accuracy: 0.9000\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0530 - accuracy: 0.9889 - val_loss: 0.3631 - val_accuracy: 0.9000\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1049 - accuracy: 0.9556 - val_loss: 0.4804 - val_accuracy: 0.9000\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1092 - accuracy: 0.9778 - val_loss: 0.6440 - val_accuracy: 0.8667\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0958 - accuracy: 0.9778 - val_loss: 0.7142 - val_accuracy: 0.8667\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0661 - accuracy: 0.9778 - val_loss: 0.7000 - val_accuracy: 0.8667\n",
      "Fold 3, Best Validation Loss: 0.3631117641925812, Best Validation Accuracy: 0.8999999761581421\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 2s 96ms/step - loss: 0.4066 - accuracy: 0.7583 - val_loss: 0.1552 - val_accuracy: 0.9667\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2364 - accuracy: 0.9250 - val_loss: 0.1487 - val_accuracy: 0.9667\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2517 - accuracy: 0.9333 - val_loss: 0.1423 - val_accuracy: 0.9667\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2231 - accuracy: 0.9500 - val_loss: 0.1311 - val_accuracy: 0.9667\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2135 - accuracy: 0.9333 - val_loss: 0.1245 - val_accuracy: 0.9667\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1666 - accuracy: 0.9583 - val_loss: 0.1145 - val_accuracy: 0.9667\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1729 - accuracy: 0.9500 - val_loss: 0.1093 - val_accuracy: 0.9667\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1517 - accuracy: 0.9583 - val_loss: 0.1294 - val_accuracy: 0.9667\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1436 - accuracy: 0.9583 - val_loss: 0.1420 - val_accuracy: 0.9333\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1383 - accuracy: 0.9583 - val_loss: 0.1521 - val_accuracy: 0.9000\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1093 - accuracy: 0.9583 - val_loss: 0.1710 - val_accuracy: 0.9000\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1161 - accuracy: 0.9583 - val_loss: 0.1431 - val_accuracy: 0.9333\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1238 - accuracy: 0.9250 - val_loss: 0.1385 - val_accuracy: 0.9333\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0923 - accuracy: 0.9417 - val_loss: 0.1339 - val_accuracy: 0.9667\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0928 - accuracy: 0.9583 - val_loss: 0.0945 - val_accuracy: 0.9667\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0595 - accuracy: 0.9667 - val_loss: 0.1059 - val_accuracy: 0.9667\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1413 - accuracy: 0.9583 - val_loss: 0.0853 - val_accuracy: 0.9667\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1178 - accuracy: 0.9500 - val_loss: 0.1237 - val_accuracy: 0.9000\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0997 - accuracy: 0.9833 - val_loss: 0.0920 - val_accuracy: 0.9667\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0993 - accuracy: 0.9583 - val_loss: 0.0955 - val_accuracy: 0.9667\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1624 - accuracy: 0.9250 - val_loss: 0.0905 - val_accuracy: 0.9667\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0782 - accuracy: 0.9583 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0913 - accuracy: 0.9417 - val_loss: 0.1590 - val_accuracy: 0.9000\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1074 - accuracy: 0.9500 - val_loss: 0.1596 - val_accuracy: 0.9000\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0575 - accuracy: 0.9750 - val_loss: 0.1623 - val_accuracy: 0.9000\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.1651 - val_accuracy: 0.9000\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1399 - accuracy: 0.9750 - val_loss: 0.2544 - val_accuracy: 0.8667\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0976 - accuracy: 0.9833 - val_loss: 0.3120 - val_accuracy: 0.8667\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0693 - accuracy: 0.9750 - val_loss: 0.1931 - val_accuracy: 0.9000\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1184 - accuracy: 0.9667 - val_loss: 0.2013 - val_accuracy: 0.9000\n",
      "Fold 4, Best Validation Loss: 0.08525202423334122, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 2s 76ms/step - loss: 0.4121 - accuracy: 0.8800 - val_loss: 0.6711 - val_accuracy: 0.7667\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2690 - accuracy: 0.9267 - val_loss: 0.5200 - val_accuracy: 0.7667\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1960 - accuracy: 0.9400 - val_loss: 0.4462 - val_accuracy: 0.9000\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2324 - accuracy: 0.9333 - val_loss: 0.4826 - val_accuracy: 0.9000\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1819 - accuracy: 0.9333 - val_loss: 0.4950 - val_accuracy: 0.9000\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1895 - accuracy: 0.9400 - val_loss: 0.4617 - val_accuracy: 0.9000\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1969 - accuracy: 0.9333 - val_loss: 0.4187 - val_accuracy: 0.9000\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1438 - accuracy: 0.9333 - val_loss: 0.6471 - val_accuracy: 0.9000\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1465 - accuracy: 0.9600 - val_loss: 0.5430 - val_accuracy: 0.9000\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1170 - accuracy: 0.9533 - val_loss: 0.3978 - val_accuracy: 0.9000\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1336 - accuracy: 0.9467 - val_loss: 0.4267 - val_accuracy: 0.9000\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1270 - accuracy: 0.9467 - val_loss: 0.7534 - val_accuracy: 0.9000\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1826 - accuracy: 0.9467 - val_loss: 0.7513 - val_accuracy: 0.9000\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1528 - accuracy: 0.9533 - val_loss: 0.5309 - val_accuracy: 0.9000\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1300 - accuracy: 0.9400 - val_loss: 0.5783 - val_accuracy: 0.9000\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1216 - accuracy: 0.9667 - val_loss: 0.6295 - val_accuracy: 0.9000\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1195 - accuracy: 0.9467 - val_loss: 0.7452 - val_accuracy: 0.9000\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1272 - accuracy: 0.9667 - val_loss: 0.7327 - val_accuracy: 0.9000\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0866 - accuracy: 0.9667 - val_loss: 0.6748 - val_accuracy: 0.9000\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0977 - accuracy: 0.9600 - val_loss: 0.6132 - val_accuracy: 0.9000\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1053 - accuracy: 0.9400 - val_loss: 0.5727 - val_accuracy: 0.8667\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0525 - accuracy: 0.9800 - val_loss: 0.6279 - val_accuracy: 0.9000\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1256 - accuracy: 0.9533 - val_loss: 0.7194 - val_accuracy: 0.9000\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0783 - accuracy: 0.9600 - val_loss: 0.7387 - val_accuracy: 0.9000\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.7383 - val_accuracy: 0.8667\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1277 - accuracy: 0.9600 - val_loss: 0.8484 - val_accuracy: 0.8667\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0490 - accuracy: 0.9733 - val_loss: 0.9444 - val_accuracy: 0.9000\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0790 - accuracy: 0.9667 - val_loss: 0.6937 - val_accuracy: 0.8667\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.5864 - val_accuracy: 0.8333\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0509 - accuracy: 0.9667 - val_loss: 0.6897 - val_accuracy: 0.8667\n",
      "Fold 5, Best Validation Loss: 0.3978498578071594, Best Validation Accuracy: 0.8999999761581421\n",
      "Mean Best Validation Loss: 0.2615754929371178\n",
      "Mean Best Validation Accuracy: 0.9333333253860474\n",
      "Epoch 1/30\n",
      "495/495 [==============================] - 5s 6ms/step - loss: 0.1591 - accuracy: 0.9670 - val_loss: 0.1188 - val_accuracy: 0.9763\n",
      "Epoch 2/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1490 - accuracy: 0.9679 - val_loss: 0.1130 - val_accuracy: 0.9763\n",
      "Epoch 3/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1467 - accuracy: 0.9679 - val_loss: 0.1127 - val_accuracy: 0.9763\n",
      "Epoch 4/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1481 - accuracy: 0.9679 - val_loss: 0.1123 - val_accuracy: 0.9763\n",
      "Epoch 5/30\n",
      "495/495 [==============================] - 3s 7ms/step - loss: 0.1461 - accuracy: 0.9679 - val_loss: 0.1134 - val_accuracy: 0.9763\n",
      "Epoch 6/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1460 - accuracy: 0.9679 - val_loss: 0.1183 - val_accuracy: 0.9763\n",
      "Epoch 7/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1460 - accuracy: 0.9679 - val_loss: 0.1122 - val_accuracy: 0.9763\n",
      "Epoch 8/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1461 - accuracy: 0.9679 - val_loss: 0.1134 - val_accuracy: 0.9763\n",
      "Epoch 9/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1450 - accuracy: 0.9679 - val_loss: 0.1139 - val_accuracy: 0.9763\n",
      "Epoch 10/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1443 - accuracy: 0.9679 - val_loss: 0.1167 - val_accuracy: 0.9763\n",
      "Epoch 11/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1462 - accuracy: 0.9679 - val_loss: 0.1132 - val_accuracy: 0.9763\n",
      "Epoch 12/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1440 - accuracy: 0.9679 - val_loss: 0.1130 - val_accuracy: 0.9763\n",
      "Epoch 13/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1442 - accuracy: 0.9679 - val_loss: 0.1154 - val_accuracy: 0.9763\n",
      "Epoch 14/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1449 - accuracy: 0.9679 - val_loss: 0.1130 - val_accuracy: 0.9763\n",
      "Epoch 15/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1452 - accuracy: 0.9679 - val_loss: 0.1125 - val_accuracy: 0.9763\n",
      "Epoch 16/30\n",
      "495/495 [==============================] - 4s 7ms/step - loss: 0.1437 - accuracy: 0.9679 - val_loss: 0.1123 - val_accuracy: 0.9763\n",
      "Epoch 17/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1442 - accuracy: 0.9679 - val_loss: 0.1129 - val_accuracy: 0.9763\n",
      "Epoch 18/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1435 - accuracy: 0.9679 - val_loss: 0.1143 - val_accuracy: 0.9763\n",
      "Epoch 19/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1433 - accuracy: 0.9679 - val_loss: 0.1131 - val_accuracy: 0.9763\n",
      "Epoch 20/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1441 - accuracy: 0.9679 - val_loss: 0.1131 - val_accuracy: 0.9763\n",
      "Epoch 21/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1435 - accuracy: 0.9679 - val_loss: 0.1138 - val_accuracy: 0.9763\n",
      "Epoch 22/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1440 - accuracy: 0.9679 - val_loss: 0.1158 - val_accuracy: 0.9763\n",
      "Epoch 23/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1441 - accuracy: 0.9679 - val_loss: 0.1138 - val_accuracy: 0.9763\n",
      "Epoch 24/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1433 - accuracy: 0.9679 - val_loss: 0.1141 - val_accuracy: 0.9763\n",
      "Epoch 25/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1429 - accuracy: 0.9679 - val_loss: 0.1149 - val_accuracy: 0.9763\n",
      "Epoch 26/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1440 - accuracy: 0.9679 - val_loss: 0.1130 - val_accuracy: 0.9763\n",
      "Epoch 27/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1438 - accuracy: 0.9679 - val_loss: 0.1133 - val_accuracy: 0.9763\n",
      "Epoch 28/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1437 - accuracy: 0.9679 - val_loss: 0.1136 - val_accuracy: 0.9763\n",
      "Epoch 29/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1443 - accuracy: 0.9679 - val_loss: 0.1127 - val_accuracy: 0.9763\n",
      "Epoch 30/30\n",
      "495/495 [==============================] - 3s 6ms/step - loss: 0.1431 - accuracy: 0.9679 - val_loss: 0.1129 - val_accuracy: 0.9763\n",
      "Fold 1, Best Validation Loss: 0.11220529675483704, Best Validation Accuracy: 0.9762823581695557\n",
      "Epoch 1/30\n",
      "989/989 [==============================] - 7s 6ms/step - loss: 0.1429 - accuracy: 0.9694 - val_loss: 0.0654 - val_accuracy: 0.9898\n",
      "Epoch 2/30\n",
      "989/989 [==============================] - 6s 6ms/step - loss: 0.1326 - accuracy: 0.9721 - val_loss: 0.0605 - val_accuracy: 0.9898\n",
      "Epoch 3/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1322 - accuracy: 0.9721 - val_loss: 0.0593 - val_accuracy: 0.9898\n",
      "Epoch 4/30\n",
      "989/989 [==============================] - 5s 6ms/step - loss: 0.1313 - accuracy: 0.9721 - val_loss: 0.0636 - val_accuracy: 0.9898\n",
      "Epoch 5/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1316 - accuracy: 0.9721 - val_loss: 0.0656 - val_accuracy: 0.9898\n",
      "Epoch 6/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1309 - accuracy: 0.9721 - val_loss: 0.0641 - val_accuracy: 0.9898\n",
      "Epoch 7/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1310 - accuracy: 0.9721 - val_loss: 0.0644 - val_accuracy: 0.9898\n",
      "Epoch 8/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1305 - accuracy: 0.9721 - val_loss: 0.0635 - val_accuracy: 0.9898\n",
      "Epoch 9/30\n",
      "989/989 [==============================] - 5s 6ms/step - loss: 0.1294 - accuracy: 0.9721 - val_loss: 0.0660 - val_accuracy: 0.9898\n",
      "Epoch 10/30\n",
      "989/989 [==============================] - 6s 6ms/step - loss: 0.1298 - accuracy: 0.9721 - val_loss: 0.0661 - val_accuracy: 0.9898\n",
      "Epoch 11/30\n",
      "989/989 [==============================] - 5s 6ms/step - loss: 0.1286 - accuracy: 0.9721 - val_loss: 0.0645 - val_accuracy: 0.9898\n",
      "Epoch 12/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1291 - accuracy: 0.9721 - val_loss: 0.0679 - val_accuracy: 0.9898\n",
      "Epoch 13/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1289 - accuracy: 0.9721 - val_loss: 0.0628 - val_accuracy: 0.9898\n",
      "Epoch 14/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1288 - accuracy: 0.9721 - val_loss: 0.0678 - val_accuracy: 0.9898\n",
      "Epoch 15/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1288 - accuracy: 0.9721 - val_loss: 0.0660 - val_accuracy: 0.9898\n",
      "Epoch 16/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1291 - accuracy: 0.9721 - val_loss: 0.0656 - val_accuracy: 0.9898\n",
      "Epoch 17/30\n",
      "989/989 [==============================] - 6s 6ms/step - loss: 0.1283 - accuracy: 0.9721 - val_loss: 0.0633 - val_accuracy: 0.9898\n",
      "Epoch 18/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1288 - accuracy: 0.9721 - val_loss: 0.0664 - val_accuracy: 0.9898\n",
      "Epoch 19/30\n",
      "989/989 [==============================] - 6s 6ms/step - loss: 0.1284 - accuracy: 0.9721 - val_loss: 0.0645 - val_accuracy: 0.9898\n",
      "Epoch 20/30\n",
      "989/989 [==============================] - 6s 6ms/step - loss: 0.1290 - accuracy: 0.9721 - val_loss: 0.0654 - val_accuracy: 0.9898\n",
      "Epoch 21/30\n",
      "989/989 [==============================] - 6s 6ms/step - loss: 0.1290 - accuracy: 0.9721 - val_loss: 0.0642 - val_accuracy: 0.9898\n",
      "Epoch 22/30\n",
      "989/989 [==============================] - 5s 6ms/step - loss: 0.1283 - accuracy: 0.9721 - val_loss: 0.0625 - val_accuracy: 0.9898\n",
      "Epoch 23/30\n",
      "989/989 [==============================] - 6s 6ms/step - loss: 0.1287 - accuracy: 0.9721 - val_loss: 0.0645 - val_accuracy: 0.9898\n",
      "Epoch 24/30\n",
      "989/989 [==============================] - 6s 6ms/step - loss: 0.1282 - accuracy: 0.9721 - val_loss: 0.0633 - val_accuracy: 0.9898\n",
      "Epoch 25/30\n",
      "989/989 [==============================] - 6s 6ms/step - loss: 0.1284 - accuracy: 0.9721 - val_loss: 0.0629 - val_accuracy: 0.9898\n",
      "Epoch 26/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1286 - accuracy: 0.9721 - val_loss: 0.0659 - val_accuracy: 0.9898\n",
      "Epoch 27/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1291 - accuracy: 0.9721 - val_loss: 0.0665 - val_accuracy: 0.9898\n",
      "Epoch 28/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1286 - accuracy: 0.9721 - val_loss: 0.0616 - val_accuracy: 0.9898\n",
      "Epoch 29/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1286 - accuracy: 0.9721 - val_loss: 0.0627 - val_accuracy: 0.9898\n",
      "Epoch 30/30\n",
      "989/989 [==============================] - 5s 5ms/step - loss: 0.1288 - accuracy: 0.9721 - val_loss: 0.0655 - val_accuracy: 0.9898\n",
      "Fold 2, Best Validation Loss: 0.05930931866168976, Best Validation Accuracy: 0.9897539615631104\n",
      "Epoch 1/30\n",
      "1483/1483 [==============================] - 9s 5ms/step - loss: 0.1150 - accuracy: 0.9773 - val_loss: 0.0990 - val_accuracy: 0.9798\n",
      "Epoch 2/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1101 - accuracy: 0.9780 - val_loss: 0.0993 - val_accuracy: 0.9798\n",
      "Epoch 3/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1106 - accuracy: 0.9780 - val_loss: 0.0990 - val_accuracy: 0.9798\n",
      "Epoch 4/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1089 - accuracy: 0.9780 - val_loss: 0.0993 - val_accuracy: 0.9798\n",
      "Epoch 5/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1084 - accuracy: 0.9780 - val_loss: 0.1004 - val_accuracy: 0.9798\n",
      "Epoch 6/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1082 - accuracy: 0.9780 - val_loss: 0.0990 - val_accuracy: 0.9798\n",
      "Epoch 7/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1082 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 8/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1074 - accuracy: 0.9780 - val_loss: 0.0992 - val_accuracy: 0.9798\n",
      "Epoch 9/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1067 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 10/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1070 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 11/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1071 - accuracy: 0.9780 - val_loss: 0.0994 - val_accuracy: 0.9798\n",
      "Epoch 12/30\n",
      "1483/1483 [==============================] - 8s 6ms/step - loss: 0.1074 - accuracy: 0.9780 - val_loss: 0.0990 - val_accuracy: 0.9798\n",
      "Epoch 13/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1070 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 14/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1069 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 15/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1070 - accuracy: 0.9780 - val_loss: 0.0994 - val_accuracy: 0.9798\n",
      "Epoch 16/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1070 - accuracy: 0.9780 - val_loss: 0.0994 - val_accuracy: 0.9798\n",
      "Epoch 17/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1071 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 18/30\n",
      "1483/1483 [==============================] - 9s 6ms/step - loss: 0.1067 - accuracy: 0.9780 - val_loss: 0.0992 - val_accuracy: 0.9798\n",
      "Epoch 19/30\n",
      "1483/1483 [==============================] - 10s 7ms/step - loss: 0.1068 - accuracy: 0.9780 - val_loss: 0.0990 - val_accuracy: 0.9798\n",
      "Epoch 20/30\n",
      "1483/1483 [==============================] - 9s 6ms/step - loss: 0.1068 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 21/30\n",
      "1483/1483 [==============================] - 9s 6ms/step - loss: 0.1067 - accuracy: 0.9780 - val_loss: 0.0994 - val_accuracy: 0.9798\n",
      "Epoch 22/30\n",
      "1483/1483 [==============================] - 9s 6ms/step - loss: 0.1067 - accuracy: 0.9780 - val_loss: 0.0990 - val_accuracy: 0.9798\n",
      "Epoch 23/30\n",
      "1483/1483 [==============================] - 10s 7ms/step - loss: 0.1069 - accuracy: 0.9780 - val_loss: 0.1000 - val_accuracy: 0.9798\n",
      "Epoch 24/30\n",
      "1483/1483 [==============================] - 9s 6ms/step - loss: 0.1066 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 25/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1070 - accuracy: 0.9780 - val_loss: 0.0994 - val_accuracy: 0.9798\n",
      "Epoch 26/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1063 - accuracy: 0.9780 - val_loss: 0.0992 - val_accuracy: 0.9798\n",
      "Epoch 27/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1068 - accuracy: 0.9780 - val_loss: 0.0990 - val_accuracy: 0.9798\n",
      "Epoch 28/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1068 - accuracy: 0.9780 - val_loss: 0.0990 - val_accuracy: 0.9798\n",
      "Epoch 29/30\n",
      "1483/1483 [==============================] - 8s 5ms/step - loss: 0.1068 - accuracy: 0.9780 - val_loss: 0.0992 - val_accuracy: 0.9798\n",
      "Epoch 30/30\n",
      "1483/1483 [==============================] - 8s 6ms/step - loss: 0.1063 - accuracy: 0.9780 - val_loss: 0.0994 - val_accuracy: 0.9798\n",
      "Fold 3, Best Validation Loss: 0.09896817803382874, Best Validation Accuracy: 0.9797609448432922\n",
      "Epoch 1/30\n",
      "1977/1977 [==============================] - 14s 6ms/step - loss: 0.1124 - accuracy: 0.9781 - val_loss: 0.0624 - val_accuracy: 0.9936\n",
      "Epoch 2/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1087 - accuracy: 0.9784 - val_loss: 0.0455 - val_accuracy: 0.9936\n",
      "Epoch 3/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1076 - accuracy: 0.9784 - val_loss: 0.0493 - val_accuracy: 0.9936\n",
      "Epoch 4/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1067 - accuracy: 0.9784 - val_loss: 0.0427 - val_accuracy: 0.9936\n",
      "Epoch 5/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1064 - accuracy: 0.9784 - val_loss: 0.0467 - val_accuracy: 0.9936\n",
      "Epoch 6/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1059 - accuracy: 0.9784 - val_loss: 0.0451 - val_accuracy: 0.9936\n",
      "Epoch 7/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1056 - accuracy: 0.9784 - val_loss: 0.0458 - val_accuracy: 0.9936\n",
      "Epoch 8/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1054 - accuracy: 0.9784 - val_loss: 0.0454 - val_accuracy: 0.9936\n",
      "Epoch 9/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1053 - accuracy: 0.9784 - val_loss: 0.0449 - val_accuracy: 0.9936\n",
      "Epoch 10/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1054 - accuracy: 0.9784 - val_loss: 0.0472 - val_accuracy: 0.9936\n",
      "Epoch 11/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1051 - accuracy: 0.9784 - val_loss: 0.0479 - val_accuracy: 0.9936\n",
      "Epoch 12/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1048 - accuracy: 0.9784 - val_loss: 0.0427 - val_accuracy: 0.9936\n",
      "Epoch 13/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1051 - accuracy: 0.9784 - val_loss: 0.0437 - val_accuracy: 0.9936\n",
      "Epoch 14/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1050 - accuracy: 0.9784 - val_loss: 0.0441 - val_accuracy: 0.9936\n",
      "Epoch 15/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1052 - accuracy: 0.9784 - val_loss: 0.0464 - val_accuracy: 0.9936\n",
      "Epoch 16/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1052 - accuracy: 0.9784 - val_loss: 0.0479 - val_accuracy: 0.9936\n",
      "Epoch 17/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1051 - accuracy: 0.9784 - val_loss: 0.0433 - val_accuracy: 0.9936\n",
      "Epoch 18/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1047 - accuracy: 0.9784 - val_loss: 0.0455 - val_accuracy: 0.9936\n",
      "Epoch 19/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1050 - accuracy: 0.9784 - val_loss: 0.0486 - val_accuracy: 0.9936\n",
      "Epoch 20/30\n",
      "1977/1977 [==============================] - 11s 6ms/step - loss: 0.1048 - accuracy: 0.9784 - val_loss: 0.0464 - val_accuracy: 0.9936\n",
      "Epoch 21/30\n",
      "1977/1977 [==============================] - 11s 6ms/step - loss: 0.1049 - accuracy: 0.9784 - val_loss: 0.0443 - val_accuracy: 0.9936\n",
      "Epoch 22/30\n",
      "1977/1977 [==============================] - 11s 5ms/step - loss: 0.1047 - accuracy: 0.9784 - val_loss: 0.0462 - val_accuracy: 0.9936\n",
      "Epoch 23/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1050 - accuracy: 0.9784 - val_loss: 0.0457 - val_accuracy: 0.9936\n",
      "Epoch 24/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1049 - accuracy: 0.9784 - val_loss: 0.0459 - val_accuracy: 0.9936\n",
      "Epoch 25/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1048 - accuracy: 0.9784 - val_loss: 0.0454 - val_accuracy: 0.9936\n",
      "Epoch 26/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1051 - accuracy: 0.9784 - val_loss: 0.0451 - val_accuracy: 0.9936\n",
      "Epoch 27/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1047 - accuracy: 0.9784 - val_loss: 0.0462 - val_accuracy: 0.9936\n",
      "Epoch 28/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1050 - accuracy: 0.9784 - val_loss: 0.0454 - val_accuracy: 0.9936\n",
      "Epoch 29/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1050 - accuracy: 0.9784 - val_loss: 0.0478 - val_accuracy: 0.9936\n",
      "Epoch 30/30\n",
      "1977/1977 [==============================] - 10s 5ms/step - loss: 0.1048 - accuracy: 0.9784 - val_loss: 0.0467 - val_accuracy: 0.9936\n",
      "Fold 4, Best Validation Loss: 0.04267233982682228, Best Validation Accuracy: 0.9936120510101318\n",
      "Epoch 1/30\n",
      "2471/2471 [==============================] - 15s 5ms/step - loss: 0.0988 - accuracy: 0.9814 - val_loss: 0.0687 - val_accuracy: 0.9872\n",
      "Epoch 2/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0959 - accuracy: 0.9815 - val_loss: 0.0728 - val_accuracy: 0.9872\n",
      "Epoch 3/30\n",
      "2471/2471 [==============================] - 14s 6ms/step - loss: 0.0951 - accuracy: 0.9815 - val_loss: 0.0689 - val_accuracy: 0.9872\n",
      "Epoch 4/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0945 - accuracy: 0.9815 - val_loss: 0.0689 - val_accuracy: 0.9872\n",
      "Epoch 5/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0941 - accuracy: 0.9815 - val_loss: 0.0727 - val_accuracy: 0.9872\n",
      "Epoch 6/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0936 - accuracy: 0.9815 - val_loss: 0.0702 - val_accuracy: 0.9872\n",
      "Epoch 7/30\n",
      "2471/2471 [==============================] - 13s 5ms/step - loss: 0.0935 - accuracy: 0.9815 - val_loss: 0.0691 - val_accuracy: 0.9872\n",
      "Epoch 8/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0936 - accuracy: 0.9815 - val_loss: 0.0703 - val_accuracy: 0.9872\n",
      "Epoch 9/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0933 - accuracy: 0.9815 - val_loss: 0.0692 - val_accuracy: 0.9872\n",
      "Epoch 10/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0933 - accuracy: 0.9815 - val_loss: 0.0693 - val_accuracy: 0.9872\n",
      "Epoch 11/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0933 - accuracy: 0.9815 - val_loss: 0.0705 - val_accuracy: 0.9872\n",
      "Epoch 12/30\n",
      "2471/2471 [==============================] - 14s 6ms/step - loss: 0.0933 - accuracy: 0.9815 - val_loss: 0.0693 - val_accuracy: 0.9872\n",
      "Epoch 13/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0932 - accuracy: 0.9815 - val_loss: 0.0690 - val_accuracy: 0.9872\n",
      "Epoch 14/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0933 - accuracy: 0.9815 - val_loss: 0.0691 - val_accuracy: 0.9872\n",
      "Epoch 15/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0932 - accuracy: 0.9815 - val_loss: 0.0695 - val_accuracy: 0.9872\n",
      "Epoch 16/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0932 - accuracy: 0.9815 - val_loss: 0.0703 - val_accuracy: 0.9872\n",
      "Epoch 17/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0933 - accuracy: 0.9815 - val_loss: 0.0700 - val_accuracy: 0.9872\n",
      "Epoch 18/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0932 - accuracy: 0.9815 - val_loss: 0.0700 - val_accuracy: 0.9872\n",
      "Epoch 19/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0928 - accuracy: 0.9815 - val_loss: 0.0700 - val_accuracy: 0.9872\n",
      "Epoch 20/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0930 - accuracy: 0.9815 - val_loss: 0.0691 - val_accuracy: 0.9872\n",
      "Epoch 21/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0928 - accuracy: 0.9815 - val_loss: 0.0693 - val_accuracy: 0.9872\n",
      "Epoch 22/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0930 - accuracy: 0.9815 - val_loss: 0.0704 - val_accuracy: 0.9872\n",
      "Epoch 23/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0930 - accuracy: 0.9815 - val_loss: 0.0699 - val_accuracy: 0.9872\n",
      "Epoch 24/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0931 - accuracy: 0.9815 - val_loss: 0.0697 - val_accuracy: 0.9872\n",
      "Epoch 25/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0930 - accuracy: 0.9815 - val_loss: 0.0687 - val_accuracy: 0.9872\n",
      "Epoch 26/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0930 - accuracy: 0.9815 - val_loss: 0.0700 - val_accuracy: 0.9872\n",
      "Epoch 27/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0929 - accuracy: 0.9815 - val_loss: 0.0692 - val_accuracy: 0.9872\n",
      "Epoch 28/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0928 - accuracy: 0.9815 - val_loss: 0.0688 - val_accuracy: 0.9872\n",
      "Epoch 29/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0929 - accuracy: 0.9815 - val_loss: 0.0698 - val_accuracy: 0.9872\n",
      "Epoch 30/30\n",
      "2471/2471 [==============================] - 12s 5ms/step - loss: 0.0927 - accuracy: 0.9815 - val_loss: 0.0695 - val_accuracy: 0.9872\n",
      "Fold 5, Best Validation Loss: 0.06868850439786911, Best Validation Accuracy: 0.987160861492157\n",
      "Mean Best Validation Loss: 0.07636872753500938\n",
      "Mean Best Validation Accuracy: 0.9853140354156494\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 3s 329ms/step - loss: 0.5738 - accuracy: 0.6222 - val_loss: 1.9193 - val_accuracy: 0.8049\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.4133 - accuracy: 0.9111 - val_loss: 1.3536 - val_accuracy: 0.8049\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3668 - accuracy: 0.9333 - val_loss: 0.9265 - val_accuracy: 0.8049\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3471 - accuracy: 0.8889 - val_loss: 0.9542 - val_accuracy: 0.8049\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2892 - accuracy: 0.9333 - val_loss: 1.2870 - val_accuracy: 0.8049\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2429 - accuracy: 0.9333 - val_loss: 1.3107 - val_accuracy: 0.8049\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1983 - accuracy: 0.9333 - val_loss: 1.3930 - val_accuracy: 0.7561\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3439 - accuracy: 0.8667 - val_loss: 1.0986 - val_accuracy: 0.8293\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3463 - accuracy: 0.9111 - val_loss: 1.0902 - val_accuracy: 0.8049\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1553 - accuracy: 0.9333 - val_loss: 1.0882 - val_accuracy: 0.8049\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2388 - accuracy: 0.9111 - val_loss: 0.9495 - val_accuracy: 0.8537\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.1396 - accuracy: 0.9556 - val_loss: 1.1034 - val_accuracy: 0.7805\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0968 - accuracy: 0.9556 - val_loss: 1.3256 - val_accuracy: 0.7805\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2003 - accuracy: 0.9333 - val_loss: 1.4513 - val_accuracy: 0.7805\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1546 - accuracy: 0.9556 - val_loss: 1.3246 - val_accuracy: 0.8049\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2551 - accuracy: 0.9111 - val_loss: 1.2867 - val_accuracy: 0.8293\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1021 - accuracy: 0.9556 - val_loss: 1.3968 - val_accuracy: 0.8049\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2589 - accuracy: 0.9333 - val_loss: 1.3687 - val_accuracy: 0.8049\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2145 - accuracy: 0.9556 - val_loss: 1.3061 - val_accuracy: 0.8293\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3125 - accuracy: 0.9556 - val_loss: 1.3847 - val_accuracy: 0.8049\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0463 - accuracy: 0.9778 - val_loss: 1.7447 - val_accuracy: 0.7805\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0992 - accuracy: 0.9556 - val_loss: 2.1796 - val_accuracy: 0.6829\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2094 - accuracy: 0.9333 - val_loss: 2.0841 - val_accuracy: 0.6585\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0602 - accuracy: 0.9778 - val_loss: 1.6290 - val_accuracy: 0.7805\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0567 - accuracy: 0.9778 - val_loss: 1.3894 - val_accuracy: 0.7805\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1416 - accuracy: 0.9556 - val_loss: 1.2105 - val_accuracy: 0.7805\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.1400 - val_accuracy: 0.8293\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0798 - accuracy: 0.9778 - val_loss: 1.1991 - val_accuracy: 0.8293\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0601 - accuracy: 0.9556 - val_loss: 1.3667 - val_accuracy: 0.7805\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0839 - accuracy: 0.9778 - val_loss: 1.6692 - val_accuracy: 0.8049\n",
      "Fold 1, Best Validation Loss: 0.9265080094337463, Best Validation Accuracy: 0.8536585569381714\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 2s 241ms/step - loss: 0.6139 - accuracy: 0.7674 - val_loss: 1.3727 - val_accuracy: 0.6829\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.6953 - accuracy: 0.8140 - val_loss: 1.1515 - val_accuracy: 0.7073\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5092 - accuracy: 0.7907 - val_loss: 2.0426 - val_accuracy: 0.6829\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6378 - accuracy: 0.8837 - val_loss: 1.5796 - val_accuracy: 0.6829\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5043 - accuracy: 0.8372 - val_loss: 1.1540 - val_accuracy: 0.6829\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5558 - accuracy: 0.8256 - val_loss: 0.9879 - val_accuracy: 0.7073\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4384 - accuracy: 0.8023 - val_loss: 1.0291 - val_accuracy: 0.7073\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3096 - accuracy: 0.8488 - val_loss: 1.2551 - val_accuracy: 0.7073\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3072 - accuracy: 0.8837 - val_loss: 1.1996 - val_accuracy: 0.6585\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.3702 - accuracy: 0.8837 - val_loss: 1.2346 - val_accuracy: 0.7073\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.2698 - accuracy: 0.9302 - val_loss: 1.1930 - val_accuracy: 0.7073\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4737 - accuracy: 0.8256 - val_loss: 1.4496 - val_accuracy: 0.7073\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3961 - accuracy: 0.8837 - val_loss: 1.5646 - val_accuracy: 0.7073\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3299 - accuracy: 0.8605 - val_loss: 1.6495 - val_accuracy: 0.7073\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2797 - accuracy: 0.9070 - val_loss: 1.5306 - val_accuracy: 0.7073\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1519 - accuracy: 0.9535 - val_loss: 1.3715 - val_accuracy: 0.7073\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1593 - accuracy: 0.9302 - val_loss: 1.3565 - val_accuracy: 0.7073\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1601 - accuracy: 0.9651 - val_loss: 1.4642 - val_accuracy: 0.7073\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.1933 - accuracy: 0.9302 - val_loss: 1.6926 - val_accuracy: 0.7073\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1198 - accuracy: 0.9535 - val_loss: 1.7949 - val_accuracy: 0.7073\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1877 - accuracy: 0.9302 - val_loss: 1.5548 - val_accuracy: 0.7073\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1427 - accuracy: 0.9302 - val_loss: 1.5216 - val_accuracy: 0.7317\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.2724 - accuracy: 0.9070 - val_loss: 1.8622 - val_accuracy: 0.6829\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1885 - accuracy: 0.9535 - val_loss: 2.0944 - val_accuracy: 0.7073\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1759 - accuracy: 0.9651 - val_loss: 1.9148 - val_accuracy: 0.7073\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2153 - accuracy: 0.9419 - val_loss: 1.2883 - val_accuracy: 0.7317\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.1245 - accuracy: 0.9419 - val_loss: 1.3991 - val_accuracy: 0.7317\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1273 - accuracy: 0.9535 - val_loss: 1.6599 - val_accuracy: 0.7317\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1352 - accuracy: 0.9419 - val_loss: 1.8783 - val_accuracy: 0.7073\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0644 - accuracy: 0.9767 - val_loss: 1.9451 - val_accuracy: 0.7073\n",
      "Fold 2, Best Validation Loss: 0.9879119396209717, Best Validation Accuracy: 0.7317073345184326\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 2s 160ms/step - loss: 0.6464 - accuracy: 0.6772 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6427 - accuracy: 0.8110 - val_loss: 0.0953 - val_accuracy: 0.9756\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5941 - accuracy: 0.7323 - val_loss: 0.0772 - val_accuracy: 0.9756\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6588 - accuracy: 0.8110 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6147 - accuracy: 0.7480 - val_loss: 0.1472 - val_accuracy: 0.9756\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4858 - accuracy: 0.7953 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4095 - accuracy: 0.8346 - val_loss: 0.1005 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4172 - accuracy: 0.8346 - val_loss: 0.0647 - val_accuracy: 0.9756\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4063 - accuracy: 0.8346 - val_loss: 0.1590 - val_accuracy: 0.9268\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3230 - accuracy: 0.8425 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3257 - accuracy: 0.8504 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2900 - accuracy: 0.8661 - val_loss: 0.1121 - val_accuracy: 0.9756\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2212 - accuracy: 0.8898 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1611 - accuracy: 0.9291 - val_loss: 0.0531 - val_accuracy: 0.9756\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0995 - accuracy: 0.9528 - val_loss: 0.0322 - val_accuracy: 0.9756\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1025 - accuracy: 0.9606 - val_loss: 0.0545 - val_accuracy: 0.9756\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1760 - accuracy: 0.9370 - val_loss: 0.0769 - val_accuracy: 0.9756\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0447 - accuracy: 0.9843 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1258 - accuracy: 0.9528 - val_loss: 0.0427 - val_accuracy: 0.9756\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0886 - accuracy: 0.9528 - val_loss: 0.1221 - val_accuracy: 0.9512\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0407 - accuracy: 0.9843 - val_loss: 0.1636 - val_accuracy: 0.9268\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0804 - accuracy: 0.9685 - val_loss: 0.0598 - val_accuracy: 0.9756\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0498 - accuracy: 0.9843 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1170 - accuracy: 0.9528 - val_loss: 0.0355 - val_accuracy: 0.9756\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1152 - accuracy: 0.9685 - val_loss: 0.0351 - val_accuracy: 0.9756\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0758 - accuracy: 0.9606 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1344 - accuracy: 0.9606 - val_loss: 0.0996 - val_accuracy: 0.9512\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1864 - accuracy: 0.9685 - val_loss: 0.1146 - val_accuracy: 0.9268\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0948 - accuracy: 0.9685 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0741 - accuracy: 0.9606 - val_loss: 0.0405 - val_accuracy: 0.9756\n",
      "Fold 3, Best Validation Loss: 0.01692555658519268, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 2s 139ms/step - loss: 0.6835 - accuracy: 0.7381 - val_loss: 0.1677 - val_accuracy: 0.9512\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.5929 - accuracy: 0.8155 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.5397 - accuracy: 0.8155 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.5696 - accuracy: 0.8393 - val_loss: 0.0962 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.5366 - accuracy: 0.8095 - val_loss: 0.1367 - val_accuracy: 0.9756\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4632 - accuracy: 0.8274 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.4657 - accuracy: 0.8452 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3216 - accuracy: 0.8929 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.3563 - accuracy: 0.8750 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3206 - accuracy: 0.8988 - val_loss: 0.0642 - val_accuracy: 0.9756\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3269 - accuracy: 0.8750 - val_loss: 0.0595 - val_accuracy: 0.9512\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2708 - accuracy: 0.9048 - val_loss: 0.0745 - val_accuracy: 0.9512\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2876 - accuracy: 0.9048 - val_loss: 0.0610 - val_accuracy: 0.9756\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1869 - accuracy: 0.9167 - val_loss: 0.0926 - val_accuracy: 0.9512\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.2695 - accuracy: 0.9048 - val_loss: 0.1188 - val_accuracy: 0.9512\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1969 - accuracy: 0.9405 - val_loss: 0.1854 - val_accuracy: 0.9512\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1534 - accuracy: 0.9405 - val_loss: 0.4397 - val_accuracy: 0.9024\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3306 - accuracy: 0.8452 - val_loss: 0.0690 - val_accuracy: 0.9756\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.3732 - accuracy: 0.8690 - val_loss: 0.0744 - val_accuracy: 0.9756\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1502 - accuracy: 0.9524 - val_loss: 0.3106 - val_accuracy: 0.9268\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2008 - accuracy: 0.9048 - val_loss: 0.1078 - val_accuracy: 0.9512\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1323 - accuracy: 0.9345 - val_loss: 0.0363 - val_accuracy: 0.9756\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1980 - accuracy: 0.9226 - val_loss: 0.2658 - val_accuracy: 0.9512\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1106 - accuracy: 0.9583 - val_loss: 0.3172 - val_accuracy: 0.9512\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0675 - accuracy: 0.9643 - val_loss: 0.2879 - val_accuracy: 0.9512\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0820 - accuracy: 0.9583 - val_loss: 0.2280 - val_accuracy: 0.9512\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0994 - accuracy: 0.9762 - val_loss: 0.2339 - val_accuracy: 0.9512\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0566 - accuracy: 0.9821 - val_loss: 0.2055 - val_accuracy: 0.9512\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0839 - accuracy: 0.9643 - val_loss: 0.1328 - val_accuracy: 0.9756\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2399 - accuracy: 0.9226 - val_loss: 0.4025 - val_accuracy: 0.9268\n",
      "Fold 4, Best Validation Loss: 0.02498687244951725, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "7/7 [==============================] - 2s 74ms/step - loss: 0.7519 - accuracy: 0.7990 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.5155 - accuracy: 0.8421 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.4876 - accuracy: 0.8612 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.4694 - accuracy: 0.8325 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.4025 - accuracy: 0.8708 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3980 - accuracy: 0.8708 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.3830 - accuracy: 0.8900 - val_loss: 0.1744 - val_accuracy: 0.9756\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.3983 - accuracy: 0.8565 - val_loss: 0.1638 - val_accuracy: 0.9268\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.3593 - accuracy: 0.8612 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3346 - accuracy: 0.8947 - val_loss: 0.1359 - val_accuracy: 0.9512\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.2926 - accuracy: 0.8900 - val_loss: 0.0925 - val_accuracy: 0.9756\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2624 - accuracy: 0.9187 - val_loss: 0.1276 - val_accuracy: 0.9512\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.2614 - accuracy: 0.9139 - val_loss: 0.0718 - val_accuracy: 0.9512\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.2687 - accuracy: 0.9139 - val_loss: 0.0669 - val_accuracy: 0.9756\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2118 - accuracy: 0.9426 - val_loss: 0.0794 - val_accuracy: 0.9756\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.2471 - accuracy: 0.9234 - val_loss: 0.2627 - val_accuracy: 0.9512\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2066 - accuracy: 0.9330 - val_loss: 0.0620 - val_accuracy: 0.9512\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.1792 - accuracy: 0.9426 - val_loss: 0.1202 - val_accuracy: 0.9512\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.1599 - accuracy: 0.9378 - val_loss: 0.1412 - val_accuracy: 0.9268\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0984 - accuracy: 0.9665 - val_loss: 0.0683 - val_accuracy: 0.9756\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.1430 - accuracy: 0.9569 - val_loss: 0.1016 - val_accuracy: 0.9756\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0445 - accuracy: 0.9761 - val_loss: 0.2607 - val_accuracy: 0.9268\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0870 - accuracy: 0.9713 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.2287 - accuracy: 0.9522 - val_loss: 0.8320 - val_accuracy: 0.7805\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.1065 - accuracy: 0.9569 - val_loss: 0.1328 - val_accuracy: 0.9512\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.1531 - accuracy: 0.9569 - val_loss: 0.2547 - val_accuracy: 0.9756\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1569 - accuracy: 0.9617 - val_loss: 0.3609 - val_accuracy: 0.9024\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0897 - accuracy: 0.9713 - val_loss: 0.0594 - val_accuracy: 0.9756\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.1883 - accuracy: 0.9522 - val_loss: 0.3340 - val_accuracy: 0.8780\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.1541 - accuracy: 0.9234 - val_loss: 0.2007 - val_accuracy: 0.9024\n",
      "Fold 5, Best Validation Loss: 0.008925571106374264, Best Validation Accuracy: 1.0\n",
      "Mean Best Validation Loss: 0.39305158983916044\n",
      "Mean Best Validation Accuracy: 0.9170731782913208\n",
      "Epoch 1/30\n",
      "108/108 [==============================] - 12s 9ms/step - loss: 0.2840 - accuracy: 0.9058 - val_loss: 0.1730 - val_accuracy: 0.9511\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1792 - accuracy: 0.9375 - val_loss: 0.1544 - val_accuracy: 0.9453\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1595 - accuracy: 0.9433 - val_loss: 0.1057 - val_accuracy: 0.9666\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1299 - accuracy: 0.9582 - val_loss: 0.1000 - val_accuracy: 0.9648\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1262 - accuracy: 0.9573 - val_loss: 0.1275 - val_accuracy: 0.9552\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1227 - accuracy: 0.9619 - val_loss: 0.1301 - val_accuracy: 0.9602\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1205 - accuracy: 0.9640 - val_loss: 0.1012 - val_accuracy: 0.9622\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1141 - accuracy: 0.9666 - val_loss: 0.0957 - val_accuracy: 0.9700\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1096 - accuracy: 0.9666 - val_loss: 0.0900 - val_accuracy: 0.9663\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1247 - accuracy: 0.9593 - val_loss: 0.0978 - val_accuracy: 0.9654\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0973 - accuracy: 0.9706 - val_loss: 0.1015 - val_accuracy: 0.9657\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 1s 11ms/step - loss: 0.1114 - accuracy: 0.9657 - val_loss: 0.1013 - val_accuracy: 0.9645\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 1s 10ms/step - loss: 0.1018 - accuracy: 0.9701 - val_loss: 0.1043 - val_accuracy: 0.9639\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1057 - accuracy: 0.9686 - val_loss: 0.1040 - val_accuracy: 0.9695\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.0993 - accuracy: 0.9686 - val_loss: 0.1008 - val_accuracy: 0.9700\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0960 - accuracy: 0.9715 - val_loss: 0.1100 - val_accuracy: 0.9636\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 1s 9ms/step - loss: 0.1047 - accuracy: 0.9672 - val_loss: 0.0975 - val_accuracy: 0.9666\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0973 - accuracy: 0.9718 - val_loss: 0.0979 - val_accuracy: 0.9706\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.9695 - val_loss: 0.1513 - val_accuracy: 0.9572\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0952 - accuracy: 0.9724 - val_loss: 0.1083 - val_accuracy: 0.9634\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0977 - accuracy: 0.9730 - val_loss: 0.1072 - val_accuracy: 0.9634\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0965 - accuracy: 0.9715 - val_loss: 0.1198 - val_accuracy: 0.9616\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1029 - accuracy: 0.9701 - val_loss: 0.1059 - val_accuracy: 0.9677\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0979 - accuracy: 0.9706 - val_loss: 0.1326 - val_accuracy: 0.9660\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1104 - accuracy: 0.9651 - val_loss: 0.0984 - val_accuracy: 0.9706\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1029 - accuracy: 0.9669 - val_loss: 0.1072 - val_accuracy: 0.9657\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1025 - accuracy: 0.9689 - val_loss: 0.1090 - val_accuracy: 0.9648\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0940 - accuracy: 0.9718 - val_loss: 0.1160 - val_accuracy: 0.9634\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1035 - accuracy: 0.9683 - val_loss: 0.0986 - val_accuracy: 0.9666\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0986 - accuracy: 0.9715 - val_loss: 0.0926 - val_accuracy: 0.9645\n",
      "Fold 1, Best Validation Loss: 0.08996643126010895, Best Validation Accuracy: 0.9706224799156189\n",
      "Epoch 1/30\n",
      "215/215 [==============================] - 4s 8ms/step - loss: 0.2281 - accuracy: 0.9273 - val_loss: 0.1441 - val_accuracy: 0.9462\n",
      "Epoch 2/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1472 - accuracy: 0.9494 - val_loss: 0.1360 - val_accuracy: 0.9343\n",
      "Epoch 3/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1264 - accuracy: 0.9539 - val_loss: 0.0947 - val_accuracy: 0.9651\n",
      "Epoch 4/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1162 - accuracy: 0.9605 - val_loss: 0.1003 - val_accuracy: 0.9636\n",
      "Epoch 5/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1146 - accuracy: 0.9589 - val_loss: 0.1047 - val_accuracy: 0.9529\n",
      "Epoch 6/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1065 - accuracy: 0.9650 - val_loss: 0.0870 - val_accuracy: 0.9642\n",
      "Epoch 7/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1116 - accuracy: 0.9628 - val_loss: 0.0847 - val_accuracy: 0.9660\n",
      "Epoch 8/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1063 - accuracy: 0.9648 - val_loss: 0.0846 - val_accuracy: 0.9677\n",
      "Epoch 9/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1051 - accuracy: 0.9650 - val_loss: 0.0889 - val_accuracy: 0.9663\n",
      "Epoch 10/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1109 - accuracy: 0.9650 - val_loss: 0.0834 - val_accuracy: 0.9668\n",
      "Epoch 11/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1012 - accuracy: 0.9667 - val_loss: 0.0846 - val_accuracy: 0.9663\n",
      "Epoch 12/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1043 - accuracy: 0.9651 - val_loss: 0.0873 - val_accuracy: 0.9663\n",
      "Epoch 13/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1027 - accuracy: 0.9677 - val_loss: 0.0811 - val_accuracy: 0.9683\n",
      "Epoch 14/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0976 - accuracy: 0.9655 - val_loss: 0.0907 - val_accuracy: 0.9671\n",
      "Epoch 15/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0961 - accuracy: 0.9680 - val_loss: 0.0841 - val_accuracy: 0.9666\n",
      "Epoch 16/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0997 - accuracy: 0.9661 - val_loss: 0.0784 - val_accuracy: 0.9697\n",
      "Epoch 17/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0996 - accuracy: 0.9682 - val_loss: 0.0827 - val_accuracy: 0.9683\n",
      "Epoch 18/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0963 - accuracy: 0.9671 - val_loss: 0.0919 - val_accuracy: 0.9657\n",
      "Epoch 19/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0973 - accuracy: 0.9686 - val_loss: 0.0822 - val_accuracy: 0.9677\n",
      "Epoch 20/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0923 - accuracy: 0.9689 - val_loss: 0.0813 - val_accuracy: 0.9680\n",
      "Epoch 21/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0935 - accuracy: 0.9658 - val_loss: 0.0748 - val_accuracy: 0.9697\n",
      "Epoch 22/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0925 - accuracy: 0.9671 - val_loss: 0.0881 - val_accuracy: 0.9666\n",
      "Epoch 23/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0948 - accuracy: 0.9689 - val_loss: 0.0802 - val_accuracy: 0.9689\n",
      "Epoch 24/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0945 - accuracy: 0.9679 - val_loss: 0.0782 - val_accuracy: 0.9689\n",
      "Epoch 25/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0926 - accuracy: 0.9714 - val_loss: 0.0759 - val_accuracy: 0.9686\n",
      "Epoch 26/30\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0929 - accuracy: 0.9689 - val_loss: 0.0779 - val_accuracy: 0.9700\n",
      "Epoch 27/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0909 - accuracy: 0.9679 - val_loss: 0.0749 - val_accuracy: 0.9706\n",
      "Epoch 28/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0916 - accuracy: 0.9687 - val_loss: 0.0741 - val_accuracy: 0.9695\n",
      "Epoch 29/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0873 - accuracy: 0.9690 - val_loss: 0.0755 - val_accuracy: 0.9689\n",
      "Epoch 30/30\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0916 - accuracy: 0.9679 - val_loss: 0.0808 - val_accuracy: 0.9674\n",
      "Fold 2, Best Validation Loss: 0.0741073414683342, Best Validation Accuracy: 0.9706224799156189\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 4s 7ms/step - loss: 0.2036 - accuracy: 0.9301 - val_loss: 0.1168 - val_accuracy: 0.9613\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.1330 - accuracy: 0.9458 - val_loss: 0.1079 - val_accuracy: 0.9628\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.1142 - accuracy: 0.9606 - val_loss: 0.1109 - val_accuracy: 0.9602\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.1076 - accuracy: 0.9641 - val_loss: 0.1116 - val_accuracy: 0.9683\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.1039 - accuracy: 0.9638 - val_loss: 0.0973 - val_accuracy: 0.9602\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 3s 8ms/step - loss: 0.1039 - accuracy: 0.9640 - val_loss: 0.0999 - val_accuracy: 0.9666\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.1031 - accuracy: 0.9611 - val_loss: 0.0934 - val_accuracy: 0.9677\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.1019 - accuracy: 0.9666 - val_loss: 0.1019 - val_accuracy: 0.9642\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0983 - accuracy: 0.9675 - val_loss: 0.0997 - val_accuracy: 0.9642\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0985 - accuracy: 0.9644 - val_loss: 0.1030 - val_accuracy: 0.9692\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0973 - accuracy: 0.9637 - val_loss: 0.0888 - val_accuracy: 0.9689\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0931 - accuracy: 0.9664 - val_loss: 0.1125 - val_accuracy: 0.9636\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0994 - accuracy: 0.9648 - val_loss: 0.1033 - val_accuracy: 0.9674\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0952 - accuracy: 0.9669 - val_loss: 0.0926 - val_accuracy: 0.9666\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0936 - accuracy: 0.9671 - val_loss: 0.0876 - val_accuracy: 0.9683\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0921 - accuracy: 0.9676 - val_loss: 0.0922 - val_accuracy: 0.9683\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0894 - accuracy: 0.9675 - val_loss: 0.0886 - val_accuracy: 0.9677\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0914 - accuracy: 0.9667 - val_loss: 0.0903 - val_accuracy: 0.9686\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0861 - accuracy: 0.9680 - val_loss: 0.0852 - val_accuracy: 0.9686\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0895 - accuracy: 0.9680 - val_loss: 0.0818 - val_accuracy: 0.9695\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0874 - accuracy: 0.9695 - val_loss: 0.0820 - val_accuracy: 0.9683\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0854 - accuracy: 0.9701 - val_loss: 0.0843 - val_accuracy: 0.9686\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0850 - accuracy: 0.9695 - val_loss: 0.0763 - val_accuracy: 0.9692\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0878 - accuracy: 0.9674 - val_loss: 0.0902 - val_accuracy: 0.9695\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 2s 8ms/step - loss: 0.0851 - accuracy: 0.9703 - val_loss: 0.0896 - val_accuracy: 0.9628\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0872 - accuracy: 0.9683 - val_loss: 0.0789 - val_accuracy: 0.9700\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0831 - accuracy: 0.9704 - val_loss: 0.0880 - val_accuracy: 0.9639\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0806 - accuracy: 0.9704 - val_loss: 0.0911 - val_accuracy: 0.9697\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0820 - accuracy: 0.9711 - val_loss: 0.0773 - val_accuracy: 0.9697\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 2s 7ms/step - loss: 0.0785 - accuracy: 0.9711 - val_loss: 0.0856 - val_accuracy: 0.9709\n",
      "Fold 3, Best Validation Loss: 0.0763164758682251, Best Validation Accuracy: 0.9709133505821228\n",
      "Epoch 1/30\n",
      "430/430 [==============================] - 5s 7ms/step - loss: 0.1918 - accuracy: 0.9365 - val_loss: 0.1404 - val_accuracy: 0.9523\n",
      "Epoch 2/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1300 - accuracy: 0.9548 - val_loss: 0.1520 - val_accuracy: 0.9447\n",
      "Epoch 3/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1205 - accuracy: 0.9593 - val_loss: 0.1078 - val_accuracy: 0.9628\n",
      "Epoch 4/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1139 - accuracy: 0.9618 - val_loss: 0.1117 - val_accuracy: 0.9631\n",
      "Epoch 5/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1083 - accuracy: 0.9624 - val_loss: 0.1000 - val_accuracy: 0.9692\n",
      "Epoch 6/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1011 - accuracy: 0.9648 - val_loss: 0.1021 - val_accuracy: 0.9668\n",
      "Epoch 7/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0995 - accuracy: 0.9652 - val_loss: 0.1094 - val_accuracy: 0.9663\n",
      "Epoch 8/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.1002 - accuracy: 0.9647 - val_loss: 0.0971 - val_accuracy: 0.9668\n",
      "Epoch 9/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0948 - accuracy: 0.9659 - val_loss: 0.1112 - val_accuracy: 0.9613\n",
      "Epoch 10/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.0949 - accuracy: 0.9665 - val_loss: 0.0945 - val_accuracy: 0.9663\n",
      "Epoch 11/30\n",
      "430/430 [==============================] - 3s 8ms/step - loss: 0.0913 - accuracy: 0.9671 - val_loss: 0.0964 - val_accuracy: 0.9668\n",
      "Epoch 12/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0911 - accuracy: 0.9685 - val_loss: 0.0903 - val_accuracy: 0.9680\n",
      "Epoch 13/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0900 - accuracy: 0.9690 - val_loss: 0.1359 - val_accuracy: 0.9581\n",
      "Epoch 14/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0872 - accuracy: 0.9685 - val_loss: 0.0849 - val_accuracy: 0.9683\n",
      "Epoch 15/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0881 - accuracy: 0.9687 - val_loss: 0.1042 - val_accuracy: 0.9613\n",
      "Epoch 16/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0879 - accuracy: 0.9688 - val_loss: 0.0864 - val_accuracy: 0.9677\n",
      "Epoch 17/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0831 - accuracy: 0.9686 - val_loss: 0.0847 - val_accuracy: 0.9645\n",
      "Epoch 18/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0796 - accuracy: 0.9703 - val_loss: 0.0777 - val_accuracy: 0.9706\n",
      "Epoch 19/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0782 - accuracy: 0.9704 - val_loss: 0.0774 - val_accuracy: 0.9700\n",
      "Epoch 20/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0742 - accuracy: 0.9709 - val_loss: 0.0812 - val_accuracy: 0.9686\n",
      "Epoch 21/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0772 - accuracy: 0.9707 - val_loss: 0.0864 - val_accuracy: 0.9631\n",
      "Epoch 22/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0743 - accuracy: 0.9715 - val_loss: 0.0733 - val_accuracy: 0.9695\n",
      "Epoch 23/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0737 - accuracy: 0.9730 - val_loss: 0.0964 - val_accuracy: 0.9666\n",
      "Epoch 24/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0705 - accuracy: 0.9723 - val_loss: 0.0912 - val_accuracy: 0.9648\n",
      "Epoch 25/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0698 - accuracy: 0.9732 - val_loss: 0.0792 - val_accuracy: 0.9680\n",
      "Epoch 26/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0701 - accuracy: 0.9728 - val_loss: 0.0723 - val_accuracy: 0.9692\n",
      "Epoch 27/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0728 - accuracy: 0.9722 - val_loss: 0.0799 - val_accuracy: 0.9660\n",
      "Epoch 28/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0685 - accuracy: 0.9721 - val_loss: 0.0598 - val_accuracy: 0.9735\n",
      "Epoch 29/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0653 - accuracy: 0.9736 - val_loss: 0.0837 - val_accuracy: 0.9700\n",
      "Epoch 30/30\n",
      "430/430 [==============================] - 3s 7ms/step - loss: 0.0679 - accuracy: 0.9731 - val_loss: 0.0622 - val_accuracy: 0.9738\n",
      "Fold 4, Best Validation Loss: 0.05981149896979332, Best Validation Accuracy: 0.9738219976425171\n",
      "Epoch 1/30\n",
      "538/538 [==============================] - 6s 7ms/step - loss: 0.1714 - accuracy: 0.9388 - val_loss: 0.1237 - val_accuracy: 0.9433\n",
      "Epoch 2/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1231 - accuracy: 0.9568 - val_loss: 0.0630 - val_accuracy: 0.9759\n",
      "Epoch 3/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1100 - accuracy: 0.9622 - val_loss: 0.0755 - val_accuracy: 0.9695\n",
      "Epoch 4/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1079 - accuracy: 0.9631 - val_loss: 0.0654 - val_accuracy: 0.9747\n",
      "Epoch 5/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1042 - accuracy: 0.9626 - val_loss: 0.0631 - val_accuracy: 0.9759\n",
      "Epoch 6/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1018 - accuracy: 0.9630 - val_loss: 0.0682 - val_accuracy: 0.9732\n",
      "Epoch 7/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.1006 - accuracy: 0.9648 - val_loss: 0.0618 - val_accuracy: 0.9747\n",
      "Epoch 8/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0990 - accuracy: 0.9650 - val_loss: 0.0638 - val_accuracy: 0.9747\n",
      "Epoch 9/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0964 - accuracy: 0.9664 - val_loss: 0.0657 - val_accuracy: 0.9767\n",
      "Epoch 10/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0987 - accuracy: 0.9654 - val_loss: 0.0594 - val_accuracy: 0.9747\n",
      "Epoch 11/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0936 - accuracy: 0.9665 - val_loss: 0.0642 - val_accuracy: 0.9747\n",
      "Epoch 12/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0946 - accuracy: 0.9670 - val_loss: 0.0584 - val_accuracy: 0.9759\n",
      "Epoch 13/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0931 - accuracy: 0.9655 - val_loss: 0.0738 - val_accuracy: 0.9697\n",
      "Epoch 14/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0944 - accuracy: 0.9655 - val_loss: 0.0580 - val_accuracy: 0.9759\n",
      "Epoch 15/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0897 - accuracy: 0.9674 - val_loss: 0.0550 - val_accuracy: 0.9759\n",
      "Epoch 16/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0861 - accuracy: 0.9675 - val_loss: 0.0577 - val_accuracy: 0.9750\n",
      "Epoch 17/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0869 - accuracy: 0.9679 - val_loss: 0.0580 - val_accuracy: 0.9747\n",
      "Epoch 18/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0839 - accuracy: 0.9680 - val_loss: 0.0561 - val_accuracy: 0.9767\n",
      "Epoch 19/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0827 - accuracy: 0.9693 - val_loss: 0.0536 - val_accuracy: 0.9767\n",
      "Epoch 20/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0802 - accuracy: 0.9694 - val_loss: 0.0530 - val_accuracy: 0.9770\n",
      "Epoch 21/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0767 - accuracy: 0.9704 - val_loss: 0.0494 - val_accuracy: 0.9776\n",
      "Epoch 22/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0778 - accuracy: 0.9688 - val_loss: 0.0490 - val_accuracy: 0.9779\n",
      "Epoch 23/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0747 - accuracy: 0.9702 - val_loss: 0.0555 - val_accuracy: 0.9782\n",
      "Epoch 24/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0771 - accuracy: 0.9706 - val_loss: 0.0540 - val_accuracy: 0.9776\n",
      "Epoch 25/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0727 - accuracy: 0.9713 - val_loss: 0.0482 - val_accuracy: 0.9779\n",
      "Epoch 26/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0720 - accuracy: 0.9706 - val_loss: 0.0480 - val_accuracy: 0.9793\n",
      "Epoch 27/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0717 - accuracy: 0.9710 - val_loss: 0.0454 - val_accuracy: 0.9796\n",
      "Epoch 28/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0696 - accuracy: 0.9713 - val_loss: 0.0465 - val_accuracy: 0.9802\n",
      "Epoch 29/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0694 - accuracy: 0.9710 - val_loss: 0.0852 - val_accuracy: 0.9692\n",
      "Epoch 30/30\n",
      "538/538 [==============================] - 4s 7ms/step - loss: 0.0685 - accuracy: 0.9724 - val_loss: 0.0479 - val_accuracy: 0.9808\n",
      "Fold 5, Best Validation Loss: 0.04537136107683182, Best Validation Accuracy: 0.9808027744293213\n",
      "Mean Best Validation Loss: 0.06911462172865868\n",
      "Mean Best Validation Accuracy: 0.9733566164970398\n",
      "Epoch 1/30\n",
      "79/79 [==============================] - 3s 9ms/step - loss: 0.6797 - accuracy: 0.8524 - val_loss: 0.6592 - val_accuracy: 0.9424\n",
      "Epoch 2/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6543 - accuracy: 0.8524 - val_loss: 0.6281 - val_accuracy: 0.9424\n",
      "Epoch 3/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6311 - accuracy: 0.8524 - val_loss: 0.5997 - val_accuracy: 0.9424\n",
      "Epoch 4/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.8524 - val_loss: 0.5728 - val_accuracy: 0.9424\n",
      "Epoch 5/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5905 - accuracy: 0.8524 - val_loss: 0.5485 - val_accuracy: 0.9424\n",
      "Epoch 6/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5728 - accuracy: 0.8524 - val_loss: 0.5257 - val_accuracy: 0.9424\n",
      "Epoch 7/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.8524 - val_loss: 0.5048 - val_accuracy: 0.9424\n",
      "Epoch 8/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.8524 - val_loss: 0.4852 - val_accuracy: 0.9424\n",
      "Epoch 9/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.8524 - val_loss: 0.4674 - val_accuracy: 0.9424\n",
      "Epoch 10/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.8524 - val_loss: 0.4510 - val_accuracy: 0.9424\n",
      "Epoch 11/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.8524 - val_loss: 0.4357 - val_accuracy: 0.9424\n",
      "Epoch 12/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.8524 - val_loss: 0.4217 - val_accuracy: 0.9424\n",
      "Epoch 13/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.8524 - val_loss: 0.4085 - val_accuracy: 0.9424\n",
      "Epoch 14/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.8524 - val_loss: 0.3965 - val_accuracy: 0.9424\n",
      "Epoch 15/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.8524 - val_loss: 0.3856 - val_accuracy: 0.9424\n",
      "Epoch 16/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.8524 - val_loss: 0.3751 - val_accuracy: 0.9424\n",
      "Epoch 17/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.8524 - val_loss: 0.3657 - val_accuracy: 0.9424\n",
      "Epoch 18/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.8524 - val_loss: 0.3570 - val_accuracy: 0.9424\n",
      "Epoch 19/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.8524 - val_loss: 0.3490 - val_accuracy: 0.9424\n",
      "Epoch 20/30\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.4469 - accuracy: 0.8524 - val_loss: 0.3419 - val_accuracy: 0.9424\n",
      "Epoch 21/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.8524 - val_loss: 0.3348 - val_accuracy: 0.9424\n",
      "Epoch 22/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.8524 - val_loss: 0.3286 - val_accuracy: 0.9424\n",
      "Epoch 23/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.8524 - val_loss: 0.3229 - val_accuracy: 0.9424\n",
      "Epoch 24/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4350 - accuracy: 0.8524 - val_loss: 0.3180 - val_accuracy: 0.9424\n",
      "Epoch 25/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.8524 - val_loss: 0.3133 - val_accuracy: 0.9424\n",
      "Epoch 26/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.8524 - val_loss: 0.3088 - val_accuracy: 0.9424\n",
      "Epoch 27/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.8524 - val_loss: 0.3044 - val_accuracy: 0.9424\n",
      "Epoch 28/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.8524 - val_loss: 0.3003 - val_accuracy: 0.9424\n",
      "Epoch 29/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.8524 - val_loss: 0.2969 - val_accuracy: 0.9424\n",
      "Epoch 30/30\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8524 - val_loss: 0.2937 - val_accuracy: 0.9424\n",
      "Fold 1, Best Validation Loss: 0.29370737075805664, Best Validation Accuracy: 0.9423999786376953\n",
      "Epoch 1/30\n",
      "157/157 [==============================] - 3s 7ms/step - loss: 0.6635 - accuracy: 0.8974 - val_loss: 0.6334 - val_accuracy: 0.9080\n",
      "Epoch 2/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.6099 - accuracy: 0.8974 - val_loss: 0.5825 - val_accuracy: 0.9080\n",
      "Epoch 3/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5643 - accuracy: 0.8974 - val_loss: 0.5390 - val_accuracy: 0.9080\n",
      "Epoch 4/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.5257 - accuracy: 0.8974 - val_loss: 0.5020 - val_accuracy: 0.9080\n",
      "Epoch 5/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4928 - accuracy: 0.8974 - val_loss: 0.4706 - val_accuracy: 0.9080\n",
      "Epoch 6/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.8974 - val_loss: 0.4439 - val_accuracy: 0.9080\n",
      "Epoch 7/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4415 - accuracy: 0.8974 - val_loss: 0.4214 - val_accuracy: 0.9080\n",
      "Epoch 8/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.8974 - val_loss: 0.4023 - val_accuracy: 0.9080\n",
      "Epoch 9/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.4055 - accuracy: 0.8974 - val_loss: 0.3862 - val_accuracy: 0.9080\n",
      "Epoch 10/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3918 - accuracy: 0.8974 - val_loss: 0.3728 - val_accuracy: 0.9080\n",
      "Epoch 11/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3804 - accuracy: 0.8974 - val_loss: 0.3617 - val_accuracy: 0.9080\n",
      "Epoch 12/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3709 - accuracy: 0.8974 - val_loss: 0.3522 - val_accuracy: 0.9080\n",
      "Epoch 13/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3630 - accuracy: 0.8974 - val_loss: 0.3442 - val_accuracy: 0.9080\n",
      "Epoch 14/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3566 - accuracy: 0.8974 - val_loss: 0.3377 - val_accuracy: 0.9080\n",
      "Epoch 15/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3513 - accuracy: 0.8974 - val_loss: 0.3321 - val_accuracy: 0.9080\n",
      "Epoch 16/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3470 - accuracy: 0.8974 - val_loss: 0.3275 - val_accuracy: 0.9080\n",
      "Epoch 17/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3435 - accuracy: 0.8974 - val_loss: 0.3239 - val_accuracy: 0.9080\n",
      "Epoch 18/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3406 - accuracy: 0.8974 - val_loss: 0.3207 - val_accuracy: 0.9080\n",
      "Epoch 19/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3383 - accuracy: 0.8974 - val_loss: 0.3181 - val_accuracy: 0.9080\n",
      "Epoch 20/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3365 - accuracy: 0.8974 - val_loss: 0.3161 - val_accuracy: 0.9080\n",
      "Epoch 21/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3351 - accuracy: 0.8974 - val_loss: 0.3144 - val_accuracy: 0.9080\n",
      "Epoch 22/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3340 - accuracy: 0.8974 - val_loss: 0.3131 - val_accuracy: 0.9080\n",
      "Epoch 23/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3331 - accuracy: 0.8974 - val_loss: 0.3119 - val_accuracy: 0.9080\n",
      "Epoch 24/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3325 - accuracy: 0.8974 - val_loss: 0.3110 - val_accuracy: 0.9080\n",
      "Epoch 25/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3320 - accuracy: 0.8974 - val_loss: 0.3103 - val_accuracy: 0.9080\n",
      "Epoch 26/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3317 - accuracy: 0.8974 - val_loss: 0.3099 - val_accuracy: 0.9080\n",
      "Epoch 27/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3314 - accuracy: 0.8974 - val_loss: 0.3094 - val_accuracy: 0.9080\n",
      "Epoch 28/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3312 - accuracy: 0.8974 - val_loss: 0.3090 - val_accuracy: 0.9080\n",
      "Epoch 29/30\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3311 - accuracy: 0.8974 - val_loss: 0.3087 - val_accuracy: 0.9080\n",
      "Epoch 30/30\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3310 - accuracy: 0.8974 - val_loss: 0.3085 - val_accuracy: 0.9080\n",
      "Fold 2, Best Validation Loss: 0.3084694445133209, Best Validation Accuracy: 0.9079999923706055\n",
      "Epoch 1/30\n",
      "235/235 [==============================] - 3s 6ms/step - loss: 0.6503 - accuracy: 0.9009 - val_loss: 0.6141 - val_accuracy: 0.8808\n",
      "Epoch 2/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.5751 - accuracy: 0.9009 - val_loss: 0.5515 - val_accuracy: 0.8808\n",
      "Epoch 3/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.5158 - accuracy: 0.9009 - val_loss: 0.5030 - val_accuracy: 0.8808\n",
      "Epoch 4/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4696 - accuracy: 0.9009 - val_loss: 0.4661 - val_accuracy: 0.8808\n",
      "Epoch 5/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4337 - accuracy: 0.9009 - val_loss: 0.4378 - val_accuracy: 0.8808\n",
      "Epoch 6/30\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4059 - accuracy: 0.9009 - val_loss: 0.4166 - val_accuracy: 0.8808\n",
      "Epoch 7/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3846 - accuracy: 0.9009 - val_loss: 0.4008 - val_accuracy: 0.8808\n",
      "Epoch 8/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3683 - accuracy: 0.9009 - val_loss: 0.3893 - val_accuracy: 0.8808\n",
      "Epoch 9/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3560 - accuracy: 0.9009 - val_loss: 0.3808 - val_accuracy: 0.8808\n",
      "Epoch 10/30\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3466 - accuracy: 0.9009 - val_loss: 0.3749 - val_accuracy: 0.8808\n",
      "Epoch 11/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3397 - accuracy: 0.9009 - val_loss: 0.3709 - val_accuracy: 0.8808\n",
      "Epoch 12/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3347 - accuracy: 0.9009 - val_loss: 0.3682 - val_accuracy: 0.8808\n",
      "Epoch 13/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3310 - accuracy: 0.9009 - val_loss: 0.3666 - val_accuracy: 0.8808\n",
      "Epoch 14/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3283 - accuracy: 0.9009 - val_loss: 0.3658 - val_accuracy: 0.8808\n",
      "Epoch 15/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3265 - accuracy: 0.9009 - val_loss: 0.3654 - val_accuracy: 0.8808\n",
      "Epoch 16/30\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3252 - accuracy: 0.9009 - val_loss: 0.3653 - val_accuracy: 0.8808\n",
      "Epoch 17/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.9009 - val_loss: 0.3655 - val_accuracy: 0.8808\n",
      "Epoch 18/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3238 - accuracy: 0.9009 - val_loss: 0.3658 - val_accuracy: 0.8808\n",
      "Epoch 19/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3235 - accuracy: 0.9009 - val_loss: 0.3661 - val_accuracy: 0.8808\n",
      "Epoch 20/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3233 - accuracy: 0.9009 - val_loss: 0.3663 - val_accuracy: 0.8808\n",
      "Epoch 21/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3232 - accuracy: 0.9009 - val_loss: 0.3666 - val_accuracy: 0.8808\n",
      "Epoch 22/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.9009 - val_loss: 0.3668 - val_accuracy: 0.8808\n",
      "Epoch 23/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.9009 - val_loss: 0.3670 - val_accuracy: 0.8808\n",
      "Epoch 24/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.9009 - val_loss: 0.3671 - val_accuracy: 0.8808\n",
      "Epoch 25/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.9009 - val_loss: 0.3672 - val_accuracy: 0.8808\n",
      "Epoch 26/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.9009 - val_loss: 0.3672 - val_accuracy: 0.8808\n",
      "Epoch 27/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.9009 - val_loss: 0.3672 - val_accuracy: 0.8808\n",
      "Epoch 28/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3230 - accuracy: 0.9009 - val_loss: 0.3673 - val_accuracy: 0.8808\n",
      "Epoch 29/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3230 - accuracy: 0.9009 - val_loss: 0.3674 - val_accuracy: 0.8808\n",
      "Epoch 30/30\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.9009 - val_loss: 0.3675 - val_accuracy: 0.8808\n",
      "Fold 3, Best Validation Loss: 0.3653412461280823, Best Validation Accuracy: 0.8808000087738037\n",
      "Epoch 1/30\n",
      "313/313 [==============================] - 3s 6ms/step - loss: 0.6374 - accuracy: 0.8959 - val_loss: 0.5924 - val_accuracy: 0.8764\n",
      "Epoch 2/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5461 - accuracy: 0.8959 - val_loss: 0.5205 - val_accuracy: 0.8764\n",
      "Epoch 3/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4803 - accuracy: 0.8959 - val_loss: 0.4699 - val_accuracy: 0.8764\n",
      "Epoch 4/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4337 - accuracy: 0.8959 - val_loss: 0.4351 - val_accuracy: 0.8764\n",
      "Epoch 5/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4010 - accuracy: 0.8959 - val_loss: 0.4116 - val_accuracy: 0.8764\n",
      "Epoch 6/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3782 - accuracy: 0.8959 - val_loss: 0.3959 - val_accuracy: 0.8764\n",
      "Epoch 7/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3625 - accuracy: 0.8959 - val_loss: 0.3860 - val_accuracy: 0.8764\n",
      "Epoch 8/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3519 - accuracy: 0.8959 - val_loss: 0.3799 - val_accuracy: 0.8764\n",
      "Epoch 9/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3450 - accuracy: 0.8959 - val_loss: 0.3765 - val_accuracy: 0.8764\n",
      "Epoch 10/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3405 - accuracy: 0.8959 - val_loss: 0.3748 - val_accuracy: 0.8764\n",
      "Epoch 11/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3377 - accuracy: 0.8959 - val_loss: 0.3741 - val_accuracy: 0.8764\n",
      "Epoch 12/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3360 - accuracy: 0.8959 - val_loss: 0.3741 - val_accuracy: 0.8764\n",
      "Epoch 13/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3350 - accuracy: 0.8959 - val_loss: 0.3743 - val_accuracy: 0.8764\n",
      "Epoch 14/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3345 - accuracy: 0.8959 - val_loss: 0.3747 - val_accuracy: 0.8764\n",
      "Epoch 15/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3342 - accuracy: 0.8959 - val_loss: 0.3750 - val_accuracy: 0.8764\n",
      "Epoch 16/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3341 - accuracy: 0.8959 - val_loss: 0.3754 - val_accuracy: 0.8764\n",
      "Epoch 17/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3341 - accuracy: 0.8959 - val_loss: 0.3755 - val_accuracy: 0.8764\n",
      "Epoch 18/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3757 - val_accuracy: 0.8764\n",
      "Epoch 19/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3758 - val_accuracy: 0.8764\n",
      "Epoch 20/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3758 - val_accuracy: 0.8764\n",
      "Epoch 21/30\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3759 - val_accuracy: 0.8764\n",
      "Epoch 22/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3759 - val_accuracy: 0.8764\n",
      "Epoch 23/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3760 - val_accuracy: 0.8764\n",
      "Epoch 24/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3759 - val_accuracy: 0.8764\n",
      "Epoch 25/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3759 - val_accuracy: 0.8764\n",
      "Epoch 26/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3760 - val_accuracy: 0.8764\n",
      "Epoch 27/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3760 - val_accuracy: 0.8764\n",
      "Epoch 28/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3760 - val_accuracy: 0.8764\n",
      "Epoch 29/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3761 - val_accuracy: 0.8764\n",
      "Epoch 30/30\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8959 - val_loss: 0.3759 - val_accuracy: 0.8764\n",
      "Fold 4, Best Validation Loss: 0.3740662932395935, Best Validation Accuracy: 0.8763999938964844\n",
      "Epoch 1/30\n",
      "391/391 [==============================] - 4s 6ms/step - loss: 0.6254 - accuracy: 0.8920 - val_loss: 0.5475 - val_accuracy: 0.9424\n",
      "Epoch 2/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.5212 - accuracy: 0.8920 - val_loss: 0.4475 - val_accuracy: 0.9424\n",
      "Epoch 3/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.4530 - accuracy: 0.8920 - val_loss: 0.3796 - val_accuracy: 0.9424\n",
      "Epoch 4/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.4093 - accuracy: 0.8920 - val_loss: 0.3330 - val_accuracy: 0.9424\n",
      "Epoch 5/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3818 - accuracy: 0.8920 - val_loss: 0.3014 - val_accuracy: 0.9424\n",
      "Epoch 6/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3647 - accuracy: 0.8920 - val_loss: 0.2796 - val_accuracy: 0.9424\n",
      "Epoch 7/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3544 - accuracy: 0.8920 - val_loss: 0.2646 - val_accuracy: 0.9424\n",
      "Epoch 8/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3486 - accuracy: 0.8920 - val_loss: 0.2547 - val_accuracy: 0.9424\n",
      "Epoch 9/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3453 - accuracy: 0.8920 - val_loss: 0.2479 - val_accuracy: 0.9424\n",
      "Epoch 10/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3436 - accuracy: 0.8920 - val_loss: 0.2431 - val_accuracy: 0.9424\n",
      "Epoch 11/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3429 - accuracy: 0.8920 - val_loss: 0.2404 - val_accuracy: 0.9424\n",
      "Epoch 12/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3425 - accuracy: 0.8920 - val_loss: 0.2384 - val_accuracy: 0.9424\n",
      "Epoch 13/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3424 - accuracy: 0.8920 - val_loss: 0.2373 - val_accuracy: 0.9424\n",
      "Epoch 14/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3424 - accuracy: 0.8920 - val_loss: 0.2367 - val_accuracy: 0.9424\n",
      "Epoch 15/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2363 - val_accuracy: 0.9424\n",
      "Epoch 16/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2361 - val_accuracy: 0.9424\n",
      "Epoch 17/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2360 - val_accuracy: 0.9424\n",
      "Epoch 18/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2360 - val_accuracy: 0.9424\n",
      "Epoch 19/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2357 - val_accuracy: 0.9424\n",
      "Epoch 20/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2359 - val_accuracy: 0.9424\n",
      "Epoch 21/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2359 - val_accuracy: 0.9424\n",
      "Epoch 22/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2359 - val_accuracy: 0.9424\n",
      "Epoch 23/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2359 - val_accuracy: 0.9424\n",
      "Epoch 24/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2357 - val_accuracy: 0.9424\n",
      "Epoch 25/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2358 - val_accuracy: 0.9424\n",
      "Epoch 26/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2361 - val_accuracy: 0.9424\n",
      "Epoch 27/30\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2359 - val_accuracy: 0.9424\n",
      "Epoch 28/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2359 - val_accuracy: 0.9424\n",
      "Epoch 29/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2359 - val_accuracy: 0.9424\n",
      "Epoch 30/30\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3423 - accuracy: 0.8920 - val_loss: 0.2359 - val_accuracy: 0.9424\n",
      "Fold 5, Best Validation Loss: 0.23566029965877533, Best Validation Accuracy: 0.9423999786376953\n",
      "Mean Best Validation Loss: 0.3154489308595657\n",
      "Mean Best Validation Accuracy: 0.9099999904632569\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5256 - accuracy: 0.9000 - val_loss: 0.5860 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5805 - accuracy: 0.9000 - val_loss: 0.4962 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5037 - accuracy: 0.8000 - val_loss: 0.4278 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4193 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3027 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3446 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2660 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1805 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1729 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Fold 1, Best Validation Loss: 0.0032817283645272255, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7316 - accuracy: 0.5000 - val_loss: 0.5627 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6014 - accuracy: 0.7500 - val_loss: 0.4529 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5825 - accuracy: 0.8125 - val_loss: 0.3882 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4531 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3936 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3876 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2794 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2329 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1683 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1631 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1087 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1253 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Fold 2, Best Validation Loss: 0.002845318289473653, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7906 - accuracy: 0.2727 - val_loss: 0.6052 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7006 - accuracy: 0.4545 - val_loss: 0.5194 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5886 - accuracy: 0.7727 - val_loss: 0.4476 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4837 - accuracy: 0.8636 - val_loss: 0.3903 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3561 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3772 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3722 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3257 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2827 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2243 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1845 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1690 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1513 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1472 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1300 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Fold 3, Best Validation Loss: 0.005508506204932928, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8904 - accuracy: 0.2143 - val_loss: 0.5724 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7429 - accuracy: 0.3929 - val_loss: 0.5731 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7621 - accuracy: 0.4643 - val_loss: 0.5801 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5912 - accuracy: 0.7857 - val_loss: 0.5865 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5518 - accuracy: 0.6786 - val_loss: 0.5916 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4126 - accuracy: 0.9286 - val_loss: 0.6021 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3859 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2885 - accuracy: 1.0000 - val_loss: 0.6310 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2426 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2231 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1618 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1548 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1561 - accuracy: 1.0000 - val_loss: 0.7698 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1031 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.8417 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.8797 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.9178 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.9922 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 1.0276 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.0619 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.0955 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.1280 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.1908 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.2211 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.2512 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2803 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3089 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.3365 - val_accuracy: 0.5000\n",
      "Fold 4, Best Validation Loss: 0.5723859071731567, Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 2s 265ms/step - loss: 0.7425 - accuracy: 0.5000 - val_loss: 0.6167 - val_accuracy: 0.8333\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6380 - accuracy: 0.6765 - val_loss: 0.5200 - val_accuracy: 0.8333\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5234 - accuracy: 0.8235 - val_loss: 0.4750 - val_accuracy: 0.8333\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4669 - accuracy: 0.8529 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3995 - accuracy: 0.9118 - val_loss: 0.4324 - val_accuracy: 0.8333\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3198 - accuracy: 0.9412 - val_loss: 0.4219 - val_accuracy: 0.8333\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2531 - accuracy: 0.9412 - val_loss: 0.4025 - val_accuracy: 0.8333\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2142 - accuracy: 0.9118 - val_loss: 0.3319 - val_accuracy: 0.8333\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2601 - accuracy: 0.9118 - val_loss: 0.2218 - val_accuracy: 0.8333\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1555 - accuracy: 0.9412 - val_loss: 0.1699 - val_accuracy: 0.8333\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1960 - accuracy: 0.9706 - val_loss: 0.1406 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1191 - accuracy: 0.9706 - val_loss: 0.1197 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1155 - accuracy: 0.9706 - val_loss: 0.1056 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1023 - accuracy: 0.9412 - val_loss: 0.0949 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0997 - accuracy: 0.9412 - val_loss: 0.0855 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1119 - accuracy: 0.9706 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Fold 5, Best Validation Loss: 0.014963244087994099, Best Validation Accuracy: 1.0\n",
      "Mean Best Validation Loss: 0.11979694082401693\n",
      "Mean Best Validation Accuracy: 1.0\n",
      "Epoch 1/30\n",
      "99/99 [==============================] - 2s 8ms/step - loss: 0.6882 - accuracy: 0.6349 - val_loss: 0.7125 - val_accuracy: 0.2623\n",
      "Epoch 2/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6793 - accuracy: 0.6349 - val_loss: 0.7320 - val_accuracy: 0.2623\n",
      "Epoch 3/30\n",
      "99/99 [==============================] - 1s 8ms/step - loss: 0.6726 - accuracy: 0.6349 - val_loss: 0.7506 - val_accuracy: 0.2623\n",
      "Epoch 4/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6676 - accuracy: 0.6349 - val_loss: 0.7675 - val_accuracy: 0.2623\n",
      "Epoch 5/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6640 - accuracy: 0.6349 - val_loss: 0.7829 - val_accuracy: 0.2623\n",
      "Epoch 6/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6615 - accuracy: 0.6349 - val_loss: 0.7968 - val_accuracy: 0.2623\n",
      "Epoch 7/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6598 - accuracy: 0.6349 - val_loss: 0.8080 - val_accuracy: 0.2623\n",
      "Epoch 8/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6587 - accuracy: 0.6349 - val_loss: 0.8171 - val_accuracy: 0.2623\n",
      "Epoch 9/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6578 - accuracy: 0.6349 - val_loss: 0.8256 - val_accuracy: 0.2623\n",
      "Epoch 10/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6573 - accuracy: 0.6349 - val_loss: 0.8327 - val_accuracy: 0.2623\n",
      "Epoch 11/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6569 - accuracy: 0.6349 - val_loss: 0.8392 - val_accuracy: 0.2623\n",
      "Epoch 12/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6567 - accuracy: 0.6349 - val_loss: 0.8434 - val_accuracy: 0.2623\n",
      "Epoch 13/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6566 - accuracy: 0.6349 - val_loss: 0.8484 - val_accuracy: 0.2623\n",
      "Epoch 14/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6565 - accuracy: 0.6349 - val_loss: 0.8503 - val_accuracy: 0.2623\n",
      "Epoch 15/30\n",
      "99/99 [==============================] - 1s 8ms/step - loss: 0.6564 - accuracy: 0.6349 - val_loss: 0.8530 - val_accuracy: 0.2623\n",
      "Epoch 16/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6564 - accuracy: 0.6349 - val_loss: 0.8542 - val_accuracy: 0.2623\n",
      "Epoch 17/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6564 - accuracy: 0.6349 - val_loss: 0.8568 - val_accuracy: 0.2623\n",
      "Epoch 18/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6564 - accuracy: 0.6349 - val_loss: 0.8580 - val_accuracy: 0.2623\n",
      "Epoch 19/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6564 - accuracy: 0.6349 - val_loss: 0.8578 - val_accuracy: 0.2623\n",
      "Epoch 20/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8582 - val_accuracy: 0.2623\n",
      "Epoch 21/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6564 - accuracy: 0.6349 - val_loss: 0.8604 - val_accuracy: 0.2623\n",
      "Epoch 22/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8602 - val_accuracy: 0.2623\n",
      "Epoch 23/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8600 - val_accuracy: 0.2623\n",
      "Epoch 24/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8602 - val_accuracy: 0.2623\n",
      "Epoch 25/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8605 - val_accuracy: 0.2623\n",
      "Epoch 26/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8623 - val_accuracy: 0.2623\n",
      "Epoch 27/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8614 - val_accuracy: 0.2623\n",
      "Epoch 28/30\n",
      "99/99 [==============================] - 1s 7ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8618 - val_accuracy: 0.2623\n",
      "Epoch 29/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8615 - val_accuracy: 0.2623\n",
      "Epoch 30/30\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6563 - accuracy: 0.6349 - val_loss: 0.8610 - val_accuracy: 0.2623\n",
      "Fold 1, Best Validation Loss: 0.7124987840652466, Best Validation Accuracy: 0.2623211443424225\n",
      "Epoch 1/30\n",
      "197/197 [==============================] - 3s 6ms/step - loss: 0.6914 - accuracy: 0.5487 - val_loss: 0.6838 - val_accuracy: 0.6305\n",
      "Epoch 2/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6892 - accuracy: 0.5512 - val_loss: 0.6783 - val_accuracy: 0.6305\n",
      "Epoch 3/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6884 - accuracy: 0.5512 - val_loss: 0.6754 - val_accuracy: 0.6305\n",
      "Epoch 4/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6881 - accuracy: 0.5512 - val_loss: 0.6740 - val_accuracy: 0.6305\n",
      "Epoch 5/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6729 - val_accuracy: 0.6305\n",
      "Epoch 6/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6723 - val_accuracy: 0.6305\n",
      "Epoch 7/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6719 - val_accuracy: 0.6305\n",
      "Epoch 8/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6719 - val_accuracy: 0.6305\n",
      "Epoch 9/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6719 - val_accuracy: 0.6305\n",
      "Epoch 10/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6716 - val_accuracy: 0.6305\n",
      "Epoch 11/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6713 - val_accuracy: 0.6305\n",
      "Epoch 12/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6716 - val_accuracy: 0.6305\n",
      "Epoch 13/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6713 - val_accuracy: 0.6305\n",
      "Epoch 14/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6714 - val_accuracy: 0.6305\n",
      "Epoch 15/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6716 - val_accuracy: 0.6305\n",
      "Epoch 16/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6717 - val_accuracy: 0.6305\n",
      "Epoch 17/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6714 - val_accuracy: 0.6305\n",
      "Epoch 18/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6715 - val_accuracy: 0.6305\n",
      "Epoch 19/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6716 - val_accuracy: 0.6305\n",
      "Epoch 20/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6716 - val_accuracy: 0.6305\n",
      "Epoch 21/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6719 - val_accuracy: 0.6305\n",
      "Epoch 22/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6718 - val_accuracy: 0.6305\n",
      "Epoch 23/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6719 - val_accuracy: 0.6305\n",
      "Epoch 24/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6715 - val_accuracy: 0.6305\n",
      "Epoch 25/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6716 - val_accuracy: 0.6305\n",
      "Epoch 26/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6718 - val_accuracy: 0.6305\n",
      "Epoch 27/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6717 - val_accuracy: 0.6305\n",
      "Epoch 28/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6719 - val_accuracy: 0.6305\n",
      "Epoch 29/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6880 - accuracy: 0.5512 - val_loss: 0.6716 - val_accuracy: 0.6305\n",
      "Epoch 30/30\n",
      "197/197 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.6715 - val_accuracy: 0.6305\n",
      "Fold 2, Best Validation Loss: 0.6713356971740723, Best Validation Accuracy: 0.6305246353149414\n",
      "Epoch 1/30\n",
      "295/295 [==============================] - 3s 6ms/step - loss: 0.6876 - accuracy: 0.5764 - val_loss: 0.6427 - val_accuracy: 0.8369\n",
      "Epoch 2/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6826 - accuracy: 0.5776 - val_loss: 0.6198 - val_accuracy: 0.8369\n",
      "Epoch 3/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6814 - accuracy: 0.5776 - val_loss: 0.6082 - val_accuracy: 0.8369\n",
      "Epoch 4/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6041 - val_accuracy: 0.8369\n",
      "Epoch 5/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6022 - val_accuracy: 0.8369\n",
      "Epoch 6/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6005 - val_accuracy: 0.8369\n",
      "Epoch 7/30\n",
      "295/295 [==============================] - 2s 6ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6001 - val_accuracy: 0.8369\n",
      "Epoch 8/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6015 - val_accuracy: 0.8369\n",
      "Epoch 9/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6007 - val_accuracy: 0.8369\n",
      "Epoch 10/30\n",
      "295/295 [==============================] - 2s 6ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5988 - val_accuracy: 0.8369\n",
      "Epoch 11/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5996 - val_accuracy: 0.8369\n",
      "Epoch 12/30\n",
      "295/295 [==============================] - 2s 6ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5995 - val_accuracy: 0.8369\n",
      "Epoch 13/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5991 - val_accuracy: 0.8369\n",
      "Epoch 14/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5995 - val_accuracy: 0.8369\n",
      "Epoch 15/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6000 - val_accuracy: 0.8369\n",
      "Epoch 16/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6001 - val_accuracy: 0.8369\n",
      "Epoch 17/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5992 - val_accuracy: 0.8369\n",
      "Epoch 18/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5994 - val_accuracy: 0.8369\n",
      "Epoch 19/30\n",
      "295/295 [==============================] - 2s 6ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6003 - val_accuracy: 0.8369\n",
      "Epoch 20/30\n",
      "295/295 [==============================] - 2s 6ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6007 - val_accuracy: 0.8369\n",
      "Epoch 21/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.6005 - val_accuracy: 0.8369\n",
      "Epoch 22/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5997 - val_accuracy: 0.8369\n",
      "Epoch 23/30\n",
      "295/295 [==============================] - 3s 9ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5991 - val_accuracy: 0.8369\n",
      "Epoch 24/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5996 - val_accuracy: 0.8369\n",
      "Epoch 25/30\n",
      "295/295 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5996 - val_accuracy: 0.8369\n",
      "Epoch 26/30\n",
      "295/295 [==============================] - 2s 6ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5984 - val_accuracy: 0.8369\n",
      "Epoch 27/30\n",
      "295/295 [==============================] - 130s 441ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5979 - val_accuracy: 0.8369\n",
      "Epoch 28/30\n",
      "295/295 [==============================] - 2s 8ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5988 - val_accuracy: 0.8369\n",
      "Epoch 29/30\n",
      "295/295 [==============================] - 2s 8ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5996 - val_accuracy: 0.8369\n",
      "Epoch 30/30\n",
      "295/295 [==============================] - 3s 9ms/step - loss: 0.6811 - accuracy: 0.5776 - val_loss: 0.5995 - val_accuracy: 0.8369\n",
      "Fold 3, Best Validation Loss: 0.5979485511779785, Best Validation Accuracy: 0.8368839621543884\n",
      "Epoch 1/30\n",
      "394/394 [==============================] - 5s 7ms/step - loss: 0.6759 - accuracy: 0.6415 - val_loss: 0.6377 - val_accuracy: 0.7358\n",
      "Epoch 2/30\n",
      "394/394 [==============================] - 3s 7ms/step - loss: 0.6580 - accuracy: 0.6424 - val_loss: 0.6134 - val_accuracy: 0.7358\n",
      "Epoch 3/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6532 - accuracy: 0.6424 - val_loss: 0.6038 - val_accuracy: 0.7358\n",
      "Epoch 4/30\n",
      "394/394 [==============================] - 3s 8ms/step - loss: 0.6523 - accuracy: 0.6424 - val_loss: 0.5995 - val_accuracy: 0.7358\n",
      "Epoch 5/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6521 - accuracy: 0.6424 - val_loss: 0.5982 - val_accuracy: 0.7358\n",
      "Epoch 6/30\n",
      "394/394 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5975 - val_accuracy: 0.7358\n",
      "Epoch 7/30\n",
      "394/394 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5976 - val_accuracy: 0.7358\n",
      "Epoch 8/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5974 - val_accuracy: 0.7358\n",
      "Epoch 9/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5972 - val_accuracy: 0.7358\n",
      "Epoch 10/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5972 - val_accuracy: 0.7358\n",
      "Epoch 11/30\n",
      "394/394 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5965 - val_accuracy: 0.7358\n",
      "Epoch 12/30\n",
      "394/394 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5971 - val_accuracy: 0.7358\n",
      "Epoch 13/30\n",
      "394/394 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5975 - val_accuracy: 0.7358\n",
      "Epoch 14/30\n",
      "394/394 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5976 - val_accuracy: 0.7358\n",
      "Epoch 15/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5981 - val_accuracy: 0.7358\n",
      "Epoch 16/30\n",
      "394/394 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5975 - val_accuracy: 0.7358\n",
      "Epoch 17/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5981 - val_accuracy: 0.7358\n",
      "Epoch 18/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5970 - val_accuracy: 0.7358\n",
      "Epoch 19/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5972 - val_accuracy: 0.7358\n",
      "Epoch 20/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5967 - val_accuracy: 0.7358\n",
      "Epoch 21/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6521 - accuracy: 0.6424 - val_loss: 0.5968 - val_accuracy: 0.7358\n",
      "Epoch 22/30\n",
      "394/394 [==============================] - 2s 5ms/step - loss: 0.6521 - accuracy: 0.6424 - val_loss: 0.5969 - val_accuracy: 0.7358\n",
      "Epoch 23/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5969 - val_accuracy: 0.7358\n",
      "Epoch 24/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5971 - val_accuracy: 0.7358\n",
      "Epoch 25/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5977 - val_accuracy: 0.7358\n",
      "Epoch 26/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5974 - val_accuracy: 0.7358\n",
      "Epoch 27/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5975 - val_accuracy: 0.7358\n",
      "Epoch 28/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6521 - accuracy: 0.6424 - val_loss: 0.5974 - val_accuracy: 0.7358\n",
      "Epoch 29/30\n",
      "394/394 [==============================] - 2s 6ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5977 - val_accuracy: 0.7358\n",
      "Epoch 30/30\n",
      "394/394 [==============================] - 3s 8ms/step - loss: 0.6520 - accuracy: 0.6424 - val_loss: 0.5976 - val_accuracy: 0.7358\n",
      "Fold 4, Best Validation Loss: 0.5965054631233215, Best Validation Accuracy: 0.7357710599899292\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 6ms/step - loss: 0.6671 - accuracy: 0.6610 - val_loss: 0.6629 - val_accuracy: 0.6283\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6453 - accuracy: 0.6611 - val_loss: 0.6599 - val_accuracy: 0.6283\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6410 - accuracy: 0.6611 - val_loss: 0.6612 - val_accuracy: 0.6283\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6404 - accuracy: 0.6611 - val_loss: 0.6619 - val_accuracy: 0.6283\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6619 - val_accuracy: 0.6283\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6622 - val_accuracy: 0.6283\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6622 - val_accuracy: 0.6283\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6623 - val_accuracy: 0.6283\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6622 - val_accuracy: 0.6283\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6621 - val_accuracy: 0.6283\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6622 - val_accuracy: 0.6283\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6625 - val_accuracy: 0.6283\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6624 - val_accuracy: 0.6283\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6623 - val_accuracy: 0.6283\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6621 - val_accuracy: 0.6283\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6623 - val_accuracy: 0.6283\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6627 - val_accuracy: 0.6283\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6404 - accuracy: 0.6611 - val_loss: 0.6624 - val_accuracy: 0.6283\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6622 - val_accuracy: 0.6283\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6622 - val_accuracy: 0.6283\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6627 - val_accuracy: 0.6283\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6625 - val_accuracy: 0.6283\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6623 - val_accuracy: 0.6283\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6621 - val_accuracy: 0.6283\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6623 - val_accuracy: 0.6283\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6622 - val_accuracy: 0.6283\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6621 - val_accuracy: 0.6283\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6622 - val_accuracy: 0.6283\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6622 - val_accuracy: 0.6283\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6611 - val_loss: 0.6621 - val_accuracy: 0.6283\n",
      "Fold 5, Best Validation Loss: 0.6599366664886475, Best Validation Accuracy: 0.6282988786697388\n",
      "Mean Best Validation Loss: 0.6476450324058532\n",
      "Mean Best Validation Accuracy: 0.618759936094284\n",
      "Epoch 1/30\n",
      "163/163 [==============================] - 3s 8ms/step - loss: 0.3447 - accuracy: 0.8842 - val_loss: 0.2960 - val_accuracy: 0.8805\n",
      "Epoch 2/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2786 - accuracy: 0.8980 - val_loss: 0.3767 - val_accuracy: 0.7723\n",
      "Epoch 3/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2422 - accuracy: 0.9013 - val_loss: 0.4124 - val_accuracy: 0.7342\n",
      "Epoch 4/30\n",
      "163/163 [==============================] - 1s 7ms/step - loss: 0.2333 - accuracy: 0.9042 - val_loss: 0.3827 - val_accuracy: 0.7763\n",
      "Epoch 5/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2245 - accuracy: 0.9046 - val_loss: 0.3842 - val_accuracy: 0.7700\n",
      "Epoch 6/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2236 - accuracy: 0.9076 - val_loss: 0.3897 - val_accuracy: 0.7715\n",
      "Epoch 7/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2209 - accuracy: 0.9065 - val_loss: 0.4486 - val_accuracy: 0.6914\n",
      "Epoch 8/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2225 - accuracy: 0.9078 - val_loss: 0.4125 - val_accuracy: 0.7193\n",
      "Epoch 9/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2174 - accuracy: 0.9140 - val_loss: 0.3794 - val_accuracy: 0.7838\n",
      "Epoch 10/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2138 - accuracy: 0.9090 - val_loss: 0.3946 - val_accuracy: 0.7412\n",
      "Epoch 11/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2052 - accuracy: 0.9095 - val_loss: 0.4660 - val_accuracy: 0.6797\n",
      "Epoch 12/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2064 - accuracy: 0.9118 - val_loss: 0.3339 - val_accuracy: 0.8576\n",
      "Epoch 13/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2043 - accuracy: 0.9078 - val_loss: 0.4338 - val_accuracy: 0.7531\n",
      "Epoch 14/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2102 - accuracy: 0.9092 - val_loss: 0.3854 - val_accuracy: 0.7938\n",
      "Epoch 15/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2021 - accuracy: 0.9155 - val_loss: 0.4021 - val_accuracy: 0.7871\n",
      "Epoch 16/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2037 - accuracy: 0.9124 - val_loss: 0.3978 - val_accuracy: 0.8121\n",
      "Epoch 17/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2050 - accuracy: 0.9105 - val_loss: 0.3804 - val_accuracy: 0.8090\n",
      "Epoch 18/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1951 - accuracy: 0.9153 - val_loss: 0.4196 - val_accuracy: 0.7625\n",
      "Epoch 19/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1938 - accuracy: 0.9111 - val_loss: 0.3613 - val_accuracy: 0.8301\n",
      "Epoch 20/30\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.1879 - accuracy: 0.9191 - val_loss: 0.3991 - val_accuracy: 0.7971\n",
      "Epoch 21/30\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.1940 - accuracy: 0.9199 - val_loss: 0.3987 - val_accuracy: 0.8013\n",
      "Epoch 22/30\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.1928 - accuracy: 0.9165 - val_loss: 0.3513 - val_accuracy: 0.8347\n",
      "Epoch 23/30\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.1873 - accuracy: 0.9199 - val_loss: 0.4134 - val_accuracy: 0.7900\n",
      "Epoch 24/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1898 - accuracy: 0.9243 - val_loss: 0.3953 - val_accuracy: 0.8115\n",
      "Epoch 25/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1935 - accuracy: 0.9163 - val_loss: 0.3983 - val_accuracy: 0.8080\n",
      "Epoch 26/30\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.1877 - accuracy: 0.9218 - val_loss: 0.3741 - val_accuracy: 0.8290\n",
      "Epoch 27/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1929 - accuracy: 0.9205 - val_loss: 0.4045 - val_accuracy: 0.7994\n",
      "Epoch 28/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1893 - accuracy: 0.9168 - val_loss: 0.3970 - val_accuracy: 0.7921\n",
      "Epoch 29/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1872 - accuracy: 0.9191 - val_loss: 0.4181 - val_accuracy: 0.7907\n",
      "Epoch 30/30\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1855 - accuracy: 0.9209 - val_loss: 0.4273 - val_accuracy: 0.7698\n",
      "Fold 1, Best Validation Loss: 0.2960318922996521, Best Validation Accuracy: 0.8804765343666077\n",
      "Epoch 1/30\n",
      "326/326 [==============================] - 15s 8ms/step - loss: 0.3164 - accuracy: 0.8979 - val_loss: 0.2776 - val_accuracy: 0.9247\n",
      "Epoch 2/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2767 - accuracy: 0.9018 - val_loss: 0.4555 - val_accuracy: 0.9178\n",
      "Epoch 3/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2651 - accuracy: 0.8998 - val_loss: 0.4338 - val_accuracy: 0.9131\n",
      "Epoch 4/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2590 - accuracy: 0.9029 - val_loss: 0.3470 - val_accuracy: 0.9074\n",
      "Epoch 5/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2468 - accuracy: 0.9044 - val_loss: 0.3415 - val_accuracy: 0.9074\n",
      "Epoch 6/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2432 - accuracy: 0.9068 - val_loss: 0.3854 - val_accuracy: 0.8901\n",
      "Epoch 7/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2415 - accuracy: 0.9042 - val_loss: 0.3314 - val_accuracy: 0.8995\n",
      "Epoch 8/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2377 - accuracy: 0.9049 - val_loss: 0.3474 - val_accuracy: 0.9101\n",
      "Epoch 9/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2341 - accuracy: 0.9095 - val_loss: 0.3306 - val_accuracy: 0.9080\n",
      "Epoch 10/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2368 - accuracy: 0.9092 - val_loss: 0.3268 - val_accuracy: 0.9189\n",
      "Epoch 11/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2319 - accuracy: 0.9094 - val_loss: 0.3352 - val_accuracy: 0.9101\n",
      "Epoch 12/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2306 - accuracy: 0.9110 - val_loss: 0.3607 - val_accuracy: 0.9141\n",
      "Epoch 13/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2325 - accuracy: 0.9098 - val_loss: 0.3602 - val_accuracy: 0.9074\n",
      "Epoch 14/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2294 - accuracy: 0.9099 - val_loss: 0.3382 - val_accuracy: 0.9047\n",
      "Epoch 15/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2305 - accuracy: 0.9097 - val_loss: 0.3632 - val_accuracy: 0.9105\n",
      "Epoch 16/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2252 - accuracy: 0.9115 - val_loss: 0.3237 - val_accuracy: 0.9106\n",
      "Epoch 17/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2275 - accuracy: 0.9124 - val_loss: 0.3499 - val_accuracy: 0.8970\n",
      "Epoch 18/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2280 - accuracy: 0.9108 - val_loss: 0.4003 - val_accuracy: 0.9060\n",
      "Epoch 19/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2228 - accuracy: 0.9105 - val_loss: 0.3564 - val_accuracy: 0.9099\n",
      "Epoch 20/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2212 - accuracy: 0.9122 - val_loss: 0.3903 - val_accuracy: 0.9060\n",
      "Epoch 21/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2243 - accuracy: 0.9128 - val_loss: 0.3433 - val_accuracy: 0.9047\n",
      "Epoch 22/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2242 - accuracy: 0.9114 - val_loss: 0.3714 - val_accuracy: 0.9003\n",
      "Epoch 23/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2242 - accuracy: 0.9109 - val_loss: 0.3255 - val_accuracy: 0.9156\n",
      "Epoch 24/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2222 - accuracy: 0.9114 - val_loss: 0.3916 - val_accuracy: 0.8995\n",
      "Epoch 25/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2217 - accuracy: 0.9118 - val_loss: 0.3603 - val_accuracy: 0.9024\n",
      "Epoch 26/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2221 - accuracy: 0.9121 - val_loss: 0.3375 - val_accuracy: 0.9116\n",
      "Epoch 27/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2221 - accuracy: 0.9143 - val_loss: 0.3385 - val_accuracy: 0.9130\n",
      "Epoch 28/30\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 0.2229 - accuracy: 0.9112 - val_loss: 0.3395 - val_accuracy: 0.9097\n",
      "Epoch 29/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2218 - accuracy: 0.9139 - val_loss: 0.3174 - val_accuracy: 0.9087\n",
      "Epoch 30/30\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 0.2182 - accuracy: 0.9136 - val_loss: 0.3095 - val_accuracy: 0.9114\n",
      "Fold 2, Best Validation Loss: 0.2775568664073944, Best Validation Accuracy: 0.924673318862915\n",
      "Epoch 1/30\n",
      "488/488 [==============================] - 5s 7ms/step - loss: 0.3055 - accuracy: 0.9037 - val_loss: 0.2774 - val_accuracy: 0.9389\n",
      "Epoch 2/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2693 - accuracy: 0.9091 - val_loss: 0.2538 - val_accuracy: 0.9389\n",
      "Epoch 3/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2534 - accuracy: 0.9092 - val_loss: 0.2227 - val_accuracy: 0.9389\n",
      "Epoch 4/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2430 - accuracy: 0.9091 - val_loss: 0.2081 - val_accuracy: 0.9324\n",
      "Epoch 5/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2408 - accuracy: 0.9087 - val_loss: 0.2035 - val_accuracy: 0.9387\n",
      "Epoch 6/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2383 - accuracy: 0.9089 - val_loss: 0.1957 - val_accuracy: 0.9406\n",
      "Epoch 7/30\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.2367 - accuracy: 0.9089 - val_loss: 0.2089 - val_accuracy: 0.9383\n",
      "Epoch 8/30\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.2361 - accuracy: 0.9098 - val_loss: 0.2622 - val_accuracy: 0.9097\n",
      "Epoch 9/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2327 - accuracy: 0.9103 - val_loss: 0.2165 - val_accuracy: 0.9349\n",
      "Epoch 10/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2320 - accuracy: 0.9082 - val_loss: 0.2090 - val_accuracy: 0.9354\n",
      "Epoch 11/30\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.2298 - accuracy: 0.9112 - val_loss: 0.1912 - val_accuracy: 0.9354\n",
      "Epoch 12/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2274 - accuracy: 0.9109 - val_loss: 0.2037 - val_accuracy: 0.9252\n",
      "Epoch 13/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2302 - accuracy: 0.9112 - val_loss: 0.2020 - val_accuracy: 0.9352\n",
      "Epoch 14/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2273 - accuracy: 0.9099 - val_loss: 0.2098 - val_accuracy: 0.9331\n",
      "Epoch 15/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2277 - accuracy: 0.9129 - val_loss: 0.1974 - val_accuracy: 0.9327\n",
      "Epoch 16/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2264 - accuracy: 0.9135 - val_loss: 0.1896 - val_accuracy: 0.9395\n",
      "Epoch 17/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2248 - accuracy: 0.9139 - val_loss: 0.2257 - val_accuracy: 0.9193\n",
      "Epoch 18/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2223 - accuracy: 0.9140 - val_loss: 0.2024 - val_accuracy: 0.9247\n",
      "Epoch 19/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2239 - accuracy: 0.9148 - val_loss: 0.2111 - val_accuracy: 0.9304\n",
      "Epoch 20/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2248 - accuracy: 0.9126 - val_loss: 0.2134 - val_accuracy: 0.9277\n",
      "Epoch 21/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2242 - accuracy: 0.9129 - val_loss: 0.1943 - val_accuracy: 0.9329\n",
      "Epoch 22/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2227 - accuracy: 0.9142 - val_loss: 0.2050 - val_accuracy: 0.9289\n",
      "Epoch 23/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2219 - accuracy: 0.9141 - val_loss: 0.2394 - val_accuracy: 0.9008\n",
      "Epoch 24/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2227 - accuracy: 0.9141 - val_loss: 0.2624 - val_accuracy: 0.8964\n",
      "Epoch 25/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2218 - accuracy: 0.9139 - val_loss: 0.2107 - val_accuracy: 0.9233\n",
      "Epoch 26/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2225 - accuracy: 0.9143 - val_loss: 0.2086 - val_accuracy: 0.9218\n",
      "Epoch 27/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2229 - accuracy: 0.9142 - val_loss: 0.2170 - val_accuracy: 0.9203\n",
      "Epoch 28/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2205 - accuracy: 0.9142 - val_loss: 0.2227 - val_accuracy: 0.9224\n",
      "Epoch 29/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2206 - accuracy: 0.9150 - val_loss: 0.2061 - val_accuracy: 0.9235\n",
      "Epoch 30/30\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.2193 - accuracy: 0.9146 - val_loss: 0.2237 - val_accuracy: 0.9141\n",
      "Fold 3, Best Validation Loss: 0.18964159488677979, Best Validation Accuracy: 0.9406226277351379\n",
      "Epoch 1/30\n",
      "651/651 [==============================] - 8s 10ms/step - loss: 0.2875 - accuracy: 0.9142 - val_loss: 0.3152 - val_accuracy: 0.8972\n",
      "Epoch 2/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2659 - accuracy: 0.9164 - val_loss: 0.2564 - val_accuracy: 0.8972\n",
      "Epoch 3/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2430 - accuracy: 0.9164 - val_loss: 0.2334 - val_accuracy: 0.8972\n",
      "Epoch 4/30\n",
      "651/651 [==============================] - 5s 8ms/step - loss: 0.2306 - accuracy: 0.9166 - val_loss: 0.2275 - val_accuracy: 0.8972\n",
      "Epoch 5/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2262 - accuracy: 0.9166 - val_loss: 0.2316 - val_accuracy: 0.8972\n",
      "Epoch 6/30\n",
      "651/651 [==============================] - 5s 8ms/step - loss: 0.2251 - accuracy: 0.9168 - val_loss: 0.2236 - val_accuracy: 0.8972\n",
      "Epoch 7/30\n",
      "651/651 [==============================] - 5s 8ms/step - loss: 0.2225 - accuracy: 0.9167 - val_loss: 0.2330 - val_accuracy: 0.8972\n",
      "Epoch 8/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2224 - accuracy: 0.9163 - val_loss: 0.2282 - val_accuracy: 0.8974\n",
      "Epoch 9/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2186 - accuracy: 0.9165 - val_loss: 0.2354 - val_accuracy: 0.8966\n",
      "Epoch 10/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2172 - accuracy: 0.9172 - val_loss: 0.2264 - val_accuracy: 0.8982\n",
      "Epoch 11/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2160 - accuracy: 0.9161 - val_loss: 0.2236 - val_accuracy: 0.8976\n",
      "Epoch 12/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2170 - accuracy: 0.9164 - val_loss: 0.2305 - val_accuracy: 0.8972\n",
      "Epoch 13/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2160 - accuracy: 0.9177 - val_loss: 0.2280 - val_accuracy: 0.8980\n",
      "Epoch 14/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2120 - accuracy: 0.9179 - val_loss: 0.2315 - val_accuracy: 0.8976\n",
      "Epoch 15/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2105 - accuracy: 0.9166 - val_loss: 0.2342 - val_accuracy: 0.8972\n",
      "Epoch 16/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2104 - accuracy: 0.9165 - val_loss: 0.2300 - val_accuracy: 0.8974\n",
      "Epoch 17/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2102 - accuracy: 0.9163 - val_loss: 0.2307 - val_accuracy: 0.8976\n",
      "Epoch 18/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2100 - accuracy: 0.9170 - val_loss: 0.2298 - val_accuracy: 0.8985\n",
      "Epoch 19/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2081 - accuracy: 0.9170 - val_loss: 0.2261 - val_accuracy: 0.8985\n",
      "Epoch 20/30\n",
      "651/651 [==============================] - 4s 7ms/step - loss: 0.2077 - accuracy: 0.9166 - val_loss: 0.2382 - val_accuracy: 0.8972\n",
      "Epoch 21/30\n",
      "651/651 [==============================] - 4s 7ms/step - loss: 0.2052 - accuracy: 0.9181 - val_loss: 0.2228 - val_accuracy: 0.9010\n",
      "Epoch 22/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2058 - accuracy: 0.9172 - val_loss: 0.2297 - val_accuracy: 0.8974\n",
      "Epoch 23/30\n",
      "651/651 [==============================] - 4s 7ms/step - loss: 0.2041 - accuracy: 0.9181 - val_loss: 0.2311 - val_accuracy: 0.8974\n",
      "Epoch 24/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2031 - accuracy: 0.9187 - val_loss: 0.2265 - val_accuracy: 0.8980\n",
      "Epoch 25/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2034 - accuracy: 0.9173 - val_loss: 0.2293 - val_accuracy: 0.8983\n",
      "Epoch 26/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2024 - accuracy: 0.9177 - val_loss: 0.2375 - val_accuracy: 0.8974\n",
      "Epoch 27/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2022 - accuracy: 0.9194 - val_loss: 0.2282 - val_accuracy: 0.8974\n",
      "Epoch 28/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.2007 - accuracy: 0.9182 - val_loss: 0.2322 - val_accuracy: 0.9005\n",
      "Epoch 29/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.1997 - accuracy: 0.9191 - val_loss: 0.2226 - val_accuracy: 0.9041\n",
      "Epoch 30/30\n",
      "651/651 [==============================] - 5s 7ms/step - loss: 0.1989 - accuracy: 0.9195 - val_loss: 0.2220 - val_accuracy: 0.9058\n",
      "Fold 4, Best Validation Loss: 0.22197039425373077, Best Validation Accuracy: 0.9058416485786438\n",
      "Epoch 1/30\n",
      "814/814 [==============================] - 8s 7ms/step - loss: 0.2867 - accuracy: 0.9114 - val_loss: 0.4063 - val_accuracy: 0.8367\n",
      "Epoch 2/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2474 - accuracy: 0.9125 - val_loss: 0.3632 - val_accuracy: 0.8367\n",
      "Epoch 3/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2437 - accuracy: 0.9126 - val_loss: 0.3480 - val_accuracy: 0.8367\n",
      "Epoch 4/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2359 - accuracy: 0.9126 - val_loss: 0.3889 - val_accuracy: 0.8367\n",
      "Epoch 5/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2303 - accuracy: 0.9126 - val_loss: 0.3894 - val_accuracy: 0.8367\n",
      "Epoch 6/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2285 - accuracy: 0.9125 - val_loss: 0.4142 - val_accuracy: 0.8367\n",
      "Epoch 7/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2264 - accuracy: 0.9133 - val_loss: 0.3942 - val_accuracy: 0.8367\n",
      "Epoch 8/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2245 - accuracy: 0.9136 - val_loss: 0.3748 - val_accuracy: 0.8367\n",
      "Epoch 9/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2231 - accuracy: 0.9129 - val_loss: 0.3344 - val_accuracy: 0.8367\n",
      "Epoch 10/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2204 - accuracy: 0.9126 - val_loss: 0.3224 - val_accuracy: 0.8367\n",
      "Epoch 11/30\n",
      "814/814 [==============================] - 5s 6ms/step - loss: 0.2187 - accuracy: 0.9135 - val_loss: 0.3943 - val_accuracy: 0.8374\n",
      "Epoch 12/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2182 - accuracy: 0.9140 - val_loss: 0.3506 - val_accuracy: 0.8378\n",
      "Epoch 13/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2162 - accuracy: 0.9135 - val_loss: 0.3523 - val_accuracy: 0.8392\n",
      "Epoch 14/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2146 - accuracy: 0.9135 - val_loss: 0.3609 - val_accuracy: 0.8370\n",
      "Epoch 15/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2136 - accuracy: 0.9142 - val_loss: 0.3230 - val_accuracy: 0.8457\n",
      "Epoch 16/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2131 - accuracy: 0.9136 - val_loss: 0.3207 - val_accuracy: 0.8430\n",
      "Epoch 17/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2142 - accuracy: 0.9132 - val_loss: 0.3203 - val_accuracy: 0.8374\n",
      "Epoch 18/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2133 - accuracy: 0.9139 - val_loss: 0.3234 - val_accuracy: 0.8369\n",
      "Epoch 19/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2115 - accuracy: 0.9145 - val_loss: 0.3534 - val_accuracy: 0.8370\n",
      "Epoch 20/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2102 - accuracy: 0.9137 - val_loss: 0.3384 - val_accuracy: 0.8370\n",
      "Epoch 21/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2101 - accuracy: 0.9142 - val_loss: 0.3089 - val_accuracy: 0.8405\n",
      "Epoch 22/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2079 - accuracy: 0.9140 - val_loss: 0.3251 - val_accuracy: 0.8376\n",
      "Epoch 23/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2106 - accuracy: 0.9143 - val_loss: 0.3504 - val_accuracy: 0.8449\n",
      "Epoch 24/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2083 - accuracy: 0.9143 - val_loss: 0.3229 - val_accuracy: 0.8436\n",
      "Epoch 25/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2065 - accuracy: 0.9145 - val_loss: 0.3301 - val_accuracy: 0.8401\n",
      "Epoch 26/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2087 - accuracy: 0.9138 - val_loss: 0.3460 - val_accuracy: 0.8392\n",
      "Epoch 27/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2090 - accuracy: 0.9132 - val_loss: 0.3110 - val_accuracy: 0.8407\n",
      "Epoch 28/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2057 - accuracy: 0.9157 - val_loss: 0.2910 - val_accuracy: 0.8420\n",
      "Epoch 29/30\n",
      "814/814 [==============================] - 5s 7ms/step - loss: 0.2061 - accuracy: 0.9133 - val_loss: 0.3086 - val_accuracy: 0.8413\n",
      "Epoch 30/30\n",
      "814/814 [==============================] - 6s 7ms/step - loss: 0.2066 - accuracy: 0.9147 - val_loss: 0.2888 - val_accuracy: 0.8422\n",
      "Fold 5, Best Validation Loss: 0.28879091143608093, Best Validation Accuracy: 0.8456956148147583\n",
      "Mean Best Validation Loss: 0.2547983318567276\n",
      "Mean Best Validation Accuracy: 0.8994619488716126\n"
     ]
    }
   ],
   "source": [
    "anomaly_rates = {}\n",
    "file_idx = 1\n",
    "error_log_file = \"transformer_error.txt\"\n",
    "size_name = (\"B\", \"KB\", \"MB\")\n",
    "for file in file_list:\n",
    "    X, y = npz_to_csv(file)\n",
    "    \n",
    "    # 파일 사이즈가 5MB 보다 큰 경우는 제외\n",
    "    file_size = os.path.getsize(file) \n",
    "    file_size_str = convert_size(file_size)\n",
    "    temp = file_size_str.split(' ')\n",
    "    if temp[1] not in size_name:\n",
    "        continue\n",
    "\n",
    "    if temp[1] == \"MB\" and float(temp[0]) > 5:\n",
    "        # print(temp, search_index)\n",
    "        continue\n",
    "    # print(file, file_size_str)\n",
    "\n",
    "    anomaly_rates[file_idx] = get_anomaly_rate(y)\n",
    "\n",
    "    # input shape 안맞는 오류 있음\n",
    "    try:\n",
    "        val_losses, val_accs = train_and_evaluate_transformer(X, y)\n",
    "        append_to_val_dict(file_idx, val_losses, val_accs)\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error occurred while processing file {file} (index {file_idx}): {e}\\n\"\n",
    "        print(error_message)  # 콘솔에 오류 메시지 출력\n",
    "        with open(error_log_file, 'a') as log_file:\n",
    "            log_file.write(error_message)\n",
    "    \n",
    "    \n",
    "    # val_losses, val_accs = train_and_evaluate_transformer(X, y)\n",
    "    # append_to_val_dict(file_idx, val_losses, val_accs)\n",
    "    file_idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_validation_metrics(val_losses, val_accs)\n",
    "# 기록된 dict를 토대로 각 데이터셋에 대해 for문을 돌리던 indexing을 통해(val_dict[idx]~~)\n",
    "# 접근하든 해서 plotting하는 함수입니다. loss 값과 accuracy값을 검증 fold마다 출력해줘요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([0.2686212360858917,\n",
       "  0.23416098952293396,\n",
       "  0.21588250994682312,\n",
       "  0.1619134098291397,\n",
       "  0.18443159759044647],\n",
       " [0.935153603553772,\n",
       "  0.9215016961097717,\n",
       "  0.9317406415939331,\n",
       "  0.9385665655136108,\n",
       "  0.935153603553772])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting 예시\n",
    "# plot_validation_metrics(val_dict[1][0], val_dict[1][1])\n",
    "plot_validation_metrics(val_dict[1][0], val_dict[1][1])\n",
    "val_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "13",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mval_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 13"
     ]
    }
   ],
   "source": [
    "val_dict[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"output_transformer.csv\"\n",
    "\n",
    "fieldnames = [\"Index\", \"val_losses\", \"val_accuracies\"]\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "    # 헤더 작성\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # 데이터 작성\n",
    "    for index, values in val_dict.items():\n",
    "        val_losses = \", \".join([f\"loss {loss}\" for loss in values[0]])\n",
    "        val_accuracies = \", \".join([f\"acc {acc}\" for acc in values[1]])\n",
    "        row = {\n",
    "            \"Index\": index,\n",
    "            \"val_losses\": val_losses,\n",
    "            \"val_accuracies\": val_accuracies\n",
    "        }\n",
    "        writer.writerow(row)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14187614619731903, 0.3102455139160156, 0.16044597327709198, 0.17473368346691132, 0.13264787197113037]\n",
      "[1.8566075563430786, 0.07231798022985458, 0.5649966597557068, 0.9236502647399902, 0.3806503415107727]\n",
      "[0.9585060477256775, 0.26275700330734253, 0.368999719619751, 0.27408382296562195, 0.36846688389778137]\n",
      "[0.2533828318119049, 0.6882942318916321, 0.23714391887187958, 0.17823408544063568, 0.2279973030090332]\n",
      "[2.9358259780565277e-05, 0.014573163352906704, 0.030070213600993156, 0.0008528577163815498, 0.02461107261478901]\n",
      "[0.5553788542747498, 0.07665827870368958, 0.022700773552060127, 0.0006071897805668414, 0.00064460578141734]\n"
     ]
    }
   ],
   "source": [
    "for a in val_dict:\n",
    "    print(val_dict[a][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ([0.2653536796569824,\n",
       "   0.3058878481388092,\n",
       "   0.3114842176437378,\n",
       "   0.31100961565971375,\n",
       "   0.35122957825660706],\n",
       "  [0.9397260546684265,\n",
       "   0.9089041352272034,\n",
       "   0.9061644077301025,\n",
       "   0.9063355922698975,\n",
       "   0.8878424763679504]),\n",
       " 2: ([0.21896110475063324,\n",
       "   0.11401791125535965,\n",
       "   0.11680148541927338,\n",
       "   0.08507449179887772,\n",
       "   0.23178640007972717],\n",
       "  [0.9230877757072449,\n",
       "   0.9712992906570435,\n",
       "   0.9633818864822388,\n",
       "   0.9691785573959351,\n",
       "   0.9459918141365051]),\n",
       " 3: ([3.7530465126037598,\n",
       "   0.9820264577865601,\n",
       "   0.01853722333908081,\n",
       "   0.0,\n",
       "   0.002259626053273678],\n",
       "  [0.5711835622787476, 0.8078902363777161, 0.9982847571372986, 1.0, 1.0]),\n",
       " 4: ([0.0, 0.0, 5.199674129486084, 2.3031206130981445, 1.214957356452942],\n",
       "  [1.0, 1.0, 0.6468067169189453, 0.0, 0.0]),\n",
       " 5: ([1.5942364931106567,\n",
       "   0.6909160614013672,\n",
       "   0.7174426913261414,\n",
       "   0.6847631335258484,\n",
       "   0.687296450138092],\n",
       "  [0.5645714402198792,\n",
       "   0.572857141494751,\n",
       "   0.43457141518592834,\n",
       "   0.538428544998169,\n",
       "   0.5881428718566895]),\n",
       " 6: ([0.003973831422626972,\n",
       "   0.8406974077224731,\n",
       "   0.0610114224255085,\n",
       "   0.07100562006235123,\n",
       "   0.3099687695503235],\n",
       "  [1.0,\n",
       "   0.7865168452262878,\n",
       "   0.9887640476226807,\n",
       "   0.9775280952453613,\n",
       "   0.8876404762268066]),\n",
       " 7: ([0.33654797077178955,\n",
       "   0.28520122170448303,\n",
       "   0.330249547958374,\n",
       "   0.320722371339798,\n",
       "   0.35346683859825134],\n",
       "  [0.8947156071662903,\n",
       "   0.9108511209487915,\n",
       "   0.8975393176078796,\n",
       "   0.9019765853881836,\n",
       "   0.8866478204727173]),\n",
       " 8: ([0.19605058431625366,\n",
       "   0.2585424482822418,\n",
       "   0.16138383746147156,\n",
       "   0.13185793161392212,\n",
       "   0.1624559760093689],\n",
       "  [0.9473684430122375,\n",
       "   0.9415204524993896,\n",
       "   0.9415204524993896,\n",
       "   0.9532163739204407,\n",
       "   0.9532163739204407]),\n",
       " 9: ([0.01978909969329834,\n",
       "   0.00022320880088955164,\n",
       "   0.011811699718236923,\n",
       "   9.590629633748904e-05,\n",
       "   5.62048917345237e-05],\n",
       "  [0.9939758777618408, 1.0, 0.9939758777618408, 1.0, 1.0]),\n",
       " 10: ([0.0,\n",
       "   0.0,\n",
       "   10.206899642944336,\n",
       "   0.00625260453671217,\n",
       "   8.362280641449615e-05],\n",
       "  [1.0, 1.0, 0.0, 1.0, 1.0]),\n",
       " 11: ([0.31753382086753845,\n",
       "   0.0152574572712183,\n",
       "   0.25290584564208984,\n",
       "   0.04844658076763153,\n",
       "   0.3398980498313904],\n",
       "  [0.8869102001190186,\n",
       "   0.9940639138221741,\n",
       "   0.9415525197982788,\n",
       "   0.983561635017395,\n",
       "   0.9170472025871277]),\n",
       " 12: ([0.45447805523872375,\n",
       "   0.007185763213783503,\n",
       "   0.3631117641925812,\n",
       "   0.08525202423334122,\n",
       "   0.3978498578071594],\n",
       "  [0.8666666746139526, 1.0, 0.8999999761581421, 1.0, 0.8999999761581421]),\n",
       " 13: ([0.11220529675483704,\n",
       "   0.05930931866168976,\n",
       "   0.09896817803382874,\n",
       "   0.04267233982682228,\n",
       "   0.06868850439786911],\n",
       "  [0.9762823581695557,\n",
       "   0.9897539615631104,\n",
       "   0.9797609448432922,\n",
       "   0.9936120510101318,\n",
       "   0.987160861492157]),\n",
       " 14: ([0.9265080094337463,\n",
       "   0.9879119396209717,\n",
       "   0.01692555658519268,\n",
       "   0.02498687244951725,\n",
       "   0.008925571106374264],\n",
       "  [0.8536585569381714, 0.7317073345184326, 1.0, 1.0, 1.0]),\n",
       " 15: ([0.08996643126010895,\n",
       "   0.0741073414683342,\n",
       "   0.0763164758682251,\n",
       "   0.05981149896979332,\n",
       "   0.04537136107683182],\n",
       "  [0.9706224799156189,\n",
       "   0.9706224799156189,\n",
       "   0.9709133505821228,\n",
       "   0.9738219976425171,\n",
       "   0.9808027744293213]),\n",
       " 16: ([0.29370737075805664,\n",
       "   0.3084694445133209,\n",
       "   0.3653412461280823,\n",
       "   0.3740662932395935,\n",
       "   0.23566029965877533],\n",
       "  [0.9423999786376953,\n",
       "   0.9079999923706055,\n",
       "   0.8808000087738037,\n",
       "   0.8763999938964844,\n",
       "   0.9423999786376953]),\n",
       " 17: ([0.0032817283645272255,\n",
       "   0.002845318289473653,\n",
       "   0.005508506204932928,\n",
       "   0.5723859071731567,\n",
       "   0.014963244087994099],\n",
       "  [1.0, 1.0, 1.0, 1.0, 1.0]),\n",
       " 18: ([0.7124987840652466,\n",
       "   0.6713356971740723,\n",
       "   0.5979485511779785,\n",
       "   0.5965054631233215,\n",
       "   0.6599366664886475],\n",
       "  [0.2623211443424225,\n",
       "   0.6305246353149414,\n",
       "   0.8368839621543884,\n",
       "   0.7357710599899292,\n",
       "   0.6282988786697388]),\n",
       " 19: ([0.2960318922996521,\n",
       "   0.2775568664073944,\n",
       "   0.18964159488677979,\n",
       "   0.22197039425373077,\n",
       "   0.28879091143608093],\n",
       "  [0.8804765343666077,\n",
       "   0.924673318862915,\n",
       "   0.9406226277351379,\n",
       "   0.9058416485786438,\n",
       "   0.8456956148147583])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "219/219 [==============================] - 6s 7ms/step - loss: 0.5102 - accuracy: 0.7756 - val_loss: 1.1809 - val_accuracy: 0.5440\n",
      "Epoch 2/30\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.8629 - val_loss: 1.2429 - val_accuracy: 0.5476\n",
      "Epoch 3/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3612 - accuracy: 0.8593 - val_loss: 1.9947 - val_accuracy: 0.5484\n",
      "Epoch 4/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.2889 - accuracy: 0.8923 - val_loss: 2.0305 - val_accuracy: 0.4950\n",
      "Epoch 5/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4423 - accuracy: 0.8024 - val_loss: 2.1525 - val_accuracy: 0.5183\n",
      "Epoch 6/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4046 - accuracy: 0.8144 - val_loss: 2.3551 - val_accuracy: 0.5254\n",
      "Epoch 7/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3832 - accuracy: 0.8311 - val_loss: 2.7182 - val_accuracy: 0.5317\n",
      "Epoch 8/30\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.3938 - accuracy: 0.8247 - val_loss: 1.5800 - val_accuracy: 0.5397\n",
      "Epoch 9/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4323 - accuracy: 0.7983 - val_loss: 2.1889 - val_accuracy: 0.5356\n",
      "Epoch 10/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3426 - accuracy: 0.8519 - val_loss: 3.0836 - val_accuracy: 0.5354\n",
      "Epoch 11/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3617 - accuracy: 0.8414 - val_loss: 2.8784 - val_accuracy: 0.5333\n",
      "Epoch 12/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3398 - accuracy: 0.8586 - val_loss: 3.2113 - val_accuracy: 0.5417\n",
      "Epoch 13/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3072 - accuracy: 0.8749 - val_loss: 3.5094 - val_accuracy: 0.5424\n",
      "Epoch 14/30\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.2876 - accuracy: 0.8827 - val_loss: 3.8197 - val_accuracy: 0.5474\n",
      "Epoch 15/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.2613 - accuracy: 0.8987 - val_loss: 4.5382 - val_accuracy: 0.5521\n",
      "Epoch 16/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.5229 - accuracy: 0.7359 - val_loss: 1.4590 - val_accuracy: 0.5460\n",
      "Epoch 17/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3940 - accuracy: 0.8221 - val_loss: 1.9393 - val_accuracy: 0.5480\n",
      "Epoch 18/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4719 - accuracy: 0.7749 - val_loss: 1.1015 - val_accuracy: 0.5411\n",
      "Epoch 19/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4969 - accuracy: 0.7541 - val_loss: 1.5143 - val_accuracy: 0.5333\n",
      "Epoch 20/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.4511 - accuracy: 0.7913 - val_loss: 1.3236 - val_accuracy: 0.5357\n",
      "Epoch 21/30\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.3823 - accuracy: 0.8464 - val_loss: 1.4667 - val_accuracy: 0.5537\n",
      "Epoch 22/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3645 - accuracy: 0.8596 - val_loss: 1.5512 - val_accuracy: 0.5504\n",
      "Epoch 23/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3536 - accuracy: 0.8540 - val_loss: 1.3838 - val_accuracy: 0.5466\n",
      "Epoch 24/30\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.3676 - accuracy: 0.8479 - val_loss: 1.2976 - val_accuracy: 0.5457\n",
      "Epoch 25/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3961 - accuracy: 0.8184 - val_loss: 1.7783 - val_accuracy: 0.5436\n",
      "Epoch 26/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3331 - accuracy: 0.8603 - val_loss: 1.9482 - val_accuracy: 0.5534\n",
      "Epoch 27/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3259 - accuracy: 0.8634 - val_loss: 2.0546 - val_accuracy: 0.5534\n",
      "Epoch 28/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3470 - accuracy: 0.8584 - val_loss: 1.5114 - val_accuracy: 0.5459\n",
      "Epoch 29/30\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.3530 - accuracy: 0.8534 - val_loss: 1.8983 - val_accuracy: 0.5486\n",
      "Epoch 30/30\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.3521 - accuracy: 0.8566 - val_loss: 1.5253 - val_accuracy: 0.5451\n",
      "Model saved to gru_model_fold_1.h5\n",
      "Fold 1, Best Validation Loss: 1.1014983654022217, Best Validation Accuracy: 0.5537142753601074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seyeong/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "438/438 [==============================] - 7s 7ms/step - loss: 0.6796 - accuracy: 0.5701 - val_loss: 0.7061 - val_accuracy: 0.4486\n",
      "Epoch 2/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6736 - accuracy: 0.5680 - val_loss: 0.7060 - val_accuracy: 0.4600\n",
      "Epoch 3/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6722 - accuracy: 0.5626 - val_loss: 0.6909 - val_accuracy: 0.5714\n",
      "Epoch 4/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6728 - accuracy: 0.5706 - val_loss: 0.7018 - val_accuracy: 0.5714\n",
      "Epoch 5/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6734 - accuracy: 0.5701 - val_loss: 0.6893 - val_accuracy: 0.5714\n",
      "Epoch 6/30\n",
      "438/438 [==============================] - 2s 5ms/step - loss: 0.6707 - accuracy: 0.5684 - val_loss: 0.7063 - val_accuracy: 0.5714\n",
      "Epoch 7/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6700 - accuracy: 0.5713 - val_loss: 0.7000 - val_accuracy: 0.5714\n",
      "Epoch 8/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6711 - accuracy: 0.5711 - val_loss: 0.7050 - val_accuracy: 0.5714\n",
      "Epoch 9/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6704 - accuracy: 0.5708 - val_loss: 0.7068 - val_accuracy: 0.5714\n",
      "Epoch 10/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6712 - accuracy: 0.5721 - val_loss: 0.6991 - val_accuracy: 0.5714\n",
      "Epoch 11/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6695 - accuracy: 0.5713 - val_loss: 0.6983 - val_accuracy: 0.5714\n",
      "Epoch 12/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6685 - accuracy: 0.5711 - val_loss: 0.7016 - val_accuracy: 0.5714\n",
      "Epoch 13/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6692 - accuracy: 0.5717 - val_loss: 0.7007 - val_accuracy: 0.5714\n",
      "Epoch 14/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6695 - accuracy: 0.5691 - val_loss: 0.7039 - val_accuracy: 0.5714\n",
      "Epoch 15/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6680 - accuracy: 0.5895 - val_loss: 0.7052 - val_accuracy: 0.5320\n",
      "Epoch 16/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6376 - accuracy: 0.6625 - val_loss: 0.7102 - val_accuracy: 0.5504\n",
      "Epoch 17/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6361 - accuracy: 0.6619 - val_loss: 0.7403 - val_accuracy: 0.5454\n",
      "Epoch 18/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6227 - accuracy: 0.6792 - val_loss: 0.7400 - val_accuracy: 0.5297\n",
      "Epoch 19/30\n",
      "438/438 [==============================] - 3s 7ms/step - loss: 0.6104 - accuracy: 0.6985 - val_loss: 0.7484 - val_accuracy: 0.5579\n",
      "Epoch 20/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6122 - accuracy: 0.6964 - val_loss: 0.7371 - val_accuracy: 0.5550\n",
      "Epoch 21/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.6486 - accuracy: 0.6284 - val_loss: 0.7188 - val_accuracy: 0.5393\n",
      "Epoch 22/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.6244 - accuracy: 0.6814 - val_loss: 0.7288 - val_accuracy: 0.5409\n",
      "Epoch 23/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5981 - accuracy: 0.7104 - val_loss: 0.7386 - val_accuracy: 0.5504\n",
      "Epoch 24/30\n",
      "438/438 [==============================] - 3s 7ms/step - loss: 0.5775 - accuracy: 0.7297 - val_loss: 0.7458 - val_accuracy: 0.5560\n",
      "Epoch 25/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.5527 - accuracy: 0.7412 - val_loss: 0.7422 - val_accuracy: 0.5640\n",
      "Epoch 26/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.5516 - accuracy: 0.7425 - val_loss: 0.7359 - val_accuracy: 0.5614\n",
      "Epoch 27/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5468 - accuracy: 0.7445 - val_loss: 0.7438 - val_accuracy: 0.5643\n",
      "Epoch 28/30\n",
      "438/438 [==============================] - 2s 6ms/step - loss: 0.5473 - accuracy: 0.7434 - val_loss: 0.7673 - val_accuracy: 0.5627\n",
      "Epoch 29/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.5416 - accuracy: 0.7476 - val_loss: 0.7342 - val_accuracy: 0.5620\n",
      "Epoch 30/30\n",
      "438/438 [==============================] - 3s 6ms/step - loss: 0.5442 - accuracy: 0.7448 - val_loss: 0.7374 - val_accuracy: 0.5641\n",
      "Model saved to gru_model_fold_2.h5\n",
      "Fold 2, Best Validation Loss: 0.6892765760421753, Best Validation Accuracy: 0.5714285969734192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seyeong/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "657/657 [==============================] - 7s 6ms/step - loss: 0.6841 - accuracy: 0.5626 - val_loss: 0.7372 - val_accuracy: 0.4286\n",
      "Epoch 2/30\n",
      "657/657 [==============================] - 3s 5ms/step - loss: 0.6820 - accuracy: 0.5713 - val_loss: 0.7277 - val_accuracy: 0.4286\n",
      "Epoch 3/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6812 - accuracy: 0.5735 - val_loss: 0.7157 - val_accuracy: 0.4289\n",
      "Epoch 4/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6807 - accuracy: 0.5715 - val_loss: 0.7354 - val_accuracy: 0.4286\n",
      "Epoch 5/30\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.6799 - accuracy: 0.5714 - val_loss: 0.7258 - val_accuracy: 0.4286\n",
      "Epoch 6/30\n",
      "657/657 [==============================] - 4s 5ms/step - loss: 0.6806 - accuracy: 0.5723 - val_loss: 0.7292 - val_accuracy: 0.4290\n",
      "Epoch 7/30\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.6798 - accuracy: 0.5738 - val_loss: 0.7332 - val_accuracy: 0.4287\n",
      "Epoch 8/30\n",
      "657/657 [==============================] - 4s 6ms/step - loss: 0.6775 - accuracy: 0.5739 - val_loss: 0.7455 - val_accuracy: 0.4370\n",
      "Epoch 9/30\n",
      "132/657 [=====>........................] - ETA: 2s - loss: 0.6740 - accuracy: 0.5784"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m X_t, y_t \u001b[38;5;241m=\u001b[39m npz_to_csv(dataset_path \u001b[38;5;241m+\u001b[39m file)\n\u001b[1;32m     11\u001b[0m anomaly_rate \u001b[38;5;241m=\u001b[39m get_anomaly_rate(y_t)\n\u001b[0;32m---> 12\u001b[0m val_losses, val_accs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_t\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 66\u001b[0m, in \u001b[0;36mtrain_and_evaluate_transformer\u001b[0;34m(X, y, n_splits, epochs, batch_size)\u001b[0m\n\u001b[1;32m     53\u001b[0m model \u001b[38;5;241m=\u001b[39m build_transformer_model(\n\u001b[1;32m     54\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]),\n\u001b[1;32m     55\u001b[0m     head_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     mlp_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     64\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 66\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# 가장 좋은 검증 성능을 기록\u001b[39;00m\n\u001b[1;32m     69\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = './datasets/Classical/'\n",
    "file = \"42_Motorcondition1.npz\"\n",
    "# f = file.split('_')\n",
    "# g = file.split('.')\n",
    "# search_index = int(f[0])\n",
    "\n",
    "X_t, y_t = npz_to_csv(dataset_path + file)\n",
    "anomaly_rate = get_anomaly_rate(y_t)\n",
    "val_losses, val_accs = train_and_evaluate_transformer(X_t, y_t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_train_and_evaluate_transformer(X, y, n_splits=5, epochs=30, batch_size=32):\n",
    "    # 데이터 정규화\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    fold = 1\n",
    "    for train_idx, test_idx in tscv.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # Input shape 맞추기 위함\n",
    "        X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "        \n",
    "        print(X_test)\n",
    "        \n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfile_list\u001b[49m:\n\u001b[1;32m      3\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m npz_to_csv(file)\n\u001b[1;32m      5\u001b[0m     val_losses, val_accs \u001b[38;5;241m=\u001b[39m test_train_and_evaluate_transformer(X, y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "file_idx = 1\n",
    "for file in file_list:\n",
    "    X, y = npz_to_csv(file)\n",
    "    \n",
    "    val_losses, val_accs = test_train_and_evaluate_transformer(X, y)\n",
    "    append_to_val_dict(file_idx, val_losses, val_accs)\n",
    "    file_idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
